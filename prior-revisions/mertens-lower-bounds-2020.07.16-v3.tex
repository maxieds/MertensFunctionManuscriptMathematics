\documentclass[11pt,reqno,a4letter]{article} 

\usepackage{amsmath,amssymb,amsfonts,amscd}
\usepackage[hidelinks]{hyperref} 
\usepackage{url}
\usepackage[usenames,dvipsnames]{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={green!63!darkgray},
    citecolor={blue!70!white},
    urlcolor={blue!80!white}
}

\usepackage[normalem]{ulem}
\usepackage{graphicx} 
\usepackage{datetime} 
\usepackage{cancel}
\usepackage{subcaption}
\captionsetup{format=hang,labelfont={bf},textfont={small,it}} 
\numberwithin{figure}{section}
\numberwithin{table}{section}

%\usepackage{stmaryrd,tikzsymbols,mathabx,wasysym} 
\usepackage{framed} 
\usepackage{ulem}
\usepackage[T1]{fontenc}
\usepackage{pbsi}


\usepackage{enumitem}
\setlist[itemize]{leftmargin=0.65in}

\usepackage{rotating,adjustbox}

\usepackage{diagbox}
\newcommand{\trianglenk}[2]{$\diagbox{#1}{#2}$}
\newcommand{\trianglenkII}[2]{\diagbox{#1}{#2}}

\let\citep\cite

\newcommand{\undersetbrace}[2]{\underset{\displaystyle{#1}}{\underbrace{#2}}}

\newcommand{\gkpSI}[2]{\ensuremath{\genfrac{\lbrack}{\rbrack}{0pt}{}{#1}{#2}}} 
\newcommand{\gkpSII}[2]{\ensuremath{\genfrac{\lbrace}{\rbrace}{0pt}{}{#1}{#2}}}
\newcommand{\cf}{\textit{cf.\ }} 
\newcommand{\Iverson}[1]{\ensuremath{\left[#1\right]_{\delta}}} 
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor} 
\newcommand{\ceiling}[1]{\left\lceil #1 \right\rceil} 
\newcommand{\e}[1]{e\left(#1\right)} 
\newcommand{\seqnum}[1]{\href{http://oeis.org/#1}{\color{ProcessBlue}{\underline{#1}}}}

\usepackage{upgreek,dsfont,amssymb}
\renewcommand{\chi}{\upchi}
\newcommand{\ChiFunc}[1]{\ensuremath{\chi_{\{#1\}}}}
\newcommand{\OneFunc}[1]{\ensuremath{\mathds{1}_{#1}}}

\usepackage{ifthen}
\newcommand{\Hn}[2]{
     \ifthenelse{\equal{#2}{1}}{H_{#1}}{H_{#1}^{\left(#2\right)}}
}

\newcommand{\Floor}[2]{\ensuremath{\left\lfloor \frac{#1}{#2} \right\rfloor}}
\newcommand{\Ceiling}[2]{\ensuremath{\left\lceil \frac{#1}{#2} \right\rceil}}

\DeclareMathOperator{\DGF}{DGF} 
\DeclareMathOperator{\ds}{ds} 
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\fg}{fg}
\DeclareMathOperator{\Div}{div}
\DeclareMathOperator{\rpp}{rpp}
\DeclareMathOperator{\logll}{\ell\ell}

\title{
       \LARGE{
       Lower bounds on the summatory function of the M\"obius function along infinite subsequences 
       } 
}
\author{{\Large Maxie Dion Schmidt} \\ 
        %{\normalsize \href{mailto:maxieds@gmail.com}{maxieds@gmail.com}} \\[0.1cm] 
        {\normalsize Georgia Institute of Technology} \\[0.025cm] 
        {\normalsize School of Mathematics} 
} 

\date{\small\underline{Last Revised:} \today \ @\ \hhmmsstime{} \ -- \ Compiled with \LaTeX2e} 

\usepackage{amsthm} 

\theoremstyle{plain} 
\newtheorem{theorem}{Theorem}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{cor}[theorem]{Corollary}
\numberwithin{theorem}{section}

\theoremstyle{definition} 
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{question}[theorem]{Question}
\newtheorem{discussion}[theorem]{Discussion}
\newtheorem{facts}[theorem]{Facts}
\newtheorem{summary}[theorem]{Summary}
\newtheorem{heuristic}[theorem]{Heuristic}

\renewcommand{\arraystretch}{1.25} 

\setlength{\textheight}{9in}
\setlength{\topmargin}{-.18in}
\setlength{\textwidth}{7.65in} 
\setlength{\evensidemargin}{-0.25in} 
\setlength{\oddsidemargin}{-0.25in} 
\setlength{\headsep}{8pt} 
%\setlength{\footskip}{10pt} 

\usepackage{geometry}
%\newgeometry{top=0.65in, bottom=18mm, left=15mm, right=15mm, outer=2in, heightrounded, marginparwidth=1.5in, marginparsep=0.15in}
\newgeometry{top=0.65in, bottom=16mm, left=15mm, right=15mm, heightrounded, marginparwidth=0in, marginparsep=0.15in}

\usepackage{fancyhdr}
\pagestyle{empty}
\pagestyle{fancy}
\fancyhead[RO,RE]{Maxie Dion Schmidt -- \today} 
\fancyhead[LO,LE]{}
\fancyheadoffset{0.005\textwidth} 

\setlength{\parindent}{0in}
\setlength{\parskip}{2cm} 

\renewcommand{\thefootnote}{\textbf{\Alph{footnote}}}
\makeatletter
\@addtoreset{footnote}{section}
\makeatother

%\usepackage{marginnote,todonotes}
%\colorlet{NBRefColor}{RoyalBlue!73} 
%\newcommand{\NBRef}[1]{
%     \todo[linecolor=green!85!white,backgroundcolor=orange!50!white,bordercolor=blue!30!black,textcolor=cyan!15!black,shadow,size=\small,fancyline]{
%     \color{NBRefColor}{\textbf{#1}
%     }
%     }
%}
\newcommand{\NBRef}[1]{}  

\newcommand{\SuccSim}[0]{\overset{_{\scriptsize{\blacktriangle}}}{\succsim}} 
\newcommand{\PrecSim}[0]{\overset{_{\scriptsize{\blacktriangle}}}{\precsim}} 
\renewcommand{\SuccSim}[0]{\ensuremath{\gg}} 
\renewcommand{\PrecSim}[0]{\ensuremath{\ll}} 

\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\Im}{\operatorname{Im}}

\input{glossaries-bibtex/PreambleGlossaries-Mertens}

\usepackage{tikz}
\usetikzlibrary{shapes,arrows}

\usepackage{enumitem} 

\allowdisplaybreaks 

\begin{document} 

\maketitle

\begin{abstract} 
The Mertens function, $M(x) = \sum_{n \leq x} \mu(n)$, is classically 
defined as the summatory function of the M\"obius function $\mu(n)$. 
The Mertens conjecture states that $|M(x)| < C \cdot \sqrt{x}$ for some absolute $C > 0$ for all 
$x \geq 1$. 
This classical conjecture has a well-known disproof due to 
Odlyzko and t\'{e} Riele by computation of 
non-trivial zeta function zeros in conjunction with integral formulas expressing $M(x)$. 
We prove the unboundedness of $|M(x)| / \sqrt{x}$ using new methods by showing that 
$$\limsup_{x \rightarrow \infty} \frac{|M(x)| \cdot (\log\log\log x)^{2}}{ 
  \sqrt{x} \cdot (\log x)^{\frac{3}{4}} (\log\log x)^{\frac{5}{2}}} > 0.$$ 
There is a distinct stylistic 
flavor and new element of combinatorial analysis to our proof 
combined with the standard methods from analytic, additive and elementary number theory. 
This stylistic tendency distinguishes 
our methods from other proofs of established upper, rather than lower, bounds on $M(x)$. 

\bigskip 
\noindent
\textbf{Keywords and Phrases:} {\it M\"obius function; Mertens function; summatory function; 
                                    Dirichlet inverse; Liouville lambda function; prime omega function; 
                                    prime counting functions; Dirichlet generating function; 
                                    asymptotic lower bounds; Mertens conjecture. } \\ 
% 11-XX			Number theory
%    11A25  	Arithmetic functions; related numbers; inversion formulas
%    11Y70  	Values of arithmetic functions; tables
%    11-04  	Software, source code, etc. for problems pertaining to number theory
% 11Nxx		Multiplicative number theory
%    11N05  	Distribution of primes
%    11N37  	Asymptotic results on arithmetic functions
%    11N56  	Rate of growth of arithmetic functions
%    11N60  	Distribution functions associated with additive and positive multiplicative functions
%    11N64  	Other results on the distribution of values or the characterization of arithmetic functions
\textbf{Math Subject Classifications (MSC 2010):} {\it 11N37; 11A25; 11N60; and 11N64. } 
\end{abstract} 

%\bigskip\hrule\bigskip

\newpage
%\section{Reference on abbreviations, special notation and other conventions} 
\label{Appendix_Glossary_NotationConvs}
     \vskip 0in
     \printglossary[type={symbols},
                    title={Glossary of special notation and conventions},
                    style={glossstyleSymbol},
                    nogroupskip=true]


%\newpage
%\setcounter{tocdepth}{2}
%\renewcommand{\contentsname}{Listing of major sections and topics} 
%\tableofcontents 

\newpage
\section{Introduction} 
\label{subSection_MertensMxClassical_Intro} 

\subsection{Definitions} 

We define the \emph{M\"obius function} to be the signed indicator function 
of the squarefree integers in the form of \cite[\seqnum{A008683}]{OEIS} 
\[
\mu(n) = \begin{cases} 
     1, & \text{if $n = 1$; } \\ 
     (-1)^{\omega(n)}, & \text{if $\omega(n) = \Omega(n)$ and $n \geq 2$; } \\ 
     0, & \text{otherwise.} 
     \end{cases} 
\]
There are many variants and special properties of the M\"obius function 
and its generalizations \cite[\cf \S 2]{HANDBOOKNT-2004}. 
One crucial role of the classical $\mu(n)$ is that the function forms an inversion relation 
for the divisor sums formed by arithmetic functions convolved with one through \emph{M\"obius inversion}: 
\[
g(n) = (f \ast 1)(n) \iff f(n) = (g \ast \mu)(n), \forall n \geq 1. 
\]
The \emph{Mertens function}, or summatory function of $\mu(n)$, is defined on the 
positive integers as 
\begin{align*} 
M(x) & = \sum_{n \leq x} \mu(n), x \geq 1. 
\end{align*} 
The sequence of slow growing oscillatory values of this 
summatory function begins as follows \cite[\seqnum{A002321}]{OEIS}: 
\[
\{M(x)\}_{x \geq 1} = \{1, 0, -1, -1, -2, -1, -2, -2, -2, -1, -2, -2, -3, -2, 
     -1, -1, -2, -2, -3, -3, -2, -1, -2, \ldots\}. 
\]
Clearly, a positive integer $n \geq 1$ is \emph{squarefree}, or contains no (prime power) divisors which are 
squares, if and only if $\mu^2(n) = 1$. 
A related summatory function which counts the 
number of \emph{squarefree} integers $n \leq x$ satisfies 
\cite[\S 18.6]{HARDYWRIGHT} \cite[\seqnum{A013928}]{OEIS} 
\[ 
Q(x) = \sum_{n \leq x} \mu^2(n) \sim \frac{6x}{\pi^2} + O\left(\sqrt{x}\right). 
\] 
It is known that the asymptotic density of the positively versus negatively 
weighted sets of squarefree numbers characterized by the sign of the 
M\"obius function are in fact equal as $x \rightarrow \infty$: 
\[
\mu_{+}(x) = \frac{\#\{1 \leq n \leq x: \mu(n) = +1\}}{x} \overset{\mathbb{E}}{\sim} 
     \mu_{-}(x) = \frac{\#\{1 \leq n \leq x: \mu(n) = -1\}}{x} 
     \xrightarrow{x \rightarrow \infty} \frac{3}{\pi^2}. 
\]

\subsection{Properties} 

A conventional approach to evaluating the limiting asymptotic 
behavior of $M(x)$ for large $x \rightarrow \infty$ results by considering an 
inverse Mellin transformation of the reciprocal of the Riemann zeta function. 
In particular, since 
\[
\frac{1}{\zeta(s)} = \prod_{p} \left(1 - \frac{1}{p^s}\right) = 
     s \cdot \int_1^{\infty} \frac{M(x)}{x^{s+1}} dx, \Re(s) > 1, 
\]
we obtain that 
\[
M(x) = \lim_{T \rightarrow \infty}\ \frac{1}{2\pi\imath} \int_{T-\imath\infty}^{T+\imath\infty} 
     \frac{x^s}{s \cdot \zeta(s)} ds. 
\] 
The previous two representations lead us to the 
exact expression of $M(x)$ for any real $x > 0$ 
given by the next theorem due to Titchmarsh. 
\nocite{TITCHMARSH} 

\begin{theorem}[Analytic Formula for $M(x)$] 
\label{theorem_MxMellinTransformInvFormula} 
Assuming the Riemann Hypothesis (RH), there exists an infinite sequence 
$\{T_k\}_{k \geq 1}$ satisfying $k \leq T_k \leq k+1$ for each $k$ 
such that for any real $x > 0$ 
\[
M(x) = \lim_{k \rightarrow \infty} 
     \sum_{\substack{\rho: \zeta(\rho) = 0 \\ |\Im(\rho)| < T_k}} 
     \frac{x^{\rho}}{\rho \cdot \zeta^{\prime}(\rho)} - 2 + 
     \sum_{n \geq 1} \frac{(-1)^{n-1}}{n \cdot (2n)! \zeta(2n+1)} 
     \left(\frac{2\pi}{x}\right)^{2n} + 
     \frac{\mu(x)}{2} \Iverson{x \in \mathbb{Z}^{+}}. 
\] 
\end{theorem} 

A historical unconditional bound on the Mertens function due to Walfisz (circa 1963) 
states that there is an absolute constant $C > 0$ such that 
$$M(x) \ll x \cdot \exp\left(-C \cdot \log^{3/5}(x) 
  (\log\log x)^{-3/5}\right).$$ 
Under the assumption of the RH, Soundararajan more recently proved new updated estimates 
bounding $M(x)$ from above for large $x$ in the following forms \cite{SOUND-MERTENS-ANNALS}: 
\begin{align*} 
M(x) & \ll \sqrt{x} \cdot \exp\left(\log^{1/2}(x) (\log\log x)^{14}\right), \\ 
M(x) & = O\left(\sqrt{x} \cdot \exp\left( 
     \log^{1/2}(x) (\log\log x)^{5/2+\epsilon}\right)\right),\ 
     \forall \epsilon > 0. 
\end{align*} 

\subsection{Conjectures on boundedness and limiting behavior} 

The RH is equivalent to showing that 
$M(x) = O\left(x^{\frac{1}{2}+\varepsilon}\right)$ for any 
$0 < \varepsilon < \frac{1}{2}$. 
There is a rich history to the original statement of the \emph{Mertens conjecture} which 
asserts that 
\[ 
|M(x)| < C \cdot \sqrt{x},\ \text{ for some absolute constant $C > 0$. }
\] 
The conjecture was first verified by Mertens for $C = 1$ and all $x < 10000$. 
Since its beginnings in 1897, the Mertens conjecture has been disproven by computation 
of non-trivial simple zeta function zeros with comparitively small imaginary parts in a famous paper by 
Odlyzko and t\'{e} Riele \cite{ODLYZ-TRIELE}. 
Since the truth of the conjecture would have implied the RH, more recent attempts 
at bounding $M(x)$ naturally consider determining the rates at which the function 
$M(x) / \sqrt{x}$ grows with or without bound along infinite 
subsequences, e.g., considering the asymptotics of the function in the limit supremum and 
limit infimum senses. 

A precise statement of this 
problem is to produce an unconditional proof of whether 
$\limsup_{x \rightarrow \infty} M(x) / \sqrt{x} = +\infty$ and 
$\liminf_{x \rightarrow \infty} M(x) / \sqrt{x} = -\infty$, or 
equivalently whether there are infinite subsequences of natural numbers 
$\{x_1, x_2, x_3, \ldots\}$ such that the magnitude of 
$M(x_i) x_i^{-1/2}$ grows without bound towards either $\pm \infty$ 
along the subsequence. 
We cite that it is only known by computation 
that \cite[\cf \S 4.1]{PRIMEREC} 
\cite[\cf \seqnum{A051400}; \seqnum{A051401}]{OEIS} 
\[
\limsup_{x\rightarrow\infty} \frac{M(x)}{\sqrt{x}} > 1.060\ \qquad (\text{now } \geq 1.826054), 
\] 
and 
\[ 
\liminf_{x\rightarrow\infty} \frac{M(x)}{\sqrt{x}} < -1.009\ \qquad (\text{now } \leq -1.837625). 
\] 
Based on work by Odlyzyko and t\'{e} Riele, it seems probable that 
each of these limits should evaluate to $\pm \infty$, respectively 
\cite{ODLYZ-TRIELE,MREVISITED,ORDER-MERTENSFN,HURST-2017}. 
Extensive computational evidence has produced 
a conjecture due to Gonek that in fact the limiting behavior of 
$M(x)$ satisfies \cite{NG-MERTENS}
$$\limsup_{x \rightarrow \infty} \frac{|M(x)|}{\sqrt{x} \cdot (\log\log\log x)^{5/4}} = O(1).$$ 

\newpage
\section{An overview of the core components to the proof} 

We offer an initial step-by-step summary overview of the core components 
to our proof outlined in the next points. 
We hope that this sketch of the logical components 
to this argument makes the article easier to parse. 

\begin{itemize} 

\item[\textbf{(1)}] We prove a matrix inversion formula relating the summatory 
           functions of an arithmetic function $f$ and its Dirichlet inverse $f^{-1}$ (for $f(1) \neq 0$). 
           See Theorem \ref{theorem_SummatoryFuncsOfDirCvls} in 
           Section \ref{Section_PrelimProofs_Config}.  
\item[\textbf{(2)}] This crucial step provides us with an exact formula for $M(x)$ in terms of $\pi(x)$, the 
           prime counting function, and the 
           Dirichlet inverse of the shifted additive function $g(n) := \omega(n) + 1$. This 
           formula is stated in \eqref{eqn_Mx_gInvnPixk_formula}. 
           The link relating our new formula in 
           \eqref{eqn_Mx_gInvnPixk_formula} to canonical additive functions and their 
           distributions lends a recent distinguishing element to the 
           success of the methods in our proof. 
\item[\textbf{(3)}] We tighten bounds from a less classical result proved in 
            \cite[\S 7]{MV} providing uniform asymptotic formulas for the  
           summatory functions, $\widehat{\pi}_k(x)$, large $x \gg e$ and 
           $1 \leq k \leq \log\log x$ 
           (see Theorem \ref{theorem_GFs_SymmFuncs_SumsOfRecipOfPowsOfPrimes}). 
           We use this result to bound sums of the form 
           $\sum_{n \leq x} \lambda(n) f(n)$ from below for particular positive arithmetic 
           functions $f$ when $x$ is large. 
\item[\textbf{(4)}] We then turn to estimating the limiting 
           asymptotics of the quasi-periodic function, $|g^{-1}(n)|$, by proving several formulas bounding its 
           average order as $x \rightarrow \infty$ in 
           Section \ref{Section_InvFunc_PreciseExpsAndAsymptotics}. 
           We eventually use these estimates to prove a substantially unique new lower bound formulas 
           for the summatory function 
           $G^{-1}(x) := \sum_{n \leq x} \lambda(n) |g^{-1}(n)|$ 
           along certain asymptotically large 
           infinite subsequences (see Theorem \ref{theorem_gInv_GeneralAsymptoticsForms}). 
\item[\textbf{(5)}] \textbf{(TODO)} 
\item[\textbf{(6)}] When we return to step \textbf{(2)} 
           with our new lower bounds at hand, we are led to a new unconditional proof of the 
           unboundedness of $\frac{|M(x)|}{\sqrt{x}}$ 
           along a very large increasing infinite subsequence of positive natural numbers. 
           In fact, we recover a quick and rigorous proof of 
           Theorem \ref{cor_ThePipeDreamResult_v1} given at the conclusion of 
           Section \ref{subSection_TheCoreResultProof}. 
           
\end{itemize} 

\newpage 
\section{A concrete new approach to bounding $M(x)$ from below} 

\subsection{Summatory functions of Dirichlet convolutions of arithmetic functions} 

\begin{theorem}[Summatory functions of Dirichlet convolutions] 
\label{theorem_SummatoryFuncsOfDirCvls} 
Let $f,h: \mathbb{Z}^{+} \rightarrow \mathbb{C}$ be any arithmetic functions such that $f(1) \neq 0$. 
Suppose that $F(x) := \sum_{n \leq x} f(n)$ and $H(x) := \sum_{n \leq x} h(n)$ denote the summatory 
functions of $f$ and $h$, respectively, and that $F^{-1}(x)$ denotes the summatory function of the 
Dirichlet inverse of $f$. We have the following exact expressions for the 
summatory function of $f \ast h$ for all integers $x \geq 1$: 
\begin{align*} 
\pi_{f \ast h}(x) & := \sum_{n \leq x} \sum_{d|n} f(d) h(n/d) \\ 
     & \phantom{:}= \sum_{d \leq x} f(d) H\left(\Floor{x}{d}\right) \\ 
     & \phantom{:}= \sum_{k=1}^{x} H(k) \left[F\left(\Floor{x}{k}\right) - 
     F\left(\Floor{x}{k+1}\right)\right]. 
\end{align*} 
Moreover, for all $x \geq 1$ 
\begin{align*} 
H(x) & = \sum_{j=1}^{x} \pi_{f \ast h}(j) \left[F^{-1}\left(\Floor{x}{j}\right) - 
     F^{-1}\left(\Floor{x}{j+1}\right)\right] \\ 
     & = \sum_{n=1}^{x} f^{-1}(n) \pi_{f \ast h}\left(\Floor{x}{n}\right). 
\end{align*} 
\end{theorem} 

\begin{cor}[Convolutions arising from M\"obius inversion] 
\label{cor_CvlGAstMu} 
Suppose that $g$ is an arithmetic function such that 
$g(1) \neq 0$. Define the summatory function of 
the convolution of $g$ with $\mu$ by $\widetilde{G}(x) := \sum_{n \leq x} (g \ast \mu)(n)$. 
The Mertens function is expressed by the sum 
\[
M(x) = \sum_{k=1}^{x} \left(\sum_{j=\floor{\frac{x}{k+1}}+1}^{\floor{\frac{x}{k}}} g^{-1}(j)\right) 
     \widetilde{G}(k), \forall x \geq 1. 
\]
\end{cor} 

\begin{cor}[A motivating special case] 
\label{cor_Mx_gInvnPixk_formula} 
We have exactly that for all $x \geq 1$ 
\begin{equation} 
\label{eqn_Mx_gInvnPixk_formula} 
M(x) = \sum_{k=1}^{x} (\omega+1)^{-1}(k) \left[\pi\left(\Floor{x}{k}\right) + 1\right]. 
\end{equation} 
\end{cor} 

\subsection{An exact expression for $M(x)$ in terms of strongly additive functions} 
\label{example_InvertingARecRelForMx_Intro}

Fix the notation for the Dirichlet invertible function $g(n) := \omega(n) + 1$ and define its 
inverse with respect to Dirichlet convolution by $g^{-1}(n) = (\omega+1)^{-1}(n)$. 
We can compute exactly that 
(see Table \ref{table_conjecture_Mertens_ginvSeq_approx_values} starting on page 
\pageref{table_conjecture_Mertens_ginvSeq_approx_values} of the appendix section) 
\[
\{g^{-1}(n)\}_{n \geq 1} = \{1, -2, -2, 2, -2, 5, -2, -2, 2, 5, -2, -7, -2, 5, 5, 2, -2, -7, -2, 
     -7, 5, 5, -2, 9, \ldots \}. 
\] 
The sign of these positive terms is given by 
$\operatorname{sgn}(g^{-1}(n)) = \frac{g^{-1}(n)}{|g^{-1}(n)|} = \lambda(n)$ for all $n \geq 1$ 
(see Proposition \ref{prop_SignageDirInvsOfPosBddArithmeticFuncs_v1}). 

There is not an easy, nor subtle 
direct recursion between the distinct values of $g^{-1}(n)$, except through auxiliary function sequences. 
The distribution of distinct sets of prime exponents is still fairly regular so that 
$\omega(n)$ and $\Omega(n)$ play a crucial role in the repitition of common values of 
$g^{-1}(n)$. 
The following observation is suggestive of the quasi-periodicity of the distribution of 
distinct values of $g^{-1}(n)$ over $n \geq 2$: 

\begin{heuristic}[Symmetry in $g^{-1}(n)$ in the prime factorizations of $n$] 
Suppose that $n_1, n_2 \geq 2$ are such that their factorizations into distinct primes are 
given by $n_1 = p_1^{\alpha_1} \cdots p_r^{\alpha_r}$ and $n_2 = q_1^{\beta_1} \cdots q_r^{\beta_r}$ 
for $ = \omega(n_i) \geq 1$. 
If $\{\alpha_1, \ldots, \alpha_r\} \equiv \{\beta_1, \ldots, \beta_r\}$ as multisets of prime exponents, 
then $g^{-1}(n_1) = g^{-1}(n_2)$. For example, $g^{-1}$ has the same values on the squarefree integers 
with exactly one, two, three, and so on prime factors.  
\end{heuristic} 

\NBRef{A01-2020-04-26}
\begin{conjecture}
\label{lemma_gInv_MxExample} 
We have the following properties characterizing the 
Dirichlet inverse function $g^{-1}(n)$: 
\begin{itemize} 

\item[\textbf{(A)}] $g^{-1}(1) = 1$; 
\item[\textbf{(B)}] For all $n \geq 1$, $\operatorname{sgn}(g^{-1}(n)) = \lambda(n)$; 
\item[\textbf{(C)}] For all squarefree integers $n \geq 1$, we have that 
     \[
     |g^{-1}(n)| = \sum_{m=0}^{\omega(n)} \binom{\omega(n)}{m} \cdot m!; 
     \]
\item[\textbf{(D)}] If $n \geq 2$ and $\Omega(n) = k$, then 
     \[
     2 \leq |g^{-1}(n)| \leq \sum_{m=0}^{k} \binom{k}{m} \cdot m!. 
     \]
\end{itemize} 
\end{conjecture} 

We illustrate parts (B)--(D) of the conjecture clearly using the computation of initial values of 
this inverse sequence in 
Table \ref{table_conjecture_Mertens_ginvSeq_approx_values}. 
A proof of (C) in fact follows from 
Lemma \ref{lemma_AnExactFormulaFor_gInvByMobiusInv_v1} 
stated on page \pageref{lemma_AnExactFormulaFor_gInvByMobiusInv_v1}. 
The realization that the beautiful and remarkably simple combinatorial form of property (C) 
in Conjecture \ref{lemma_gInv_MxExample} holds for all squarefree $n \geq 1$ 
motivates our pursuit of simpler formulas for the inverse functions $g^{-1}(n)$ 
through sums of auxiliary sequences of arithmetic functions 
(see Section \ref{Section_InvFunc_PreciseExpsAndAsymptotics}). 

We prove that (see Proposition \ref{prop_Mx_SBP_IntegralFormula}) 
\[
M(x) = G^{-1}(x) + G^{-1}\left(\frac{x}{2}\right) - 
     \sum_{k=1}^{\sqrt{x}} G^{-1}(k) \left[ 
     \pi\left(\Floor{x}{k}\right) - \pi\left(\Floor{x}{k+1}\right) 
     \right]. 
\]
This formula 
implies that we can establish new \emph{lower bounds} on $M(x)$ along large infinite subsequences 
by bounding appropriate estimates of the summatory function $G^{-1}(x)$. 

\subsection{Uniform asymptotics from enumerative bivariate DGFs from Mongomery and Vaughan} 

\begin{theorem}[Montgomery and Vaughan]
\label{theorem_HatPi_ExtInTermsOfGz} 
Recall that we have defined 
$$\widehat{\pi}_k(x) := \#\{n \leq x: \Omega(n)=k\}.$$ 
For $R < 2$ we have that uniformly for all $1 \leq k \leq R \log\log x$ 
\[
\widehat{\pi}_k(x) = \mathcal{G}\left(\frac{k-1}{\log\log x}\right) \frac{x}{\log x} 
     \frac{(\log\log x)^{k-1}}{(k-1)!} \left[1 + O_R\left(\frac{k}{(\log\log x)^2}\right)\right], 
\]
where 
\[
\mathcal{G}(z) := \frac{1}{\Gamma(z+1)} \times 
     \prod_p \left(1-\frac{z}{p}\right)^{-1} \left(1-\frac{1}{p}\right)^z, 0 \leq |z| \leq R. 
\]
\end{theorem} 

The proof of the next result is combinatorially motivated in so much as it interprets 
lower bounds on a key infinite product factor of $\mathcal{G}(z)$ defined in 
Theorem \ref{theorem_HatPi_ExtInTermsOfGz} 
as corresponding to an ordinary generating function of certain 
homogeneous symmetric polynomials involving the primes. This interpretation allows us to recover the 
following uniform lower bounds on $\widehat{\pi}_k(x)$ as $x \rightarrow \infty$: 

\begin{theorem} 
\label{theorem_GFs_SymmFuncs_SumsOfRecipOfPowsOfPrimes} 
\label{cor_BoundsOnGz_FromMVBook_initial_stmt_v1} 
For all sufficiently large $x$ we have uniformly for $1 \leq k \leq \log\log x$ that 
\[
\widehat{\pi}_k(x) \gg 
     \frac{x^{3/4}}{(\log x)^{1/2}} \cdot 
     \frac{(\log\log x)^{k-1}}{(k-1)!} \left[1 + 
     O\left(\frac{k}{(\log\log x)^2}\right)\right]. 
\]
\end{theorem} 

\subsubsection{Applications of the new uniform lower bound estimates} 

Our inspiration for the new bounds found in the last sections of this article allows us to 
approximate finite partial sums of certain bounded 
non-negative arithmetic functions weighted by the Liouville lambda function 
$\lambda(n)$. 

\begin{lemma} 
\label{lemma_CLT_and_AbelSummation} 
\textbf{(TODO)} 
Suppose that $f(n)$ is an arithmetic function defined 
such that $f(n) > 0$ for all $n > u_0$ where 
$f(n) \SuccSim \widehat{\tau}_{\ell}(n) > 0$ whenever $n > u_0$ 
as $n \rightarrow \infty$. Assume also that 
the bounding function $\widehat{\tau}_{\ell}(t)$ is a 
continuously differentiable function of $t$ for all 
large enough $t \gg u_0$.  
We define the $\lambda$-sign-scaled summatory function of $f$ as follows: 
\[
F_{\lambda}(x) := \sum_{\substack{u_0 < n \leq x}} \lambda(n) f(n). 
\]
Let the summatory weight function be defined as 
\begin{align*} 
A_{\Omega}(t) & := \sum_{k=1}^{\floor{\log\log t}} (-1)^k \widehat{\pi}_k(t). 
\end{align*} 
Suppose that $|A_{\Omega}(t)| \gg |A_{\Omega}^{(\ell)}(t)|$ as $t \rightarrow \infty$. 
Then we have that for sufficiently large $x > e$ 
\begin{equation} 
\label{eqn_Flambdax_RHA_AbelSummationFormula_v1} 
|F_{\lambda}(x)| \SuccSim \left\lvert 
     \left\lvert A_{\Omega}^{(\ell)}(x) \widehat{\tau}_{\ell}(x) \right\rvert - 
     \int_{\frac{\log\log x}{2} - \frac{1}{2}}^{\frac{\log\log x}{2}} 
     \left\lvert A_{\Omega}^{(\ell)}\left(e^{e^{2t}}\right) 
     \widehat{\tau}_{\ell}^{\prime}\left(e^{e^{2t}}\right) 
     \right\rvert e^{e^{2t}} dt 
     \right\rvert.  
\end{equation} 
\end{lemma} 

\subsubsection{Remarks} 

We emphasize the relevant recency of the method demonstrated by 
Montgomery and Vaughan in constructing a proof of 
Theorem \ref{theorem_HatPi_ExtInTermsOfGz}. 
To the best of our knowledge, this textbook reference is 
one of the first clear-cut applications documenting something of a hybrid 
DGF-and-OGF approach to enumerating sequences of arithmetic functions 
and their summatory functions. The hybrid method is motivated by the fact that it 
does not require a direct appeal to 
traditional highly oscillatory DGF-only inversions and integral formulas 
involving the Riemmann zeta function. 
This newer interpretaion of certain bivariate DGFs 
offers a window into the best of both generating function series worlds: 
It combines the additivity 
implicit to the coefficients indexed by a formal power series variable formed by 
multiplication of these structures, while coordinating the distinct DGF-best 
property of the multiplicativity of distinct prime powers invoked 
by taking powers of an Euler product. 

\subsection{Cracking the classical unboundedness barrier} 

In Section \ref{Section_KeyApplications}, 
we are able to state what forms a bridge between the results 
we carefully prove up to that point the article. 
What we obtain at the conclusion of the section 
is the next summary theorem that unconditionally 
resolves the classical question of the 
unboundedness of the scaled function Mertens function 
$q(x) := |M(x)| / \sqrt{x}$ in the limit supremum sense. 

\begin{theorem}[Unboundedness of the the Mertens function, $q(x)$] 
\label{cor_ThePipeDreamResult_v1} 
We have that 
\[
\limsup_{x \rightarrow \infty} \frac{|M(x)|}{\sqrt{x}} = +\infty. 
\]
\end{theorem} 

In establishing the rigorous proof of 
Theorem \ref{cor_ThePipeDreamResult_v1} 
based on our new methods, we not only show unboundedness of 
$q(x)$, but also set a minimal rate (along a large infinite subsequence) 
at which this form of the 
scaled Mertens function grows without bound. 

\newpage 
\section{Preliminary proofs of new results} 
\label{Section_PrelimProofs_Config} 

\subsection{Establishing the summatory function properties and inversion identities} 

We will offer a proof of Theorem \ref{theorem_SummatoryFuncsOfDirCvls} 
suggested by an intuitive construction through matrix methods. 
Related results on summations of Dirichlet convolutions appear in 
\cite[\S 2.14; \S 3.10; \S 3.12; \cf \S 4.9, p.\ 95]{APOSTOLANUMT}. 

\begin{proof}[Proof of Theorem \ref{theorem_SummatoryFuncsOfDirCvls}] 
\label{proofOf_theorem_SummatoryFuncsOfDirCvls} 
Let $h,g$ be arithmetic functions such that $g(1) \neq 0$. 
Denote the summatory functions of $h$ and $g$, 
respectively, by $H(x) = \sum_{n \leq x} h(n)$ and $G(x) = \sum_{n \leq x} g(n)$. 
We define $\pi_{g \ast h}(x)$ to be the summatory function of the 
Dirichlet convolution of $g$ with $h$. 
We have that the following formulas hold for all $x \geq 1$: 
\begin{align} 
\notag 
\pi_{g \ast h}(x) & := \sum_{n=1}^{x} \sum_{d|n} g(n) h(n/d) = \sum_{d=1}^x g(d) H\left(\floor{\frac{x}{d}}\right) \\ 
\label{eqn_proof_tag_PigAsthx_ExactSummationFormula_exp_v2} 
     & = \sum_{i=1}^x \left[G\left(\floor{\frac{x}{i}}\right) - G\left(\floor{\frac{x}{i+1}}\right)\right] H(i). 
\end{align} 
The first formula above is well known. The second formula is justified directly using 
summation by parts as\footnote{
     For any arithmetic functions, $u_n,v_n$, 
     with $U_j := u_1+u_2+\cdots+u_j$ for $j \geq 1$, we have that 
     \cite[\S 2.10(ii)]{NISTHB} 
     \[
     \sum_{j=1}^{n-1} u_j \cdot v_j = U_{n-1} v_n + 
          \sum_{j=1}^{n-1} U_j \left(v_j - v_{j+1}\right), n \geq 2. 
     \]
} 
\begin{align*} 
\pi_{g \ast h}(x) & = \sum_{d=1}^x h(d) G\left(\floor{\frac{x}{d}}\right) \\ 
     & = \sum_{i \leq x} \left(\sum_{j \leq i} h(j)\right) \times 
     \left[G\left(\floor{\frac{x}{i}}\right) - 
     G\left(\floor{\frac{x}{i+1}}\right)\right]. 
\end{align*} 
We next form the invertible matrix of coefficients associated with this linear system defining $H(j)$ for all 
$1 \leq j \leq x$ in \eqref{eqn_proof_tag_PigAsthx_ExactSummationFormula_exp_v2} by defining 
\[
g_{x,j} := G\left(\floor{\frac{x}{j}}\right) - G\left(\floor{\frac{x}{j+1}}\right) \equiv G_{x,j} - G_{x,j+1}, 
\] 
where 
\[
G_{x,j} := G\left(\Floor{x}{j}\right), 1 \leq j \leq x. 
\]
Since $g_{x,x} = G(1) = g(1)$ and $g_{x,j} = 0$ for all $j > x$, 
the matrix we must invert in this problem is lower triangular with a non-zero 
constant on its diagonals, and is hence invertible. 
Moreover, if we let $\hat{G} := (G_{x,j})$, then this matrix is 
expressed by applying an invertible shift operation as 
\[
(g_{x,j}) = \hat{G} (I - U^{T}). 
\]
Here, $U$ is a square matrix with sufficiently large finite dimensions 
whose $(i,j)^{th}$ entries are defined by $(U)_{i,j} = \delta_{i+1,j}$ such that 
\[
\left[(I - U^T)^{-1}\right]_{i,j} = \Iverson{j \leq i}. 
\]
Observe that 
\[
\Floor{x}{j} - \Floor{x-1}{j} = \begin{cases} 
     1, & \text{ if $j|x$; } \\ 
     0, & \text{ otherwise. } 
     \end{cases} 
\] 
The previous property implies that 
\begin{equation} 
\label{eqn_proof_tag_FloorFuncDiffsOfSummatoryFuncs_v2} 
G\left(\floor{\frac{x}{j}}\right) - G\left(\floor{\frac{x-1}{j}}\right) = 
     \begin{cases} 
     g\left(\frac{x}{j}\right), & \text{ if $j | x$; } \\ 
     0, & \text{ otherwise. } 
     \end{cases}
\end{equation} 
We use the last property in \eqref{eqn_proof_tag_FloorFuncDiffsOfSummatoryFuncs_v2} 
to shift the matrix $\hat{G}$, and then invert the result to obtain a matrix involving the 
Dirichlet inverse of $g$ in the following form: 
\begin{align*} 
\left[(I-U^{T}) \hat{G}\right]^{-1} & = \left(g\left(\frac{x}{j}\right) \Iverson{j|x}\right)^{-1} = 
     \left(g^{-1}\left(\frac{x}{j}\right) \Iverson{j|x}\right). 
\end{align*} 
Our target matrix in the inversion problem is defined by 
$$(g_{x,j}) = (I-U^{T}) \left(g\left(\frac{x}{j}\right) \Iverson{j|x}\right) (I-U^{T})^{-1}.$$
We can express its inverse by a similarity transformation conjugated by shift operators as follows: 
\begin{align*} 
(g_{x,j})^{-1} & = (I-U^{T})^{-1} \left(g^{-1}\left(\frac{x}{j}\right) \Iverson{j|x}\right) (I-U^{T}) \\ 
     & = \left(\sum_{k=1}^{\floor{\frac{x}{j}}} g^{-1}(k)\right) (I-U^{T}) \\ 
     & = \left(\sum_{k=1}^{\floor{\frac{x}{j}}} g^{-1}(k) - \sum_{k=1}^{\floor{\frac{x}{j+1}}} g^{-1}(k)\right). 
\end{align*} 
Hence, the summatory function $H(x)$ is given exactly for any $x \geq 1$ 
by a vector product with the inverse matrix from the previous equation in the next form. 
\begin{align*} 
H(x) & = \sum_{k=1}^x g_{x,k}^{-1} \cdot \pi_{g \ast h}(k) 
     = \sum_{k=1}^x \left(\sum_{j=\floor{\frac{x}{k+1}}+1}^{\floor{\frac{x}{k}}} g^{-1}(j)\right) 
     \cdot \pi_{g \ast h}(k) 
\end{align*} 
We can prove an inversion formula providing the coefficients of $G^{-1}(i)$ for $1 \leq i \leq x$ given 
by the last equation by adapting our argument to prove 
\eqref{eqn_proof_tag_PigAsthx_ExactSummationFormula_exp_v2} above. 
This leads to the identity that 
\[
H(x) = \sum_{k=1}^{x} g^{-1}(x) \pi_{g \ast h}\left(\Floor{x}{k}\right). 
     \qedhere 
\]
\end{proof} 

\subsection{Proving the characteristic signedness property of $g^{-1}(n)$} 

Let $\chi_{\mathbb{P}}$ denote the characteristic function of the primes, 
$\varepsilon(n) = \delta_{n,1}$ be the multiplicative identity with respect to Dirichlet convolution, 
and denote by $\omega(n)$ the strongly additive function that counts the number of 
distinct prime factors of $n$. Then we can easily prove using DGFs that 
\begin{equation}
\label{eqn_AntiqueDivisorSumIdent} 
\chi_{\mathbb{P}} + \varepsilon = (\omega + 1) \ast \mu. 
\end{equation} 
When combined with Corollary \ref{cor_CvlGAstMu} 
this convolution identity yields the exact 
formula for $M(x)$ stated in \eqref{eqn_Mx_gInvnPixk_formula} of 
Corollary \ref{cor_Mx_gInvnPixk_formula}. 

\begin{prop}[The signedness property of $g^{-1}(n)$]
\label{prop_SignageDirInvsOfPosBddArithmeticFuncs_v1} 
Let the operator 
$\operatorname{sgn}(h(n)) = \frac{h(n)}{|h(n)| + \Iverson{h(n) = 0}} \in \{0, \pm 1\}$ denote the sign 
of the arithmetic function $h$ at integers $n \geq 1$. 
For the Dirichlet invertible function, $g(n) := \omega(n) + 1$, 
we have that $\operatorname{sgn}(g^{-1}(n)) = \lambda(n)$ for all $n \geq 1$. 
\NBRef{A02-2020-04-26}
\end{prop} 
\begin{proof} 
The function $D_f(s) := \sum_{n \geq 1} f(n) n^{-s}$ denotes the 
\emph{Dirichlet generating function} (DGF) of any 
arithmetic function $f(n)$ which is convergent for all $s \in \mathbb{C}$ satisfying 
$\Re(s) > \sigma_f$ for $\sigma_f$ the abcissa of convergence of the series. 
Recall that $D_1(s) = \zeta(s)$, $D_{\mu}(s) = 1 / \zeta(s)$ and $D_{\omega}(s) = P(s) \zeta(s)$ for 
$\Re(s) > 1$. 
Then by \eqref{eqn_AntiqueDivisorSumIdent} and the known property that the DGF of $f^{-1}(n)$ is 
the reciprocal of the DGF of any arithmetic function $f$ such that $f(1) \neq 0$, 
we have for all $\Re(s) > 1$ that 
\begin{align} 
\label{eqn_DGF_of_gInvn} 
D_{(\omega+1)^{-1}}(s) = \frac{1}{(P(s)+1) \zeta(s)}. 
\end{align} 
It follows that $(\omega + 1)^{-1}(n) = (h^{-1} \ast \mu)(n)$ when we take 
$h := \chi_{\mathbb{P}} + \varepsilon$. 
We first show that $\operatorname{sgn}(h^{-1}) = \lambda$. 
This observation implies 
that $\operatorname{sgn}(h^{-1} \ast \mu) = \lambda$. The remainder of the proof fills in the 
precise details needed to make our claims rigorous. 

By the recurrence relation that defines the Dirichlet inverse function of any 
arithmetic function $h$ such that $h(1) = 1$, we have that \cite[\S 2.7]{APOSTOLANUMT} 
\begin{equation} 
\label{eqn_proof_tag_hInvn_ExactRecFormula_v1}
h^{-1}(n) = \begin{cases} 
            1, & n = 1; \\ 
            -\sum\limits_{\substack{d|n \\ d>1}} h(d) h^{-1}(n/d), & n \geq 2. 
            \end{cases} 
\end{equation} 
For $n \geq 2$, the summands in \eqref{eqn_proof_tag_hInvn_ExactRecFormula_v1} 
can be simply indexed over the primes $p|n$ given our definition of $h$ from above. 
This observation yields that we can inductively 
unfold these sums into nested divisor sums provided the depth of the 
expanded divisor sums does not exceed the 
capacity to index summations over the primes dividing $n$. Namely, notice that for $n \geq 2$ 
\begin{align*} 
h^{-1}(n) & = -\sum_{p|n} h^{-1}\left(\frac{n}{p}\right), && \text{\ if\ } \Omega(n) \geq 1 \\ 
     & = \sum_{p_1|n} \sum_{p_2|\frac{n}{p_1}} h^{-1}\left(\frac{n}{p_1p_2}\right), && \text{\ if\ } \Omega(n) \geq 2 \\ 
     & = -\sum_{p_1|n} \sum_{p_2|\frac{n}{p_1}} \sum_{p_3|\frac{n}{p_1p_2}} h^{-1}\left(\frac{n}{p_1p_2p_3}\right), 
     && \text{\ if\ } \Omega(n) \geq 3. 
\end{align*} 
Then by induction with $h^{-1}(1) = h(1) = 1$, we expand these 
nested divisor sums as above to the maximal possible depth as 
\begin{equation} 
\label{eqn_proof_tag_hInvn_ExactNestedSumFormula_v2} 
\lambda(n) \cdot h^{-1}(n) = \sum_{p_1|n} \sum_{p_2|\frac{n}{p_1}} \times \cdots \times 
     \sum_{p_{\Omega(n)}|\frac{n}{p_1p_2 \cdots p_{\Omega(n)-1}}} 1, n \geq 2. 
\end{equation} 
In fact, by a combinatorial argument we recover exactly that 
\begin{equation} 
\label{eqn_proof_tag_hInvn_ExactNestedSumFormula_CombInterpetIdent_v3} 
h^{-1}(n) = \lambda(n) \frac{(\alpha_1+\cdots+\alpha_{\omega(n)})!}{ 
     \alpha_1! \alpha_2! \cdots \alpha_{\omega(n)}!} = 
     \lambda(n) \binom{\Omega(n)}{\alpha_1,\alpha_2,\ldots,\alpha_{\omega(n)}}. 
\end{equation} 
These expansions imply that the following property holds for all $n \geq 1$: 
\begin{equation} 
\notag 
\operatorname{sgn}(h^{-1}(n)) = \lambda(n). 
\end{equation} 
Since $\lambda$ is completely multiplicative we have that 
$\lambda\left(\frac{n}{d}\right) \lambda(d) = \lambda(n)$ for all 
$d|n$ and $n \geq 1$. We also know that $\mu(n) = \lambda(n)$ whenever $n$ is squarefree, 
so that we obtain
\[
g^{-1}(n) = (h^{-1} \ast \mu)(n) = \lambda(n) \times \sum_{d|n} \mu^2\left(\frac{n}{d}\right) |h^{-1}(n)|, n \geq 1. 
     \qedhere 
\]
\end{proof} 

\subsection{Statements of known limiting asymptotics} 
\label{subSection_OtherFactsAndResults} 

\begin{theorem}[Mertens theorem]
\label{theorem_Mertens_theorem} 
For all $x \geq 2$ we have that 
\[
P_1(x) := \sum_{p \leq x} \frac{1}{p} = \log\log x + B + o(1), 
     \mathrm{\ as\ } x \rightarrow \infty, 
\]
where 
$B \approx 0.2614972128476427837554$ 
is an absolute constant\footnote{ 
     Precisely, we have that the \emph{Mertens constant} is defined by 
     \cite[\seqnum{A077761}]{OEIS} 
     \[
     B = \gamma + \sum_{m \geq 2} \frac{\mu(m)}{m} \log\left[\zeta(m)\right]. 
     \]
}.
\end{theorem} 

\begin{cor}[Product form of Mertens theorem] 
\label{lemma_Gz_productTermV2} 
We have that for all sufficiently large $x \gg 2$ 
\[
\prod_{p \leq x} \left(1 - \frac{1}{p}\right) = \frac{e^{-\gamma}}{\log x}\left( 
     1 + o(1)\right), \mathrm{\ as\ } x \rightarrow \infty, 
\]
where the notation for the absolute constant $0 < B < 1$ coincides with the definition of 
Mertens constant from Theorem \ref{theorem_Mertens_theorem}. 
Hence, for any real $z \geq 0$ we obtain that 
\[
\prod_{p \leq x} \left(1 - \frac{1}{p}\right)^{z} \sim 
     \frac{e^{-\gamma z}}{(\log x)^{z}}, \mathrm{\ as\ } x \rightarrow \infty. 
\]
\end{cor} 

Proofs of Theorem \ref{theorem_Mertens_theorem} and 
Corollary \ref{lemma_Gz_productTermV2} are given in 
\cite[\S 22.7; \S 22.8]{HARDYWRIGHT}. 
We have a related analog of Corollary \ref{lemma_Gz_productTermV2} 
that is justified using the Euler product representation for the 
Riemann zeta function: 
\begin{align*} 
\prod_{p \leq x} \left(1 + \frac{1}{p}\right) & = \prod_{p \leq x} 
     \frac{\left(1 - p^{-2}\right)}{\left(1 - p^{-1}\right)} 
     = \zeta(2) e^{\gamma} (\log x) (1 + o(1)), 
     \mathrm{\ as\ } x \rightarrow \infty. 
\end{align*} 

\begin{facts}[Exponential integrals and the incomplete gamma function] 
\label{facts_ExpIntIncGammaFuncs} 
\begin{subequations}
Two variants of the \emph{exponential integral function} are defined by the 
integral next representations \cite[\S 8.19]{NISTHB}. 
\begin{align*} 
\operatorname{Ei}(x) & := \int_{-x}^{\infty} \frac{e^{-t}}{t} dt, x \in \mathbb{R} \\ 
E_1(z) & := \int_1^{\infty} \frac{e^{-tz}}{t} dt, \Re(z) \geq 0 
\end{align*} 
These functions are related by $\operatorname{Ei}(-kz) = -E_1(kz)$ for real $k, z > 0$. 
We have the following inequalities providing 
quasi-polynomial upper and lower bounds on $\operatorname{Ei}(\pm x)$ for all real $x > 0$: 
\begin{align}
\gamma + \log x - x \leq & \operatorname{Ei}(-x) \leq \gamma + \log x - x + \frac{x^2}{4}, \\ 
\notag 
1 + \gamma + \log x -\frac{3}{4} x \leq & \operatorname{Ei}(x) \phantom{-} \leq 
     1 + \gamma + \log x -\frac{3}{4} x + \frac{11}{36} x^2. 
\end{align}
The (upper) \emph{incomplete gamma function} is defined by \cite[\S 8.4]{NISTHB} 
\[
\Gamma(s, x) = \int_{x}^{\infty} t^{s-1} e^{-t} dt, \Re(s) > 0. 
\]
The following properties of $\Gamma(s, x)$ hold: 
\begin{align} 
\label{eqn_IncompleteGamma_PropA} 
\Gamma(s, x) & = (s-1)! \cdot e^{-x} \times \sum_{k=0}^{s-1} \frac{x^k}{k!}, s \in \mathbb{Z}^{+}, x > 0, \\ 
\label{eqn_IncompleteGamma_PropB} 
\Gamma(s, x) & \sim x^{s-1} \cdot e^{-x}, s > 0, \mathrm{\ as\ } x \rightarrow \infty. 
\end{align}
\end{subequations}
\end{facts} 

\newpage 
\section{Components to the asymptotic analysis of lower bounds for 
         sums of arithmetic functions weighted by $\lambda(n)$} 
\label{Section_MVCh7_GzBounds} 

\subsection{A discussion of the results proved by Montgomery and Vaughan} 
\label{subSection_MVPrereqResultStmts} 

\begin{remark}[Intuition and constructions in Theorem \ref{theorem_HatPi_ExtInTermsOfGz}] 
\label{remark_intuitionConstrIn_theorem_HatPi_ExtInTermsOfGz} 
For $|z| < 2$ and $\Re(s) > 1$, let 
\begin{equation} 
\label{eqn_IntuitionMVThm_FszFuncDef_v1} 
F(s, z) := \prod_{p} \left(1 - \frac{z}{p^s}\right)^{-1} \left(1 - \frac{1}{p^s}\right)^{z}, 
\end{equation} 
and define the DGF coefficients, $a_z(n)$ for $n \geq 1$, by the product 
\[
\zeta(s)^{z} \cdot F(s, z) := \sum_{n \geq 1} \frac{a_z(n)}{n^s}, \Re(s) > 1. 
\]
Suppose that $A_z(x) := \sum_{n \leq x} a_z(n)$ for $x \geq 1$. Then we obtain the next 
generating function like identity in $z$ enumerating the $\widehat{\pi}_k(x)$ for 
$1 \leq k \leq \log\log x$ \footnote{ 
     In fact, for any additive arithmetic function $a(n)$, 
     characterized by the property that 
     $a(n) = \sum_{p^{\alpha} || n} a(p^{\alpha})$ for all $n \geq 2$, we have that 
     \cite[\cf \S 1.7]{IWANIEC-KOWALSKI} 
     \[
     \prod_p \left( 
          1 - \sum_{m \geq 1} \frac{z^{a(p^m)}}{p^{ms}}\right)^{-1} = 
          \sum_{n \geq 1} \frac{z^{a(n)}}{n^s}, \Re(s) > 1. 
     \]
}
\begin{equation} 
\label{eqn_remark_MV_AzxCoeffFormlaIntegral_v1} 
A_z(x) = \sum_{n \leq x} z^{\Omega(n)} = \sum_{k \geq 0} \widehat{\pi}_k(x) z^k 
\end{equation} 
Thus for $r < 2$, by Cauchy's integral formula we have 
\[
\widehat{\pi}_k(x) = \frac{1}{2\pi\imath} \int_{|z|=r} \frac{A_z(x)}{z^{k+1}} dz. 
\]
Selecting $r := \frac{k-1}{\log\log x}$ for $1 \leq k < 2\log\log x$ 
leads to the uniform asymptotic formulas for $\widehat{\pi}_k(x)$ given in 
Theorem \ref{theorem_HatPi_ExtInTermsOfGz}. 
Montgomery and Vaughan then consider individual analysis of the main and error 
terms for $A_z(x)$ to prove that 
\[
\widehat{\pi}_k(x) = \mathcal{G}\left(\frac{k-1}{\log\log x}\right) \frac{x}{\log x} \cdot 
     \frac{(\log\log x)^{k-1}}{(k-1)!} \left[1 + O\left(\frac{k}{(\log\log x)^2}\right)\right]. 
\]
We will require estimates of $A_{-z}(x)$ from below to form summatory functions 
that weight the terms of $\lambda(n)$ in our new formulas derived in the next sections. 
\end{remark} 

\subsection{New uniform asymptotics based on refinements of Theorem \ref{theorem_HatPi_ExtInTermsOfGz}} 
\label{subSection_PartialPrimeProducts_Proofs} 

\begin{prop} 
\label{cor_PartialSumsOfReciprocalsOfPrimePowers} 
For real $s \geq 1$, let 
\[
P_s(x) := \sum_{p \leq x} p^{-s}, x \geq 2. 
\]
When $s := 1$, we have the asymptotic formula from Mertens theorem 
(see Theorem \ref{theorem_Mertens_theorem}). 
For all integers $s \geq 2$ 
there is are absolutely defined quasi-polynomial bounding functions 
$\gamma_0(s, x)$ and $\gamma_1(s, x)$ in $s,x$ such that 
\[
\gamma_0(s, x) + o(1) \leq P_s(x) \leq \gamma_1(s, x) + o(1), \mathrm{\ as\ } x \rightarrow \infty. 
\] 
It suffices to define the bounds in the previous equation by the functions 
\begin{align*} 
\gamma_0(s, x) & = s\log\left(\frac{\log x}{\log 2}\right) - 
     s(s-1) \log\left(\frac{x}{2}\right) - 
     \frac{1}{4} s(s-1)^2 \log^2(2) \\ 
\gamma_1(s, x) & = s\log\left(\frac{\log x}{\log 2}\right) - s(s-1) \log\left(\frac{x}{2}\right) + 
     \frac{1}{4} s(s-1)^2 \log^2(x). 
\end{align*}
\end{prop} 
\NBRef{A05-2020-04-26} 
\begin{proof} 
Let $s > 1$ be real-valued. 
By Abel summation with the summatory function 
$A(x) = \pi(x) \sim \frac{x}{\log x}$, and where 
our target function smooth function is $f(t) = t^{-s}$ so that 
$f^{\prime}(t) = -s \cdot t^{-(s+1)}$, we obtain that 
\begin{align*} 
P_s(x) & = \frac{1}{x^s \cdot \log x} + s \cdot \int_2^{x} \frac{dt}{t^s \log t} \\ 
     & = \operatorname{Ei}(-(s-1) \log x) - \operatorname{Ei}(-(s-1) \log 2) + o(1), 
     \mathrm{\ as\ } x \rightarrow \infty. 
\end{align*} 
Now using the inequalities in Facts \ref{facts_ExpIntIncGammaFuncs}, we obtain that the 
difference of the exponential integral functions is bounded above and below by 
\begin{align*} 
\frac{P_s(x)}{s} & \geq \log\left(\frac{\log x}{\log 2}\right) - (s-1) \log\left(\frac{x}{2}\right) - 
     \frac{1}{4} (s-1)^2 \log^2(2) + o(1) \\ 
\frac{P_s(x)}{s} & \leq \log\left(\frac{\log x}{\log 2}\right) - (s-1) \log\left(\frac{x}{2}\right) + 
     \frac{1}{4} (s-1)^2 \log^2(x) + o(1). 
     \qedhere 
\end{align*} 
\end{proof} 

We will first prove the stated form of the lower bound on 
$\mathcal{G}(-z)$ for $z := \frac{k-1}{\log\log x}$. 
Then we will discuss the technical adaptations to Montgomery and Vaughan's proof of 
Theorem \ref{theorem_HatPi_ExtInTermsOfGz} in 
Remark \ref{remark_TechAdjustments_theorem_HatPi_ExtInTermsOfGz_TO_GFs_SymmFuncs_SumsOfRecipOfPowsOfPrimes} 
to justify the new asymptotic lower bounds on $\widehat{\pi}_k(x)$ that hold uniformly for all 
$1 \leq k \leq \log\log x$. 

\NBRef{A06-2020-04-26} 
\begin{proof}[Proof of Theorem \ref{theorem_GFs_SymmFuncs_SumsOfRecipOfPowsOfPrimes}] 
\label{proofOf_theorem_GFs_SymmFuncs_SumsOfRecipOfPowsOfPrimes} 
For $0 \leq z < 2$ and integers $x \geq 2$, 
the right-hand-side of the following product is finite. 
\[
\widehat{P}(z, x) := \prod_{p \leq x} \left(1 - \frac{z}{p}\right)^{-1}. 
\]
For fixed, finite $x \geq 2$ let 
\[
\mathbb{P}_x := \left\{n \geq 1: \mathrm{ all\ prime\ divisors\ } 
     p|n \mathrm{\ satisfy\ } p \leq x\right\}. 
\]
Then we can see that 
\begin{equation} 
\label{eqn_proof_tag_PHatFiniteTruncProdFactorOfGz_v2} 
\prod_{p \leq x} \left(1 - \frac{z}{p^s}\right)^{-1} = \sum_{n \in \mathbb{P}_x} 
     \frac{z^{\Omega(n)}}{n^s}, x \geq 2. 
\end{equation} 
By extending the argument in the proof given in 
\cite[\S 7.4]{MV}, we have that the formulas 
\[
A_{-z}(x) := \sum_{n \leq x} \lambda(n) z^{\Omega(n)} = 
     \sum_{k \geq 0} \widehat{\pi}_k(x) (-z)^k, 
\] 
If we let $a_n(z, x)$ be defined by the DGF 
\[
\widehat{P}(z, x) := \sum_{n \geq 1} \frac{a_n(z, x)}{n^s}, 
\]
then we show that 
\[
\sum_{n \leq x} a_n(-z, x) = \sum_{n \leq x} \lambda(n) z^{\Omega(n)} = 
     \sum_{k=0}^{\log_2(x)} \widehat{\pi}_k(x) (-z)^k + 
     \sum_{k > \log_2(x)} e_k(x) (-z)^{k}. 
\]
This assertion if correct since the products of all non-negative integral powers of the 
primes $p \leq x$ generate the integers $\{1 \leq n \leq x\}$ as a subset. 
Thus we capture all of the relevant terms needed to express 
$(-1)^{k} \cdot \widehat{\pi}_k(x)$ 
via the Cauchy integral formula representation over $A_{-z}(x)$ by 
replacing the corresponding infinite product terms with 
$\widehat{P}(-z, x)$ in the definition of $\mathcal{G}(-z)$. 

Now we must argue that 
\[
\mathcal{G}(-z) \gg \prod_{p \leq x} \left(1 + \frac{z}{p}\right)^{-1} 
     \left(1 - \frac{1}{p}\right)^{-z}, 0 \leq z < 1, x \geq 2. 
\]
For $0 \leq z < 1$ and $x \geq 2$, we see that 
\begin{align*} 
\mathcal{G}(-z) & = \exp\left(-\sum_p \left[\log\left(1 + \frac{z}{p}\right) + 
     \log\left(1 - \frac{1}{p}\right)\right]\right) \\ 
     & \gg 
     \exp\left(-z \times \sum_{p > x} \left[
     \log\left(1 - \frac{1}{p}\right) + \frac{1}{p}\right] - 
     \sum_{p \leq x} \left[\log\left(1 + \frac{z}{p}\right) + 
     \log\left(1 - \frac{1}{p}\right)\right]\right) \\ 
     & = \widehat{P}(-z, x) \times \exp\left(-z(B+o(1))\right) 
     \gg_z \widehat{P}(-z, x), \mathrm{\ as\ } x \rightarrow \infty. 
\end{align*} 
Next, we have for all integers $0 \leq k \leq m < \infty$, and any sequence 
$\{f(n)\}_{n \geq 1}$ with sufficiently bounded partial power sums, that 
\cite[\S 2]{MACDONALD-SYMFUNCS} 
\begin{equation} 
\label{eqn_pf_tag_hSymmPolysGF} 
[z^k] \prod_{1 \leq i \leq m} (1-f(i) z)^{-1} = [z^k] \exp\left(\sum_{j \geq 1} 
     \left(\sum_{i=1}^m f(i)^j\right) \frac{z^j}{j}\right), |z| < 1. 
\end{equation} 
In our case we have that $f(i)$ denotes the reciprocal of the 
$i^{th}$ prime in the generating function expansion of 
\eqref{eqn_pf_tag_hSymmPolysGF}. 
It follows from Proposition \ref{cor_PartialSumsOfReciprocalsOfPrimePowers} that 
for any real $0 \leq z < 1$ we obtain 
\begin{align} 
\notag 
\log\left[\prod_{p \leq x} \left(1+\frac{z}{p}\right)^{-1}\right] & \geq -(B + \log\log x) z + 
     \sum_{j \geq 0} \left[\log\left(\frac{\log x}{\log 2}\right) - 
     (2j+1) \log\left(\frac{x}{2}\right) - (2j+1)^2 \frac{\log^2 2}{4}\right] z^{2j+2} \\ 
\notag 
     & \phantom{\geq -(B + \log\log x) z\ } + 
     \sum_{j \geq 0} \left[\log\left(\frac{\log x}{\log 2}\right) - 
     (2j+2) \log\left(\frac{x}{2}\right) + (2j+2)^2 \frac{\log^2 x}{4}\right] z^{2j+3} \\ 
\notag 
     & = -(B + \log\log x) z + z^2 \times \sum_{j \geq 0} \left[ 
     \log\left(\frac{\log x}{\log 2}\right) - 
     (j+1) \log\left(\frac{x}{2}\right)\right] (-z)^j \\ 
\notag 
     & \phantom{= -(B + \log\log x) z\ } - 
     \frac{z^2}{4} \times \sum_{j \geq 0} \left[\log^2 2 + \log^2 x\right] (j+1)^2 z^j \\ 
\label{eqn_proof_tag_PHatFiniteTruncProdFactorOfGz_v3} 
     & = -(B + \log\log x) z + z^2 \left[ 
     \log\left(\frac{\log x}{\log 2}\right) \frac{1}{1+z} - 
     \log\left(\frac{x}{2}\right) \frac{1}{(1+z)^2}\right] \\ 
\notag 
     & \phantom{= -(B + \log\log x) z\ } + 
     \left(\log^2 2 + \log^2 x\right) \frac{z^2 (1+z)}{4 \cdot (1-z)^3} \\ 
\notag 
     & =: \widehat{\mathcal{B}}(x; z). 
\end{align} 
We adjust the uniform bound parameter $R$ so that 
$$z \equiv z(k, x) = \frac{k-1}{\log\log x} \in \left[0, 1\right),$$ 
whenever $1 \leq k \leq \log\log x$ 
in the notation of Theorem \ref{theorem_HatPi_ExtInTermsOfGz}. 
This implies that $(1+z)^{-1} \in \left(\frac{1}{2}, 1\right]$. 
Then we have from \eqref{eqn_proof_tag_PHatFiniteTruncProdFactorOfGz_v3} that 
\begin{align*} 
\widehat{\mathcal{B}}(x; z) & \gg \left(\frac{\log x}{\log 2}\right)^{\frac{z^2}{2}} \cdot 
     \left(\frac{2}{x}\right)^{\frac{1}{4}} \cdot \exp\left( 
     \frac{z^2 (1+z)}{4 \cdot (1-z)^3} \cdot \log^2 x\right) \\ 
     & \gg \frac{(\log x)^{1/2}}{x^{1/4}}. 
\end{align*} 
In summary, we have arrived at a proof that 
as $x \rightarrow \infty$
\begin{align} 
\label{eqn_proof_tag_simpl_v1} 
\frac{e^{\gamma z}}{(\log x)^{-z}} \times \exp\left(\widehat{\mathcal{B}}(u, x; z)\right) & \gg 
     \frac{(\log x)^{1/2}}{x^{1/4}}. 
\end{align} 
Finally, to finish our proof of the new form of the lower bound on $\mathcal{G}(-z)$, 
we need to bound the reciprocal factor of $\Gamma(1-z)$. 
Since $z \equiv z(k, x) = \frac{k-1}{\log\log x}$ and 
$k \in [1, \log\log x]$, or again with $z \in [0, 1)$, 
we obtain for minimal $k$ and all large enough $x \gg 1$ that 
$\Gamma(1-z) = \Gamma(1) = 1$, and for $k$ towards the upper range of 
its interval that 
\[
\Gamma(1-z) \approx \Gamma\left(\frac{1}{\log\log x}\right) = 
     \frac{1}{\log\log x} \Gamma\left(1 + \frac{1}{\log\log x}\right) 
     \approx \frac{1}{\log\log x}. 
     \qedhere 
\]
\end{proof} 

\begin{remark}[Technical adjustments in the proof of Theorem \ref{theorem_GFs_SymmFuncs_SumsOfRecipOfPowsOfPrimes}] 
\label{remark_TechAdjustments_theorem_HatPi_ExtInTermsOfGz_TO_GFs_SymmFuncs_SumsOfRecipOfPowsOfPrimes} 
We now discuss the differences between our construction and that in 
the technical proof of Theorem \ref{theorem_HatPi_ExtInTermsOfGz} 
in the reference when we bound $\mathcal{G}(-z)$ from below as in 
Theorem \ref{theorem_GFs_SymmFuncs_SumsOfRecipOfPowsOfPrimes}. 
The reference proves that for real $0 \leq z < 2$ 
\begin{equation} 
\label{eqn_MV_Azx_formula} 
A_{-z}(x) = -\frac{z F(1, -z)}{\Gamma(1-z)} \cdot x (\log x)^{-(z+1)} + 
     O\left(x (\log x)^{-\Re(z) - 2}\right). 
\end{equation}
Recall that for $r < 2$ we have by Cauchy's integral formula that 
\begin{equation} 
\label{eqn_MV7.61_CIF} 
(-1)^{k} \widehat{\pi}_k(x) = \frac{1}{2\pi\imath} \int_{|z|=r} 
     \frac{A_{-z}(x)}{z^{k+1}} dz. 
\end{equation} 
We first claim that uniformly for large $x$ and $1 \leq k \leq \log\log x$ we have 
\begin{equation} 
\label{eqn_proof_tag_HatPikx_BoundForGmz_v1} 
\widehat{\pi}_k(x) = \mathcal{G}\left(\frac{1-k}{\log\log x}\right) \times 
     \frac{x (\log\log x)^{k-1}}{(\log x) (k-1)!} 
     \left[1 + O\left(\frac{k}{(\log\log x)^3}\right)\right]. 
\end{equation} 
Then since we have proved in Theorem \ref{theorem_HatPi_ExtInTermsOfGz} 
above that 
\[
\mathcal{G}\left(\frac{1-k}{\log\log x}\right) \gg 
     \frac{2^{1/4} (\log x)^{1/2}}{\sqrt{\log 2} \cdot x^{1/4}} \cdot 
     \frac{(k-1)}{\log\log x}, 
\]
the result in \eqref{eqn_proof_tag_HatPikx_BoundForGmz_v1} implies our 
stated uniform asymptotic bound. Namely, we obtain that 
\[
\widehat{\pi}_k(x) \gg \frac{2^{1/4}}{\sqrt{\log 2}} \cdot 
     \frac{x^{3/4}}{(\log x)^{1/2}} \cdot 
     \frac{(\log\log x)^{k-1}}{(k-1)!} \left[1 + 
     O\left(\frac{k}{(\log\log x)^2}\right)\right]. 
\]
We have to provide analogs to the two separate bounds corresponding to the error and 
main terms of our estimate according to 
\eqref{eqn_MV_Azx_formula} and \eqref{eqn_MV7.61_CIF}. 
The error term estimate is simpler, so we tackle it first in the next argument. 
The second part of our proof establishing the main term in 
\eqref{eqn_proof_tag_HatPikx_BoundForGmz_v1} 
requires us to duplicate and adjust significant parts of the 
fine-tuned reasoning given in the reference. \\ 
\textit{Error Term Bound.} 
To prove that the error term bound holds, we estimate that 
\begin{align} 
\notag 
\left\lvert \frac{1}{2\pi\imath} \int_{|z|=r} 
     \frac{x}{(\log x)^2} \frac{(\log x)^{-\Re(z)}}{z^{k+1}} \right\rvert & \ll 
     x (\log x)^{-(r+2)} r^{-(k+1)} 
     \ll \frac{x}{(\log x)^2} \frac{(\log\log x)^{k+1}}{e^{k-1} (k-1)^{k+1}} \\ 
\notag 
     & \ll \frac{x}{(\log x)^2} \frac{(\log\log x)^{k+1}}{e^{2(k-1)} (k-1)! (k-1)} 
     \ll \frac{x}{(\log x)^{2}} \frac{(\log\log x)^{k+1}}{(k-1)!} \\ 
\label{eqn_proof_tag_ErrorTermBounds_v1} 
     & \ll \frac{x}{\log x} \frac{(\log\log x)^{k-4}}{(k-1)!}. 
\end{align} 
We can calculate that for $0 \leq z < 1$ 
\begin{align*} 
\prod_p \left(1 + \frac{z}{p}\right)^{-1} \left(1 - \frac{1}{p}\right)^{-z} & = 
     \exp\left(-\sum_p \left[\log\left(1 + \frac{z}{p}\right) + z 
     \log\left(1 - \frac{1}{p}\right) \right]\right) \\ 
     & \sim \exp\left(-o(z) \times \sum_p \frac{1}{p^2}\right) \\ 
     & \gg \exp\left(-o(z) \frac{\pi^2}{6}\right) \gg_z 1. 
\end{align*} 
In other words, we have that 
$\mathcal{G}\left(\frac{1-k}{\log\log x}\right) \gg 1$. 
So the error term in \eqref{eqn_proof_tag_ErrorTermBounds_v1} 
is majorized by taking $O\left(\frac{k}{(\log\log x)^3}\right)$ as our 
upper bound. \\ 
\textit{Main Term Bounds.} 
Notice that the main term 
estimate corresponfing to \eqref{eqn_MV_Azx_formula} and \eqref{eqn_MV7.61_CIF} 
is given by $\frac{x}{\log x} I$, where 
\[
I := \frac{(-1)^{k-1}}{2\pi\imath} \int_{|z|=r} G(-z) (\log x)^{-z} z^{-k} dz. 
\]
In particular, we can write $I = I_1 + I_2$ where we define 
\begin{align*} 
I_1 & := \frac{(-1)^{k-1} G(-r)}{2\pi\imath} \int_{|z|=r} (\log x)^{-z} z^{-k} dz \\ 
    & \phantom{:}= \frac{G(-r) (\log\log x)^{k-1}}{(k-1)!} \\ 
I_2 & := \frac{(-1)^{k-1}}{2\pi\imath} \int_{|z|=r} (G(-z) - G(-r)) (\log x)^{-z} z^{-k} dz \\ 
    & \phantom{:}= \frac{(-1)^{k-1}}{2\pi\imath} \int_{|z|=r} (G(-z) - G(-r) + G^{\prime}(-r) (z+r)) 
    (\log x)^{-z} z^{-k} dz. 
\end{align*} 
We have by a power series expansion of $G^{\prime\prime}(-w)$ about $-z$ and integrating 
the resulting series termwise with respect to $w$ that 
\[
\left\lvert G(-z) - G(-r) + G^{\prime}(-r) (z+r) \right\rvert = 
     \left\lvert \int_{-r}^{z} (z+w) G^{\prime\prime}(-w) dw \right\rvert \ll 
     G^{\prime\prime}(-r) \times |z+r|^2 \ll |z+r|^2. 
\] 
Now we parameterize the curve in the contour for $I_2$ by writing 
$z = re^{2\pi\imath t}$ for $t \in [-1/2, 1/2]$. This leads us to the bounds 
\begin{align*} 
|I_2| & = r^{3-k} \times \int_{-1/2}^{1/2} |e^{2\pi\imath t} + 1|^2 \cdot 
     (\log x)^{r e^{2\pi\imath t}} \cdot e^{2\pi\imath t} dt \\ 
     & \ll r^{3-k} \times \int_{-1/2}^{1/2} \sin^2(\pi t) \cdot 
     e^{(1-k) \cos(2\pi t)} dt. 
\end{align*} 
Whenever $|x| \leq 1$, we know that $|\sin x| \leq |x|$. 
We can construct bounds on $-\cos(2\pi t)$ for 
$t \in [-1/2, 1/2]$ by writing $\cos(2x) = 1 - 2\sin^2 x$ for $|x| < 1/2$. 
Then by the alternating Taylor series expansions of the sine function 
\begin{align*} 
1-2\sin^2(2\pi t) & \geq 1 - 2 \left(1 - \frac{\pi t}{3}\right)^2 \geq -1 - \frac{2\pi^2 t^2}{9} 
     \qquad \implies \\ 
-\cos(2\pi t) & \leq 1 + \frac{2\pi^2 t^2}{9} \leq \left(4 + \frac{2\pi^2}{9}\right) t^2 \leq 1 + 3t^2. 
\end{align*} 
So it follows that 
\begin{align*} 
|I_2| & \ll r^{3-k} e^{k-1} \times \left\lvert \int_0^{\infty} t^2 e^{3(k-1) t^2} dt 
     \right\rvert \\ 
     & \ll \frac{r^{3-k} e^{k-1}}{(k-1)^{3/2}} = \frac{(\log\log x)^{k-3} e^{k-1}}{(k-1)^{k-3/2}} \\ 
     & \ll \frac{k \cdot (\log\log x)^{k-3}}{(k-1)!}. 
\end{align*} 
Thus the contribution from the term $|I_2|$ can then be asborbed into the error term bound 
in \eqref{eqn_proof_tag_HatPikx_BoundForGmz_v1}. 
\end{remark} 

\subsection{The distribution of exceptional values of $\Omega(n)$} 

The next theorems reproduced from \cite[\S 7.4]{MV} characterize the relative 
scarcity of the distribution of the $\Omega(n)$ for $n \leq x$ such that 
$\Omega(n) > \log\log x$. The tendency of this canonical completely additive 
function to not deviate substantially from its average order is an extraordinary 
property that allows us to prove asymptotic relations on summatory functions that 
are weighted by its parity without having to account for significant local 
oscillations when we average over a large interval. 

\begin{theorem}[Upper bounds on exceptional values of $\Omega(n)$ for large $n$] 
\label{theorem_MV_Thm7.20-init_stmt} 
Let 
\begin{align*} 
A(x, r) & := \#\left\{n \leq x: \Omega(n) \leq r \cdot \log\log x\right\}, \\ 
B(x, r) & := \#\left\{n \leq x: \Omega(n) \geq r \cdot \log\log x\right\}. 
\end{align*} 
If $0 < r \leq 1$ and $x \geq 2$, then 
\[
A(x, r) \ll x (\log x)^{r-1 - r\log r}, \text{ \ as\ } x \rightarrow \infty. 
\]
If $1 \leq r \leq R < 2$ and $x \geq 2$, then 
\[
B(x, r) \ll_R x \cdot (\log x)^{r-1-r \log r}, \text{ \ as\ } x \rightarrow \infty. 
\]
\end{theorem} 

Theorem \ref{theorem_MV_Thm7.21-init_stmt} is an analog to the 
celebrated Erd\"os-Kac theorem typically stated for the 
normally distributed values of the scaled-shifted $\omega(n)$ function over $n \leq x$ as 
$x \rightarrow \infty$. 

\begin{theorem}[Exact bounds on exceptional values of $\Omega(n)$ for large $n$] 
\label{theorem_MV_Thm7.21-init_stmt} 
We have that as $x \rightarrow \infty$ 
\[
\#\left\{3 \leq n \leq x: \Omega(n) - \log\log n \leq 0\right\} = 
     \frac{x}{2} + O\left(\frac{x}{\sqrt{\log\log x}}\right). 
\]
\end{theorem} 

\begin{remark} 
The key interpretation we need to take away from the statements 
of Theorem \ref{theorem_MV_Thm7.20-init_stmt} and 
Theorem \ref{theorem_MV_Thm7.21-init_stmt} 
is the result proved in the next corollary. 
The role of the parameter $R$ involved in stating the previous theorem 
is a critical bound as the scalar factor in the upper bound on $k \leq R\log\log x$ in 
Theorem \ref{theorem_HatPi_ExtInTermsOfGz} up to which our uniform bounds given by 
Theorem \ref{theorem_GFs_SymmFuncs_SumsOfRecipOfPowsOfPrimes} hold. 
In contrast, for $n \geq 2$ we can actually 
have contributions from values distributed throughout the range $1 \leq \Omega(n) \leq \log_2(n)$ 
infinitely often. 
It is then crucial that we can show that the main term in the asymptotic formulas we obtain 
for these summatory functions is captured by summing only over the truncated range of 
$k \in [1, \log\log x]$ where the uniform bounds hold. 
\end{remark} 

\begin{cor} 
\label{theorem_MV_Thm7.20} 
Using the notation for $A(x, r)$ and $B(x, r)$ from 
Theorem \ref{theorem_MV_Thm7.20-init_stmt}, 
we have that for $x \geq 2$ and $\delta > 0$, 
\[
o(1) \leq \frac{B(x, 1+\delta)}{A(x, 1)} \ll 2, 
     \mathrm{\ as\ } \delta \rightarrow 0^{+}, x \rightarrow \infty. 
\]
\end{cor} 
\begin{proof} 
The lower bound stated above is clear. To show that the asymptotic 
upper bound is correct, we compute using Theorem \ref{theorem_MV_Thm7.20-init_stmt} and 
Theorem \ref{theorem_MV_Thm7.21-init_stmt} that 
\begin{align*} 
\frac{B(x, 1+\delta)}{A(x, 1)} & \ll 
     \frac{x \cdot (\log x)^{\delta - \delta\log(1+\delta)}}{ 
     O(1) + \frac{x}{2} + 
     O\left(\frac{x}{\sqrt{\log\log x}}\right)} 
     \sim 
     o_{\delta}(1),  
\end{align*} 
as $x \rightarrow \infty$. Notice that since $\mathbb{E}[\Omega(n)] = \log\log n + B$, with $0 < B < 1$ the 
absolute constant from Mertens theorem, 
when we denote the range of $k > \log\log x$ as holding in the form of 
$k > (1 + \delta) \log\log x$ for $\delta > 0$ at large $x$, we can assume that 
$\delta \rightarrow 0^{+}$ as $x \rightarrow \infty$. 
In particular, this holds since $k > \log\log x$ implies that 
\[
\floor{\log\log x} + 1 \geq (1 + \delta) \log\log x \quad\implies\quad 
     \delta \leq \frac{1 + \left\{\log\log x\right\}}{\log\log x} = o(1), 
     \mathrm{\ as\ } x \rightarrow \infty. 
\] 
The key consequence is that $B(x, 1 + \delta)$ is at most a bounded constant multiple of 
$A(x, 1)$ for all large $x$. 
\end{proof} 

\newpage
\section{Average case analysis of bounds on the Dirichlet inverse functions, $g^{-1}(n)$} 
\label{Section_InvFunc_PreciseExpsAndAsymptotics} 

The pages of tabular data given as Table \ref{table_conjecture_Mertens_ginvSeq_approx_values} 
in the appendix section (refer to 
page \pageref{table_conjecture_Mertens_ginvSeq_approx_values}) are intended to 
provide clear insight into why we arrived at the approximations to 
$g^{-1}(n)$ proved in this section. The table provides illustrative 
numerical data by examining the approximate behavior 
at hand for the cases of $1 \leq n \leq 500$ with \emph{Mathematica}. 

\subsection{Definitions and basic properties of component function sequences} 

We define the following auxiliary coefficient sequence for integers $n \geq 1, k \geq 0$: 
\begin{align} 
\label{eqn_CknFuncDef_v2} 
C_k(n) := \begin{cases} 
     \varepsilon(n), & \text{ if $k = 0$; } \\ 
     \sum\limits_{d|n} \omega(d) C_{k-1}(n/d), & \text{ if $k \geq 1$. } 
     \end{cases} 
\end{align} 
By recursively expanding the definition of $C_k(n)$ 
at any fixed $n \geq 2$, we see that 
we can form a chain of at most $\Omega(n)$ iterated (or nested) divisor sums by 
unfolding the definition of \eqref{eqn_CknFuncDef_v2} inductively. 
By the same argument, we see that at fixed $n$, the function 
$C_k(n)$ is seen to be non-zero only for positive integers 
$k \leq \Omega(n)$ whenever $n \geq 2$. 
A sequence of relevant signed semi-diagonals of the functions $C_k(n)$ begins as 
\cite[\seqnum{A008480}]{OEIS} 
\[
\{\lambda(n) \cdot C_{\Omega(n)}(n) \}_{n \geq 1} \mapsto \{
     1, -1, -1, 1, -1, 2, -1, -1, 1, 2, -1, -3, -1, 2, 2, 1, -1, -3, -1, \
     -3, 2, 2, -1, 4, 1, 2, \ldots \}. 
\]

\begin{example}[Special cases of the functions $C_k(n)$ for small $k$] 
\label{example_SpCase_Ckn} 
We cite the following special cases which are verified by 
explicit computation using \eqref{eqn_CknFuncDef_v2} 
\cite[\seqnum{A066922}]{OEIS}\footnote{ 
     For all $n,k \geq 2$, we have the following recurrence 
     relation satisfied by $C_k(n)$ between successive values of $k$: 
     \begin{equation*}
     C_k(n) = \sum_{p|n} \sum_{d\rvert\frac{n}{p^{\nu_p(n)}}} \sum_{i=0}^{\nu_p(n)-1} 
          C_{k-1}\left(dp^i\right), n \geq 1. 
     \end{equation*}
}: 
\NBRef{A07-2020-04-26} 
\begin{align*} 
C_0(n) & = \delta_{n,1} \\ 
C_1(n) & = \omega(n) \\ 
C_2(n) & = d(n) \times \sum_{p|n} \frac{\nu_p(n)}{\nu_p(n)+1} - \gcd\left(\Omega(n), \omega(n)\right). 
\end{align*} 
\end{example} 

The connection between the functions $C_k(n)$ and the inverse sequence $g^{-1}(n)$ is 
clarified precisely in Section \ref{subSection_Relating_CknFuncs_to_gInvn}. Before we can prove explicit 
bounds on $|g^{-1}(n)|$ through its relation to these functions, we will require a perspective 
on the lower asymptotic order of $C_k(n)$ for fixed $k$ when $n$ is large. 

\subsection{Uniform asymptotics of $C_k(n)$ for large all $n$ and fixed $k$} 

The next theorem formally proves a minimal growth rate of the class of functions 
$C_k(n)$ as functions of fixed $k$ and $n \rightarrow \infty$. 
In the statement of the result that follows, we view $k$ as a fixed variable which is 
necessarily bounded in $n$, but is still taken as an independent parameter of $n$. 

\begin{theorem}[Asymptotics of the functions $C_k(n)$] 
\label{theorem_Ckn_GeneralAsymptoticsForms} 
For $k := 0$, we have by definition that $C_0(n) = \delta_{n,1}$. 
For all sufficiently large $n > 1$ and any fixed $1 \leq k \leq \Omega(n)$ 
taken independently of $n$, 
we obtain that the asymptotic main term for the expected order of 
$C_k(n)$ is bounded uniformly from below as 
\[
\mathbb{E}[C_k(n)] \gg (\log\log n)^{2k-1}, \mathrm{\ as\ }n \rightarrow \infty. 
\]
\end{theorem} 
\NBRef{A08-2020-04-26} 
\begin{proof} 
\label{proofOf_theorem_Ckn_GeneralAsymptoticsForms} 
We prove our bounds by induction on $k$. 
We can see by Example \ref{example_SpCase_Ckn} that $C_1(n)$ 
satsfies the formula we must establish when $k := 1$ since $\mathbb{E}[\omega(n)] = \log\log n$. 
Suppose that $k \geq 2$ and let our inductive assumption provide that for all $1 \leq m < k$ and $n \geq 2$
\[
\mathbb{E}[C_m(n)] \gg (\log\log n)^{2m-1}. 
\] 
For all large $x > e$, we cite that the summatory function of 
$\omega(n)$ satisfies \cite[\S 22.10]{HARDYWRIGHT} 
\[
\sum_{n \leq x} \omega(n) = x \log\log x + Bx + O\left(\frac{x}{\log x}\right). 
\]
Now using the recursive formula we used to define the sequences of $C_k(n)$ in 
\eqref{eqn_CknFuncDef_v2}, we have that as $n \rightarrow \infty$ 
\begin{align} 
\notag
\mathbb{E}[C_k(n)] & = \mathbb{E}\left[\sum_{d|n} \omega(n/d) C_{k-1}(d)\right] \\ 
\notag 
     & = \frac{1}{n} \times \sum_{d \leq n} C_{k-1}(d) \times \sum_{r=1}^{\Floor{n}{d}} \omega(r) \\ 
\notag 
     & \sim \sum_{d \leq n} C_{k-1}(d) \left[ 
     \frac{\log\log(n/d) \Iverson{d \leq \frac{n}{e}}}{d} + \frac{B}{d} + o(1)\right] \\ 
\label{eqn_proof_tag_ECkn_sum_steps_v3} 
     & \sim \sum_{d \leq \frac{n}{e}} \left[ 
     \sum_{m < d} \frac{\mathbb{E}[C_{k-1}(m)]}{m} \log\log\left(\frac{n}{m}\right) + 
     B \cdot \mathbb{E}[C_{k-1}(d)] + B \cdot \sum_{m < d} \frac{\mathbb{E}[C_{k-1}(m)]}{m} 
     \right] \\ 
\notag 
     & \gg \sum_{d \leq \frac{n}{e}} \frac{\mathbb{E}[C_{k-1}(m)]}{m} \\ 
\notag 
     & \gg (\log n) (\log\log n)^{2k-3}. 
\end{align} 
In transitioning from the previous step, we have used that 
$(\log n) \gg (\log\log n)^2$ as $n \rightarrow \infty$. We have also used that for large 
$n$ and fixed $m$, by an asymptotic approximation to the incomplete gamma function 
we have that 
\[
\int_{e}^{n} \frac{(\log\log t)^m}{t} dt \sim (\log n) (\log\log n)^{m}, 
     \mathrm{\ as\ } n \rightarrow \infty. 
\]
Hence, the claim follows by mathematical induction for large $n \rightarrow \infty$ whenever 
$1 \leq k \leq \Omega(n)$. 
\end{proof} 

%\begin{remark}[A more accurate main term]
%In step \eqref{eqn_proof_tag_ECkn_sum_steps_v3} of the above proof, we can see that the main term 
%for the expectation of $C_k(n)$ actually corresponds to the double sum 
%\[
%M_k(n) := \sum_{d \leq \frac{n}{e}} 
%     \sum_{m < d} \frac{\mathbb{E}[C_{k-1}(m)]}{m} \log\log\left(\frac{n}{m}\right). 
%\]
%Since
%\[
%\log\log\left(\frac{n}{m}\right) = \log\log n - \frac{\log m}{\log n} + 
%     O\left(\frac{\log^2 m}{\log^2 n}\right), 
%\]
%we can approximate $M_k(n)$ as follows: 
%\begin{align*} 
%M_k(n) & \sim \int_e^n \left(
%     \int_e^t \frac{(\log s)^{2k-4} (\log\log s)^{k-1} (\log\log n)}{s \cdot (2k-4)!} ds 
%     \right) dt \\ 
%     & \gg \int_e^n \frac{(\log t)^{2k-3} (\log\log t)^{k-1} (\log\log n)}{t \cdot (2k-3)!} dt \\ 
%     & \sim \frac{(\log n)^{2k-2} (\log\log n)^k}{(2k-2)!}. 
%\end{align*} 
%This estimate is much closer to the asymptotically dominant behavior of 
%$\mathbb{E}[C_k(n)]$ as $n \rightarrow \infty$. 
%\end{remark}

\subsection{Relating the auxiliary functions $C_k(n)$ to formulas approximating $g^{-1}(n)$} 
\label{subSection_Relating_CknFuncs_to_gInvn} 

\begin{lemma}[An exact formula for $g^{-1}(n)$] 
\label{lemma_AnExactFormulaFor_gInvByMobiusInv_v1} 
For all $n \geq 1$, we have that 
\[
g^{-1}(n) = \sum_{d|n} \mu\left(\frac{n}{d}\right) \lambda(d) C_{\Omega(d)}(d). 
\]
\end{lemma}
\begin{proof} 
We first write out the standard recurrence relation for the Dirichlet inverse of 
$\omega+1$ as 
\begin{align} 
\label{eqn_proof_tag_gInvCvlOne_EQ_omegaCvlgInvCvl_v1} 
g^{-1}(n) & = - \sum_{\substack{d|n \\ d>1}} (\omega(d) + 1) g^{-1}(n/d) 
     \quad\implies\quad 
     (g^{-1} \ast 1)(n) = -(\omega \ast g^{-1})(n). 
\end{align} 
We argue that for $1 \leq m \leq \Omega(n)$, we can inductively expand the 
implication on the right-hand-side of \eqref{eqn_proof_tag_gInvCvlOne_EQ_omegaCvlgInvCvl_v1} 
in the form of $(g^{-1} \ast 1)(n) = F_m(n)$ where 
$F_m(n) := (-1)^{m} \cdot (C_m(-) \ast g^{-1})(n)$, or so that 
\[
F_m(n) = - 
     \begin{cases} 
     \sum\limits_{\substack{d|n \\ d > 1}} F_{m-1}(d) \times \sum\limits_{\substack{r|\frac{n}{d} \\ r > 1}} 
     \omega(r) g^{-1}\left(\frac{n}{dr}\right), & m \geq 2, \\ 
     (\omega \ast g^{-1})(n), & m = 1. 
     \end{cases} 
\]
By repeatedly expanding the right-hand-side of the previous equation, 
we find that for $m := \Omega(n)$ 
\begin{equation} 
\label{eqn_proof_tag_gInvCvlOne_EQ_omegaCvlgInvCvl_v2} 
(g^{-1} \ast 1)(n) = (-1)^{\Omega(n)} C_{\Omega(n)}(n) = \lambda(n) C_{\Omega(n)}(n). 
\end{equation} 
The formula then follows from \eqref{eqn_proof_tag_gInvCvlOne_EQ_omegaCvlgInvCvl_v2} 
by M\"obius inversion applied to each side of the last equation. 
\end{proof} 

\begin{cor} 
\label{cor_AnExactFormulaFor_gInvByMobiusInv_nSqFree_v2} 
For all squarefree integers $n \geq 1$, we have that 
\begin{equation} 
\label{eqn_gInvnSqFreeN_exactDivSum_Formula} 
g^{-1}(n) = \lambda(n) \times \sum_{d|n} C_{\Omega(d)}(d). 
\end{equation} 
\end{cor} 
\begin{proof} 
Since $g^{-1}(1) = 1$, clearly the claim is true for $n = 1$. Suppose that $n \geq 2$ and that 
$n$ is squarefree. Then $n = p_1p_2 \cdots p_{\omega(n)}$ where $p_i$ is prime for all 
$1 \leq i \leq \omega(n)$. Since all divisors of any squarefree $n$ are necessarily also squarefree, 
we can transform the exact divisor sum guaranteed for all $n$ in 
Lemma \ref{lemma_AnExactFormulaFor_gInvByMobiusInv_v1} into a sum that partitions the divisors 
according to the number of distinct prime factors: 
\begin{align*} 
g^{-1}(n) & = \sum_{i=0}^{\omega(n)} \sum_{\substack{d|n \\ \omega(d)=i}} (-1)^{\omega(n) - i} (-1)^{i} \cdot 
     C_{\Omega(d)}(d) \\ 
     & = \lambda(n) \times \sum_{i=0}^{\omega(n)} \sum_{\substack{d|n \\ \omega(d)=i}} C_{\Omega(d)}(d) \\ 
     & = \lambda(n) \times \sum_{d|n} C_{\Omega(d)}(d). 
\end{align*} 
The signed contributions in the first of the previous equations is 
justified by noting that $\lambda(n) = (-1)^{\omega(n)}$ 
whenever $n$ is squarefree, and that for $d \geq 1$
 squarefree we have the correspondence 
 $\omega(d) = k$ $\implies$ $\Omega(d) = k$ for $1 \leq k \leq \log_2(d)$. 
\end{proof} 

Since $C_{\Omega(n)}(n) = |h^{-1}(n)|$ using the notation defined in the the proof of 
Proposition \ref{prop_SignageDirInvsOfPosBddArithmeticFuncs_v1}, we can see that 
$C_{\Omega(n)}(n) = (\omega(n))!$ for squarefree $n \geq 1$. 
A proof of part (C) of Conjecture \ref{lemma_gInv_MxExample} 
follows as an immediate consequence. 

\begin{lemma} 
\label{lemma_AbsValueOf_gInvn_FornSquareFree_v1} 
For all positive integers $n \geq 1$, we have that 
\begin{equation} 
\label{eqn_AbsValueOf_gInvn_FornSquareFree_v1} 
|g^{-1}(n)| = \sum_{d|n} \mu^2\left(\frac{n}{d}\right) C_{\Omega(d)}(d). 
\end{equation} 
\end{lemma} 
\begin{proof} 
By applying 
Lemma \ref{lemma_AnExactFormulaFor_gInvByMobiusInv_v1}, 
Proposition \ref{prop_SignageDirInvsOfPosBddArithmeticFuncs_v1} and the 
complete multiplicativity of $\lambda(n)$, 
we easily obtain the stated result. 
In particular, since $\mu(n)$ is non-zero only at squarefree integers and 
at any squarefree $d \geq 1$ we have $\mu(d) = (-1)^{\omega(d)} = \lambda(d)$. 
Lemma \ref{lemma_AnExactFormulaFor_gInvByMobiusInv_v1} implies 
\begin{align*} 
|g^{-1}(n)| & = \lambda(n) \times \sum_{d|n} \mu\left(\frac{n}{d}\right) \lambda(d) C_{\Omega(d)}(d) \\ 
     & = \sum_{d|n} \mu^2\left(\frac{n}{d}\right) \lambda\left(\frac{n}{d}\right) 
     \lambda(nd) C_{\Omega(d)}(d) \\ 
     & = \lambda(n^2) \times \sum_{d|n} \mu^2\left(\frac{n}{d}\right) C_{\Omega(d)}(d). 
\end{align*} 
In the last equation, we see that 
that $\lambda(n^2) = +1$ for all $n \geq 1$ since the number of distinct 
prime factors (counting multiplicity) of any square integer is even. 
\end{proof} 

Combined with the signedness property of $g^{-1}(n)$ guaranteed by 
Proposition \ref{prop_SignageDirInvsOfPosBddArithmeticFuncs_v1}, 
Lemma \ref{lemma_AbsValueOf_gInvn_FornSquareFree_v1} shows that the summatory 
function is expressed as 
\[
G^{-1}(x) = \sum_{d \leq x} \lambda(d) C_{\Omega(d)}(d) M\left(\Floor{x}{d}\right). 
\]
Since $\lambda(d) C_{\Omega(d)}(d) = (g^{-1} \ast 1)^{-1}(d) = (\chi_{\mathbb{P}} + \varepsilon)(d)$ 
where $\chi_{\mathbb{P}}$ denotes the characteristic function of the primes, we also clearly 
recover by inversion that 
\[
M(x) = G^{-1}(x) + \sum_{p \leq x} G^{-1}\left(\Floor{x}{p}\right), x \geq 1. 
\]

\begin{cor} 
\label{lemma_BddExpectationOfgInvn} 
We have that 
\[
(\log n) (\log\log n) \ll 
     \mathbb{E}|g^{-1}(n)| \leq 
     \mathbb{E}\left[\sum_{d|n} C_{\Omega(d)}(d)\right]. 
\]
\end{cor} 
\begin{proof} 
To prove the lower bound, 
recall from the introduction that the summatory function of the 
squarefree integers is given by 
\[
Q(x) := \sum_{n \leq x} \mu^2(n) = \frac{6x}{\pi^2} + O(\sqrt{x}). 
\]
Then since $C_{\Omega(d)}(d) \geq 1$ for all $d \geq 1$, and since 
$\mathbb{E}[C_k(d)]$ is minimized when $k := 1$ according to 
Theorem \ref{theorem_Ckn_GeneralAsymptoticsForms}, 
we obtain by summing over 
\eqref{eqn_AbsValueOf_gInvn_FornSquareFree_v1} that 
\begin{align*} 
\frac{1}{x} \times \sum_{n \leq x} |g^{-1}(n)| & = \frac{1}{x} \times \sum_{d \leq x} 
     C_{\Omega(d)}(d) Q\left(\Floor{x}{d}\right) \\ 
     & \sim \sum_{d \leq x} C_{\Omega(d)}(d) \left[\frac{6}{d \cdot \pi^2} + O\left(\frac{1}{\sqrt{dx}}\right) 
     \right] \\ 
     & = \frac{6}{\pi^2} \left[\mathbb{E}[C_{\Omega(x)}(x)] + \sum_{d<x} 
     \frac{\mathbb{E}[C_{\Omega(d)}(d)]}{d}\right] + 
     O\left(\frac{1}{\sqrt{x}} \times \int_0^{x} t^{-1/2} dt\right) \\ 
     & \gg \left[\sum_{e \leq d \leq x} 
     \frac{\log\log d}{d}\right] + O(1) \\ 
     & \sim \times \int_{e}^{x} \frac{\log\log t}{t} dt + O(1) \\ 
     & \gg (\log x) (\log\log x), \mathrm{\ as\ } x \rightarrow \infty. 
\end{align*} 
To prove the upper bound, notice that by 
Lemma \ref{lemma_AnExactFormulaFor_gInvByMobiusInv_v1} and 
Corollary \ref{cor_AnExactFormulaFor_gInvByMobiusInv_nSqFree_v2}, 
\[
|g^{-1}(n)| \leq \sum_{d|n} C_{\Omega(d)}(d), n \geq 1. 
\]
Now since both of the above quantities are positive for all $n \geq 1$, 
we clearly obtain the upper bound stated above when we average over $n \leq x$ 
for all large $x$. 
\end{proof} 

\subsubsection{A connection to the distribution of the primes} 

\begin{remark} 
The combinatorial complexity of $g^{-1}(n)$ is deeply tied to the distribution of the primes 
$p \leq n$ as $n \rightarrow \infty$. 
While the magnitudes and dispersion of the primes $p \leq x$ certainly restricts the 
repeating of these distinct sequence 
values we can see in the contributions to $G^{-1}(x)$, the following 
statement is still clear about the relation of the weight functions $|g^{-1}(n)|$ to the 
distribution of the primes: 
The value of $|g^{-1}(n)|$ is entirely dependent on the pattern of the \emph{exponents} 
(viewed as multisets) of the distinct prime factors of $n \geq 2$. 
The relation of the repitition of the distinct values 
of $|g^{-1}(n)|$ in forming bounds on $G^{-1}(x)$ makes another clear tie to 
$M(x)$ through Proposition \ref{prop_Mx_SBP_IntegralFormula} in the next section. 
\end{remark}

\begin{example}[Combinatorial significance to the distribution of $g^{-1}(n)$] 
We have a natural extremal behavior with respect to distinct values of $\Omega(n)$ 
corresponding to squarefree integers, and prime powers. Namely, if for $k \geq 1$ we define the 
infinite sets $M_k$ and $m_k$ to correspond to the maximal (minimal) positive integers such that 
\begin{align*} 
M_k & := \left\{n \geq 2: |g^{-1}(n)| = \underset{{\substack{j \geq 2 \\ \Omega(j) = k}}}{\operatorname{sup}} 
     |g^{-1}(j)|\right\}, \\  
m_k & := \left\{n \geq 2: |g^{-1}(n)| = \underset{{\substack{j \geq 2 \\ \Omega(j) = k}}}{\operatorname{inf}} 
     |g^{-1}(j)|\right\}, 
\end{align*} 
then any element of $M_k$ is squarefree and any element of $m_k$ is a prime power. 
In particular, we have that for any $N_k \in M_k$ and $n_k \in m_k$
\[
N_k = \sum_{j=0}^{k} \binom{k}{j} \cdot j!, \quad \mathrm{\ and\ } \quad n_k = 2 \cdot (-1)^{k}. 
\]
The formula for the function $h^{-1}(n) = (g^{-1} \ast 1)(n)$ defined in the proof of 
Proposition \ref{prop_SignageDirInvsOfPosBddArithmeticFuncs_v1} implies that we can express 
an exact formula for $g^{-1}(n)$ in terms of symmetric polynomials in the 
exponents of the prime factorization of $n$. 
Namely, for $n \geq 2$ let 
\[
\widehat{e}_k(n) := [z^k] \prod_{p|n} (1 + z \cdot \nu_p(n)) = [z^k] \prod_{p^{\alpha} || n} (1 + \alpha z), 
     0 \leq k \leq \omega(n). 
\]
Then we have essentially shown using 
\eqref{eqn_proof_tag_hInvn_ExactNestedSumFormula_CombInterpetIdent_v3} and 
\eqref{eqn_AbsValueOf_gInvn_FornSquareFree_v1} that we can expand 
\[
g^{-1}(n) = h^{-1}(n) \times \sum_{k=0}^{\omega(n)} \binom{\Omega(n)}{k}^{-1} 
     \frac{\widehat{e}_k(n)}{k!}, n \geq 2. 
\]
The combinatorial formula for 
$h^{-1}(n) = \lambda(n) \cdot (\Omega(n))! \times \prod_{p^{\alpha} || n} (\alpha !)^{-1}$ 
we derived in the proof of the key signedness proposition in 
Section \ref{Section_PrelimProofs_Config} 
suggests further patterns and more regularity in the contributions of the distinct weighted 
terms for $G^{-1}(x)$ when we sum over all of the distinct prime exponent patterns that factorize 
$n \leq x$. 
\end{example} 

\newpage
\section{New formulas and bounds for $g^{-1}(n)$ and its summatory function} 
\label{Section_NewFormulasForgInvn} 

\subsection{Exact probabilistic bounds on the distributions of component sequences} 

We have remarked already in the introduction that the relation of the component 
functions, $g^{-1}(n)$ and $C_k(n)$, to the canonical additive functions 
$\omega(n)$ and $\Omega(n)$ leads to the regular properties of these functions 
witnessed in Table \ref{table_conjecture_Mertens_ginvSeq_approx_values}. 
In particular, each of $\omega(n)$ and $\Omega(n)$ satisfies 
an Erd\"os-Kac theorem that shows that a shifted and scaled variant of each 
of the sets of these function values can be expressed through a 
limiting normal distribution as $n \rightarrow \infty$. This extremely regular 
tendency of these functions towards their average order is inherited by the component 
function sequences we are summing in the approximation of $M(x)$ stated by 
Proposition \ref{prop_Mx_SBP_IntegralFormula}. 
In the remainder of this section we establish more technical analytic proofs of 
related properties of our key sequences, again in the spirit of 
Montgomery and Vaughan's reference. 

\begin{prop} 
\label{prop_HatAzx_ModSummatoryFuncExps_RelatedToCkn} 
For $|z| < 2$, let the summatory function be defined as 
\[
\widehat{A}_z(x) := \sum_{n \leq x} (-1)^{\omega(n)} 
     C_{\Omega(n)}(n) z^{\Omega(n)}. 
\]
Let the function $F(s, z)$ is defined for $\Re(s) > 1$ and $|z| < |P(s)|^{-1}$ 
in terms of the prime zeta function by 
\[
F(s, z) := \frac{1}{1-P(s) z} 
     \times \prod_p \left(1 - \frac{1}{p^s}\right)^{z}. 
\]
Then we have that for large $x$ 
\[
\widehat{A}_z(x) = \frac{x \cdot F(2, z)}{\Gamma(z)} (\log x)^{z-1} + 
     O_{z}\left(x \cdot (\log x)^{\Re(z) - 2}\right), |z| < P(2)^{-1}. 
\]
\end{prop} 
\begin{proof} 
\textbf{(TODO)} 
We know from the proof of 
Proposition \ref{prop_SignageDirInvsOfPosBddArithmeticFuncs_v1} that for $n \geq 2$ 
\[
C_{\Omega(n)}(n) = (\Omega(n))! \times \prod_{p^{\alpha}||n} \frac{1}{\alpha!}. 
\]
Then we can generate the denominator terms by the Dirichlet series 
\begin{align*} 
\sum_{n \geq 1} \frac{C_{\Omega(n)}(n)}{(\Omega(n))!} \cdot 
     \frac{(-1)^{\omega(n)} z^{\Omega(n)}}{n^s} & = \prod_p \left(1 + \sum_{r \geq 1} 
     \frac{z^{\Omega(p^r)}}{r! \cdot p^{rs}}\right)^{-1} 
     = \exp\left(z \cdot P(s)\right), \Re(s) > 1, z \in \mathbb{C}. 
\end{align*} 
By computing a Laplace transform on the right-hand-side of the above with 
respect to the variable $z$, we obtain 
\begin{align*} 
\sum_{n \geq 1} C_{\Omega(n)}(n) \cdot \frac{(-1)^{\omega(n)} z^{\Omega(n)}}{n^s} & = 
     \int_0^{\infty} e^{-t} \exp\left(tz \cdot P(s)\right) dt = \frac{1}{1 - P(s) z}, 
     \Re(s) > 1, |z| < |P(s)|^{-1}. 
\end{align*} 
It follows that 
\[
\sum_{n \geq 1} \frac{(-1)^{\omega(n)} C_{\Omega(n)}(n) z^{\Omega(n)}}{n^s} = 
     \zeta(s)^z \times F(s, z), 
\]
where 
\[
F(s, z) := \frac{1}{1-P(s) z} \times \prod_p \left(1 - \frac{1}{p^s}\right)^{z}, 
     \Re(s) > 1, |z| < |P(s)|^{-1}. 
\]
We adapt the details to the case where this method arises in the first 
application from \cite[\S 7.4; Thm.\ 7.18]{MV} 
so that we can sum over our modified function depending on $\Omega(n)$. 
In fact, we notice that since $|z|^{\Omega(n)} < n$ for $|z| < P(2)^{-1}$, we have the 
exact DGF 
\[
\mathcal{H}(s) := \sum_{n \geq 1} \frac{\lambda(n) C_{\Omega(n)}(n)}{n^s}, 
\]
which is absolutely convergent for $\Re(s) \geq 2$. The DGF $\mathcal{H}(s)$ is thus an 
analytic function of $s$ whenever $\Re(s) \geq 2$, and so we can differentiate it any integer 
$m \geq 0$ number of times to still obtain an absolutely convergent series of the form 
\[
\left\lvert \sum_{n \geq 1} \frac{(-1)^{\omega(n)} C_{\Omega(n)}(n) (\log n)^m z^{\Omega(n)}}{n^s} 
     \right\rvert < +\infty, \Re(s) \geq 2, |z| < P(2)^{-1}. 
\]
Let the function $d_z(n)$ be generated as the coefficients of the DGF 
$\zeta(s)^{z}$ for $\Re(s) > 1$, with corresponding 
summatory function $D_z(x) := \sum_{n \leq x} d_z(n)$. 
Adopting the notation from the reference, we set 
$b_z(n) := (-1)^{\omega(n)} C_{\Omega(n)}(n) z^{\Omega(n)}$, let the convolution 
$a_z(n) := \sum_{d|n} b_z(d) d_z(n/d)$, and define the summatory function 
$A_z(x) := \sum_{n \leq x} a_z(n)$. 
The theorem in \cite[Thm.\ 7.17; \S 7.4]{MV} implies that for any $z \in \mathbb{C}$ and $x \geq 2$ 
\[
D_z(x) = \frac{x (\log x)^{z-1}}{\Gamma(z)} + O\left(x \cdot (\log x)^{\Re(z)-2}\right). 
\]
Then we have that 
\begin{align*} 
A_z(x) & = \sum_{m \leq x/2} b_z(m) D_z(x/m) + \sum_{x/2 < m \leq x} b_z(m) \\ 
     & = \frac{x}{\Gamma(z)} \times \sum_{m \leq x/2} 
     \frac{b_z(m)}{m^2} \log\left(\frac{x}{m}\right)^{z-1} + 
     O\left(x \sum_{m \leq x} \frac{|b_z(m)|}{m^2} \times 
     \log\left(\frac{2x}{m}\right)^{\Re(z) - 2}\right). 
\end{align*} 
The error term in the previous equation satisfies 
\begin{align*} 
x \sum_{m \leq x} \frac{|b_z(m)|}{m^2} \times 
     \log\left(\frac{2x}{m}\right)^{\Re(z) - 2} & \ll 
     x (\log x)^{\Re(z) - 2} \sum_{m \leq \sqrt{x}} \frac{|b_z(m)|}{m^2} + 
     x (\log x)^{-(R+2)} \sum_{m > \sqrt{x}} \frac{|b_z(m)|}{m^2} (\log m)^{2R} \\ 
     & \ll x (\log x)^{\Re(z) - 2}, |z| \leq R. 
\end{align*} 
In the main term estimate for $A_z(x)$, when $m \leq \sqrt{x}$ we have 
\[
\log\left(\frac{x}{m}\right)^{z-1} = (\log x)^{z-1} + 
     O\left((\log m) (\log x)^{\Re(z) - 2}\right). 
\]
The remaining main term sum over the interval $m \leq x/2$ corresponds to bounding 
\begin{align*} 
\sum_{m \leq x/2} b_z(m) D_z(x/m) & = x (\log x)^{z-1} \sum_{m \leq x/2} \frac{b_z(m)}{m^2} \\ 
     & \phantom{=\quad\ } + 
     O\left(x (\log x)^{\Re(z)-2} \sum_{m \leq \sqrt{x}} \frac{|b_z(m)|}{m^2} + 
     x (\log x)^{R-1} \sum_{m > \sqrt{x}} \frac{|b_z(m)|}{m^2}\right) \\ 
     & = x (\log x)^{z-1} F(2, z) + O\left( 
     x (\log x)^{\Re(z)-2} \sum_{m \geq 1} \frac{b_z(m) (\log m)^{2R+1}}{m^2} 
     \right).
     \qedhere  
\end{align*} 
\end{proof} 

\begin{remark}[A standard simplifying assumption] 
Let the constant $\widehat{c} \approx 1.5147$ be defined explicitly as the 
product of primes 
\[
\widehat{c} := \frac{1}{6} \times \prod_{p > 2} \left(1 - 
     \frac{1}{(p-1)^2}\right)^{-1}. 
\] 
\begin{subequations} 
\label{eqn_dk_OmegaFuncDiffDensities_CharFormulas_v1} 
This constant is related to expressions of the 
asymptotic densities of the sets 
$$N_k(x) := \left\{n \leq x: \Omega(n) - \omega(n) = k\right\},$$ 
for integers $k \geq 0$ in the form of \cite[\S 2.4]{MV} 
\begin{equation} 
N_k(x) = d_k x + O\left(\left(\frac{3}{4}\right)^{k} \sqrt{x} (\log x)^{4/3}\right), 
\end{equation}
where for each natural number $k \geq 0$, $d_k > 0$ is an absolute constant that 
satisfies 
\begin{equation} 
d_k = \frac{\widehat{c}}{2^k} + O\left(5^{-k}\right). 
\end{equation} 
A hybrid DGF generating function for these densities is given by 
\begin{equation}
\sum_{k \geq 0} d_k z^k = \prod_{p} \left(1 - \frac{1}{p}\right) 
     \left(1 - \frac{1}{p-z}\right). 
\end{equation} 
\end{subequations} 
The limiting distribution of $\Omega(n) - \omega(n)$ is utilized in the proof 
of Theorem \ref{theorem_CnkSpCasesScaledSummatoryFuncs}. 

For $m \leq \omega_{\max}$ and $k \leq \Omega_{\max}$, as $n \rightarrow \infty$ 
we expect 
\[
\mathbb{P}\left(\omega(n) = m | \Omega(n) = k\right) \approx 
     \frac{\omega_{\max} + 1 - k}{\omega_{\max}}, 
\]
so that the conditional distribution of $\omega(n),\Omega(n)$ is not uniform over its 
bounded range. However, we do as is standard fare in proofs of the more traditional 
Erd\"os-Kac theorems require the simplifying assumption that as $n \rightarrow \infty$, 
we expect independently that $\omega(n),\Omega(n)$ are approximately equally likely to 
assume any values in some bounded $[1, M]$. This means we can treat the difference 
$\Omega(n) - \omega(n)$ as being approximately randomly distributed over some bounded range 
of its possible values. 
For a more rigorous treatment of this underlying principle see 
\cite{ERDOS-KAC-REF,BILLINGSLY-CLT-PRIMEDIVFUNC,RENYI-TURAN}. 
\end{remark} 

\begin{theorem} 
\label{theorem_CnkSpCasesScaledSummatoryFuncs} 
We have uniformly for $1 \leq k < \log\log x$ 
that as $x \rightarrow \infty$ 
\[
\widehat{C}_k(x) := 
     \sum_{\substack{n \leq x \\ \Omega(n) = k}} \lambda(n) (-1)^{\omega(n)} 
     C_k(n) \asymp 
     \frac{x}{\log x} \cdot \frac{(-1)^{k-1} (\log\log x + P(2))^{k}}{k!} \left[1 + 
     O\left(\frac{k}{(\log\log x)^3}\right)\right]. 
\]
\end{theorem} 
\begin{proof} 
The proof is a similar adaptation of the method of Montgomery and Vaughan we cited in 
Remark \ref{remark_TechAdjustments_theorem_HatPi_ExtInTermsOfGz_TO_GFs_SymmFuncs_SumsOfRecipOfPowsOfPrimes} 
to prove our variant of 
Theorem \ref{theorem_GFs_SymmFuncs_SumsOfRecipOfPowsOfPrimes}. 
We begin by bounding a contour integral over the error term for fixed large $x$ for 
$r := \frac{k-1}{\log\log x}$ with $r < P(2)^{-1} \approx 2.21118$: 
\begin{align*} 
\left\lvert \int_{|z|=r} \frac{x \cdot (\log x)^{-(\Re(z) + 2)}}{z^{k+1}} dz \right\rvert & \ll 
     x (\log x)^{-(r+2)} r^{-(k+1)} \ll \frac{x}{(\log x)^2} \cdot 
     \frac{(\log\log x)^{k+1}}{(k-1)^{k+1}} \cdot \frac{1}{e^{k-1}} \\ 
     & \ll \frac{x}{(\log x)^2} \cdot \frac{(\log\log x)^{k+1}}{(k-1)^{3/2}} \cdot 
     \frac{1}{e^{2k} (k-1)!} \\ 
     & \ll \frac{x}{(\log x)^2} \cdot \frac{(\log\log x)^{k-1}}{(k-1)!} \ll 
     \frac{x}{\log x} \cdot \frac{k \cdot (\log\log x)^{k-5}}{(k-1)!}. 
\end{align*} 
We must find an asymptotically accurate main term approximation to the coefficients 
of the following contour integral for $r \in [0, z_{\max}]$ where 
$z_{\max} < P(2)^{-1} \approx 2.21118$: 
\begin{align} 
\label{eqn_WideTildeArx_CountourIntDef_v1} 
\widetilde{A}_r(x) := 
     -\int_{|z|=r} \frac{x \cdot \exp(-P(2) z) (\log x)^{-z}}{(\log x) \Gamma(1+z) \cdot 
     z^{k+1} (1 + P(2) z)} dz. 
\end{align} 
Finding an exact formula for the derivatives of the function that is implicit to the 
Cauchy integral formula (CIF) for \eqref{eqn_WideTildeArx_CountourIntDef_v1} 
is complicated significantly by the need to differentiate $\Gamma(1+z)^{-1}$ 
up to integer order $k$ in the formula. What results in this case is a mess of 
confluent hypergeometric function approximations depending on $k$ and an extra 
factor of $(k!)^{-1}$ in the main-most term that \emph{substantially} complicates 
the formative summation patterns related to the incomplete gamma function in the 
$\widehat{\pi}_k(x)$ cases from 
Section \ref{subSection_PartialPrimeProducts_Proofs}. 
We can show that provided a restriction on the uniform bound parameter to 
$1 \leq r < 1$, we can approximate the contour integral in 
\eqref{eqn_WideTildeArx_CountourIntDef_v1} using a sane bounding procedure where 
the resulting main term is accurate up to a bounded constant factor. 

We observe that for $r := 1$, the function $|\Gamma(1+re^{2\pi\imath t})|$ has a 
singularity (pole) when $t := \frac{1}{2}$. Thus we restrict the range of $|z| = r$ 
so that $0 \leq r < 1$ to necessarily avoid this problematic value of $t$ when 
we parameterize $z = r e^{2\pi\imath t}$ as a real integral over $t \in [0, 1]$. 
Then we can compute the finite extremal values as 
\begin{align*} 
\min\limits_{\substack{0 \leq r < 1 \\ 0 \leq t \leq 1}} |\Gamma(1+re^{2\pi\imath t})| & = 
     |\Gamma(1+re^{2\pi\imath t})| \Biggr\rvert_{(r,t) \approx (1, 0.740592)} \approx 
     0.520089 \\ 
\max\limits_{\substack{0 \leq r < 1 \\ 0 \leq t \leq 1}} |\Gamma(1+re^{2\pi\imath t})| & = 
     |\Gamma(1+re^{2\pi\imath t})| \Biggr\rvert_{(r,t) \approx (1, 0.999887)} \approx 1. 
\end{align*} 
This shows that 
\begin{align} 
\label{eqn_WideTildeArx_CountourIntDef_v2} 
\widetilde{A}_r(x) \asymp 
     -\int_{|z|=r} \frac{x \cdot \exp(-P(2) z) (\log x)^{-z}}{(\log x) \cdot 
     z^{k+1} (1 + P(2) z)} dz, 
\end{align} 
where as $x \rightarrow \infty$ 
\[
\frac{\widetilde{A}_r(x)}{-\int_{|z|=r} \frac{x \cdot \exp(-P(2) z) (\log x)^{-z}}{(\log x) \cdot 
     z^{k+1} (1 + P(2) z)} dz} \in [1, 1.92275]. 
\] 
In particular, this argument holds by an analog to the mean value theorem for real integrals 
based on sufficient continuity conditions on the parameterized path and the 
smoothness of the integrand viewed as a function of $z$.  

By induction we can compute the remaining coefficients 
$[z^k] \Gamma(1+z) \times \widehat{A}_z(x)$ with respect to 
$x$ for fixed $k \leq \log\log x$ using the CIF. 
Namely, it is not difficult to see that for any integer $m \geq 0$, 
we have the $m^{th}$ partial derivative of the integrand with respect to $z$ 
has the following expansion: 
\begin{align*} 
\frac{1}{m!} \times \frac{\partial^{(m)}}{{\partial z}^{(m)}}\left[ 
     \frac{(\log x)^{-z}}{1 + P(2) z}\right] \Biggr\rvert_{z=0} & = 
     \sum_{j=0}^{m} \frac{(-1)^{m} P(2)^{j} (\log\log x + P(2))^{m-j}}{(m-j)!} \\ 
     & = 
     \frac{e \cdot (-P(2))^{m} (\log x)^{\frac{1}{P(2)}}}{m!} \times 
     \Gamma\left(m+1, 1 + \frac{\log\log x}{P(2)}\right) \\ 
     & \sim \frac{(-1)^m (\log\log x + P(2))^{m}}{m!}. 
\end{align*} 
Now by parameterizing the countour around $|z| = r := \frac{k-1}{\log\log x} < 1$ we 
deduce that the the main term of our approximation corresponds to 
\begin{align*} 
-\int_{|z|=r} \frac{x \cdot \exp(-P(2) z) (\log x)^{-z}}{(\log x) z^{k+1} (1 + P(2) z)} dz & \asymp 
     \frac{x}{\log x} \cdot \frac{(-1)^{k-1} (\log\log x + P(2))^{k}}{k!}. 
     \qedhere 
\end{align*} 
\end{proof} 

\begin{lemma} 
\label{lemma_HatCAstxSum_ExactFormulaWithError_v1} 
We have that as $x \rightarrow \infty$ 
\[
\left\lvert \mathbb{E}\left[ 
     \sum_{n \leq x} \lambda(n) (-1)^{\omega(n)} C_{\Omega(n)}(n) 
     \right] \right\rvert 
     \asymp \frac{P(2)}{\sqrt{2\pi}} \cdot \frac{1}{\sqrt{\log\log x}}. 
\] 
\end{lemma} 
\begin{proof} 
We observe that 
\begin{align*} 
\sum_{n \leq x} \lambda(n) (-1)^{\omega(n)} C_{\Omega(n)}(n) & = 
     \sum_{k=1}^{\log_2(x)} \sum_{\substack{n \leq x \\ \Omega(n) = k}} 
     \lambda(n) (-1)^{\omega(n)} C_{\Omega(n)}(n) 
     = 
     \sum_{k=1}^{\log_2(x)} \widehat{C}_k(x). 
\end{align*} 
We claim that 
\begin{equation} 
\label{eqn_proof_tag_PartialSumsOver_HatCkx_v1} 
\sum_{k=1}^{\log_2(x)} \widehat{C}_k(x) \asymp 
     \sum_{k=1}^{\log\log x} \widehat{C}_k(x). 
\end{equation} 
To prove \eqref{eqn_proof_tag_PartialSumsOver_HatCkx_v1}, it suffices to show that 
\begin{equation} 
\label{eqn_proof_tag_PartialSumsOver_HatCkx_EquivCond_v2} 
\left\lvert \frac{\sum\limits_{\log\log x < k \leq \log_2(x)} \widehat{C}_k(x)}{ 
     \sum\limits_{k=1}^{\log\log x} \widehat{C}_k(x)} \right\rvert = o(1), 
     \mathrm{\ as\ } x \rightarrow \infty. 
\end{equation} 
We first compute the absolute value of the following 
summatory function by applying 
Theorem \ref{theorem_CnkSpCasesScaledSummatoryFuncs} for large 
$x \rightarrow \infty$: 
\begin{align} 
\notag 
\left\lvert \sum_{k=1}^{\log\log x} \widehat{C}_k(x) \right\rvert & \asymp 
     \left\lvert \frac{x}{\log x} - \frac{x \cdot e^{-P(2)} \Gamma(\log\log x, -(\log\log x) + P(2)))}{ 
     (\log x)^2 \cdot \Gamma\left(\log\log x\right)} \right\rvert \left[
     1 + O\left(\frac{1}{(\log\log x)^2}\right)
     \right] \\ 
\label{eqn_proof_tag_PartialSumsOver_HatCkx_v3} 
     & \sim \frac{x}{\log x} + \frac{x \cdot \sqrt{\log\log x}}{\sqrt{2\pi} (\log\log x + P(2))} 
     (1 + o(1)). 
\end{align} 
We define the following component sums for large $x$ and $0 < \varepsilon < 1$ so that 
$(\log\log x)^{\varepsilon \frac{\log\log x}{\log\log\log x}} = o(\log x)$: 
\begin{align*} 
S_{2,\varepsilon}(x) & := \sum_{P(2)^{-1} \log\log x < k \leq \log\log x} \widehat{C}_k(x). 
\end{align*} 
Then 
\[
\sum_{P(2)^{-1} \log\log x < k \leq (\log\log x)^{\varepsilon \frac{\log\log x}{\log\log\log x}}} \widehat{C}_k(x) 
     \gg S_{2,\varepsilon}(x),  
\]
with equality as $\varepsilon \rightarrow 1$ so that the upper bound of summation tends to $\log x$. 
To show that \eqref{eqn_proof_tag_PartialSumsOver_HatCkx_EquivCond_v2} holds, 
observe that whenever $\Omega(n) = k$, we have that $C_{\Omega(n)}(n) \leq k!$. 
We can bound the sum defined above using 
Theorem \ref{theorem_MV_Thm7.20-init_stmt} for large $x \rightarrow \infty$ as 
\begin{align*} 
S_{2,\varepsilon}(x) & \leq 
     \sum_{\log\log x \leq k \leq \log\log x} \sum_{\substack{n \leq x \\ \Omega(n)=k}} C_{\Omega(n)}(n) 
     \ll \sum_{k=\log\log x}^{(\log\log x)^{\varepsilon \frac{\log\log x}{\log\log\log x}}} 
      \frac{\widehat{\pi}_k(x)}{x} \cdot k! \\ 
     & \ll \sum_{k=\log\log x}^{(\log\log x)^{\varepsilon \frac{\log\log x}{\log\log\log x}}} 
     (\log x)^{\frac{k}{\log\log x} - 1 - \frac{k}{\log\log x} \left( 
     \log k - \log\log\log x\right)} \cdot \left(\frac{k}{e}\right)^{k} \sqrt{2\pi k} \\ 
     & \ll \sum_{k=\log\log x}^{\varepsilon \frac{\log\log x}{\log\log\log x}} 
     (\log x)^{k \frac{\log\log\log x}{\log\log x} - 1} \sqrt{k} 
     \ll \frac{1}{(\log x)} \times \int_{\log\log x}^{\varepsilon 
     \frac{\log\log x}{\log\log\log x}} (\log\log x)^t \sqrt{t} \cdot dt \\ 
     & \ll \frac{1}{(\log x)} \sqrt{\frac{\varepsilon \cdot \log\log x}{\log\log\log x}} 
     (\log\log x)^{\frac{\varepsilon \cdot \log\log x}{\log\log\log x}} = o(x), 
\end{align*} 
where $\lim_{x \rightarrow \infty} (\log x)^{\frac{1}{\log\log x}} = e$. 
By \eqref{eqn_proof_tag_PartialSumsOver_HatCkx_v3} this 
form of the ratio in \eqref{eqn_proof_tag_PartialSumsOver_HatCkx_EquivCond_v2} clearly tends to zero. 
If we have a contribution from the terms $\widehat{\pi}_k(x)$ as $\varepsilon \rightarrow 1$, 
e.g., if $x$ is a power of two, then $C_{\Omega(x)}(x) = 1$ by the formula in 
\eqref{eqn_proof_tag_hInvn_ExactNestedSumFormula_CombInterpetIdent_v3}, so that 
the contribution from this upper-most indexed term is negligible: 
\[
x=2^k \implies \Omega(x) = k \implies C_{\Omega(x)}(x) = \frac{(\Omega(x))!}{k!} = 1. 
\]
The formula for the expectation claimed in the statement of this lemma above then 
follows from \eqref{eqn_proof_tag_PartialSumsOver_HatCkx_v3} by scaling by 
$\frac{1}{x}$ and dropping the asymptotically lesser error terms in the bound. 
\end{proof} 

\begin{remark}
The signs of the functions estimated in 
Theorem \ref{theorem_CnkSpCasesScaledSummatoryFuncs} are 
dictated by the differences of the prime omega functions as 
$(-1)^{\Omega(n) - \omega(n)}$. It happens, as we have summarized above, that 
this distribution is fairly regular with limiting asymptotic densities of the distinct values 
of the difference between the additive functions. This signedness property, in place of 
the more natural $\lambda(n)$ weights as appear in 
Proposition \ref{prop_SignageDirInvsOfPosBddArithmeticFuncs_v1}, is necessary to 
simplify the DGF expansion we used to obtain the asymptotics for the summatory 
functions $\widehat{A}_z(x)$ in 
Proposition \ref{prop_HatAzx_ModSummatoryFuncExps_RelatedToCkn}. It also leads to additional 
cancellation in the corresponding summatory functions and the resulting average order 
expectations we would obtain from these sums in this raw form. 

An exact DGF expression for 
$\lambda(n) C_{\Omega(n)}(n)$ is in fact very much complicated by the need to estimate the asymptotics 
of the coefficients of the right-hand-side products 
\begin{align*} 
\sum_{n \geq 1} \frac{\lambda(n) C_{\Omega(n)}(n) z^{\Omega(n)}}{(\Omega(n))! \cdot n^s} & = 
     \prod_p \left(2 - \exp\left(-z \cdot p^{-s}\right)\right)^{-1}, 
     \Re(s) > 1, |z| < \log 2 \\ 
     & = \exp\left(\sum_{j \geq 1} \sum_p \left(e^{-zp^{-s}}-1\right)^{j} \frac{1}{j}\right). 
\end{align*} 
It is unclear how to exactly, and effectively, bound the 
coefficients of powers of $z$ in the DGF expansion defined by the last equation. 
We use an alternate method in the next corollary to obtain the asymptotics for the actual 
summatory functions on which we require tight average case bounds. 
\end{remark} 

\begin{cor}[Summatory functions of the unsigned component sequences] 
\label{cor_SummatoryFuncsOfUnsignedSeqs_v2} 
We have that for large $x \geq 2$ and $1 \leq k \leq \log\log x$ 
\begin{align*} 
\sum_{\substack{n \leq x \\ \Omega(n) = k}} C_{\Omega(n)}(n) & \asymp 
     \frac{3}{2\hat{c}} \cdot \frac{x}{(\log x)^2} \left[ 
     \frac{(\log\log x + P(2))^{k}}{k!} - \frac{(\log\log x + P(2))^{k-1}}{(k-1)!}
     \right]. 
\end{align*} 
\end{cor} 
\begin{proof} 
We handle transforming our previous results for the sum over the unsigned sequence 
$C_{\Omega(n)}(n)$ such that $\Omega(n) = k$. 
The argument basically boils down to approximating the smooth summatory function of 
$\lambda_{\ast}(n) := (-1)^{\Omega(n) - \omega(n)}$ using the weighted 
densities defined by \eqref{eqn_dk_OmegaFuncDiffDensities_CharFormulas_v1}. 
We then have an integral formula involving the non-sign-weighted 
sequence that results by again 
applying ordinary Abel summation (and integrating by parts) in the form of 
\begin{align} 
\label{eqn_AbelSummationIBPReverseFormula_stmt_v1} 
\sum_{n \leq x} \lambda_{\ast}(n) h(n) & = \left(\sum_{n \leq x} \lambda_{\ast}(n)\right) h(x) - 
     \int_{1}^{x} \left(\sum_{n \leq t} \lambda_{\ast}(n)\right) h^{\prime}(t) dt \\ 
\notag 
     & \asymp \left\{\begin{array}{ll} 
     u_t = L_{\ast}(t) & v_t^{\prime} = h^{\prime}(t) dt \\ 
     u_t^{\prime} = L_{\ast}^{\prime}(t) dt & v_t = h(t) 
     \end{array} 
     \right\} 
     \int_1^{x} \frac{d}{dt}\left[\sum_{n \leq t} \lambda_{\ast}(n)\right] h(t) dt. 
\end{align} 
Let the signed left-hand-side summatory function in 
\eqref{eqn_AbelSummationIBPReverseFormula_stmt_v1} for our function be defined by 
\begin{align*} 
\widehat{C}_{k,\ast}(x) & := \left\lvert \sum_{\substack{n \leq x \\ \Omega(n)=k}} 
     \lambda(n) (-1)^{\omega(n)} C_{\Omega(n)}(n) \right\rvert \\ 
     & \phantom{:} = 
     \frac{x}{\log x} \cdot \frac{(\log\log x + P(2))^{k}}{k!} \left[ 
     1 + O\left(\frac{1}{(\log\log x)^2}\right)\right], 
\end{align*} 
where the second equation follows from the proof of 
Theorem \ref{theorem_CnkSpCasesScaledSummatoryFuncs}. 
Then by differentiating the formula we engineered well for ourselves in 
\eqref{eqn_AbelSummationIBPReverseFormula_stmt_v1}, and 
then summing over the uniform range of $1 \leq k \leq \log\log x$, 
we can recover an approximation to the unsigned summatory function for the 
sequence we need to bound in later results proved in this section. 

We handle the sign weighted terms by defining and approximating the asymptotic main term 
of the following summatory function 
(\cf Table \ref{table_LAstxSummatoryFuncCompsWithExact_v2} starting on page 
\pageref{table_LAstxSummatoryFuncCompsWithExact_v2}): 
\begin{align*} 
L_{\ast}(t) & := \sum_{n \leq t} \lambda(n) (-1)^{\omega(n)} = 
     \sum_{j=0}^{\log_2(t)} (-1)^{j} \cdot \#\{n \leq t: \Omega(n) - \omega(n) = j\} \\ 
     & \sim \sum_{j=0}^{\log_2(t)} \cdot \frac{\hat{c} \cdot t (-1)^{j}}{2^j} = 
     \frac{2\hat{c} \cdot t}{3} + o(1), \mathrm{\ as\ } t \rightarrow \infty. 
\end{align*} 
The approximation to the densities $d_k$ for the difference of the prime omega 
functions is cited from 
\eqref{eqn_dk_OmegaFuncDiffDensities_CharFormulas_v1} \cite[\S 2.4]{MV}. 
After applying the formula from \eqref{eqn_AbelSummationIBPReverseFormula_stmt_v1},  
we deduce that the unsigned summatory function variant satisfies 
\begin{align*} 
\widehat{C}_{k,\ast}(x) & = \int_1^{x} L_{\ast}^{\prime}(t) C_{\Omega(t)}(t) dt \qquad \implies 
C_{\Omega(x)}(x) \asymp \frac{\widehat{C}_{k,\ast}^{\prime}(x)}{L_{\ast}^{\prime}(x)} \\ 
C_{\Omega(x)}(x) & \asymp \frac{3}{2\hat{c}} \left[\frac{(\log\log x + P(2))^{k}}{(\log x) k!} \left(1 - 
     \frac{1}{\log x}\right) + \frac{(\log\log x + P(2))^{k-1}}{(\log x)^2 (k-1)!}\right] 
     =: \widehat{C}_{k,\ast\ast}(x). 
\end{align*} 
So again applying the Abel summation formula, we obtain that 
\begin{align*} 
\sum_{\substack{n \leq x \\ \Omega(n)=k}} C_{\Omega(n)}(n) & \asymp 
     \left\lvert \int \widehat{C}_{k,\ast\ast}^{\prime}(x) dx \right\rvert \\ 
     & = \frac{3}{2\hat{c}} \cdot \frac{x}{(\log x)^2} \left[ 
     \frac{(\log\log x + P(2))^{k}}{k!} - \frac{(\log\log x + P(2))^{k-1}}{(k-1)!}
     \right]. 
\end{align*} 
This proves the stated formula, and it similarly holds uniformly for all $1 \leq k \leq \log\log x$ 
when $x$ is large. 
\end{proof} 

\begin{remark} 
Notice that even though we are using asymptotic notation 
($\gg$ and $\asymp$) that does not preserve constant factors 
of its operands well (in principle), we are still making an effort to keep the 
sanctity of the multiplicative 
constants which we can be certain are exact in our new formulas. 
This is not an objection to 
nor ignorance of conventions, but rather a necessity in maintaining 
tight enough bounds so we can still sum over differences involving these functions 
within a small window of error. 
That we are not off by more than, say a factor of $2$, as we established in 
proving Theorem \ref{theorem_CnkSpCasesScaledSummatoryFuncs}, 
increases the accuracy of the next probabilistic results that will 
be important in bounding $|g^{-1}(n)|$ near its expectation, or average order asymptotics. 
In particular, we will require a fairly close bound near the expectation of this 
function in conjunction with the probabilistic statement of the result in 
Corollary \ref{cor_CLT_VII} below. 
This means in practice that we are unable to be too imprecise with constant factors as error terms 
in the differences of $|g^{-1}(n)| - \mathbb{E}|g^{-1}(n)|$ can accumulate and generate 
non-negligible noise when we apply these results in the next section (n.b.). 
\end{remark} 

\begin{cor}[Expectation formulas] 
\label{cor_ExpectationFormulaAbsgInvn_v2} 
We have that as $n \rightarrow \infty$ 
\begin{align*} 
\mathbb{E}|g^{-1}(n)| & \asymp \frac{1}{\hat{c} \sqrt{2\pi}} (\log n) (\log\log n)^{3/2}. 
\end{align*} 
\end{cor} 
\begin{proof} 
We use the formula from Corollary \ref{cor_SummatoryFuncsOfUnsignedSeqs_v2} 
to find $\mathbb{E}[C_{\Omega(n)}(n)]$ up to a small bounded multiplicative 
constant factor as $n \rightarrow \infty$: 
\begin{align*} 
\mathbb{E}[C_{\Omega(n)}(n)] & = 
     \sum_{k=1}^{\log_2(n)} \sum_{\substack{n \leq x \\ \Omega(n) = k}} C_k(n) \\ 
     & \asymp \frac{1}{n} \times 
     \sum_{k=1}^{\log\log n} \frac{3}{2\hat{c}} \cdot \frac{n}{(\log n)^2} \left[ 
     \frac{(\log\log n + P(2))^{k}}{k!} - \frac{(\log\log n + P(2))^{k-1}}{(k-1)!}
     \right] \\ 
     & \asymp \frac{3}{2\hat{c} \sqrt{2\pi}} \cdot \frac{\sqrt{\log\log n}}{\log n}\left[1 + 
     O\left(\frac{1}{\log\log n}\right)\right]. 
\end{align*} 
This implies that for large $x$ 
\begin{align*} 
\int \frac{\mathbb{E}[C_{\Omega(x)}(x)]}{x} dx & \asymp 
     \frac{1}{\hat{c} \sqrt{2\pi}} \cdot (\log\log x)^{3/2} \left[1 + 
     O\left(\frac{1}{\log\log x}\right)\right]. 
\end{align*} 
Therefore, citing the formula we derived in the proof of 
Corollary \ref{lemma_BddExpectationOfgInvn}, we find that 
\begin{align*} 
\mathbb{E}|g^{-1}(n)| & = \frac{6}{\pi^2}\left[\mathbb{E}[C_{\Omega(n)}(n)] + 
     \sum_{d<n} \frac{\mathbb{E}[C_{\Omega(d)}(d)]}{d}\right] + O(1) \\ 
     & \asymp \frac{3}{4\sqrt{2} \hat{c}} \cdot \operatorname{erfi}\left(\sqrt{\log\log n}\right) + 
     \frac{1}{\hat{c} \sqrt{2\pi}} (\log n) (\log\log n)^{3/2} \\ 
     & \asymp \frac{3}{4\sqrt{2\pi} \hat{c}} \cdot \frac{(\log n)}{\sqrt{\log\log n}} + 
     \frac{1}{\hat{c} \sqrt{2\pi}} (\log n) (\log\log n)^{3/2}. 
\end{align*} 
In the previous equation, we have used a known asymptotic expansion of the function $\operatorname{erfi}(z)$ 
about infinity in the form of \cite[\S 3.2]{INCGAMMA-BOOK} 
\[
\operatorname{erfi}(z) = \frac{e^{z^2}}{\sqrt{\pi}} \left(z^{-1} + \frac{1}{2}z^{-3} + \frac{3}{4}z^{-5} + \cdots \right), 
     \mathrm{\ as\ } |z| \rightarrow \infty. 
\]
This proves the claimed formula for the expectation of our key function. 
\end{proof} 

\begin{theorem} 
\label{theorem_CLT_VI} 
Let the mean and variance analogs be denoted by 
\[
\mu_x(C) := \log\log x + P(2), 
     \qquad \mathrm{\ and\ } \qquad 
     \sigma_x(C) := \sqrt{\mu_x(C)}
\]
Set $Y > 0$ and suppose that $z \in [-Y, Y]$. Then we have 
uniformly for all $-Y \leq z \leq Y$ as $x \rightarrow \infty$ that 
\[
\frac{1}{x} \cdot \#\left\{2 \leq n \leq x: \frac{C_{\Omega(n)}(n) - 
     \mu_x(C)}{\sigma_x(C)} \leq z\right\} = 
     \frac{3 e^{P(2)}}{2\widehat{c} \cdot (\log x)} \left[\Phi(z) + 
     O\left(\frac{1}{(\log\log x)^{1/2}}\right)\right]. 
\] 
\end{theorem} 
\begin{proof} 
For large $x$ and $n \leq x$, define the following auxiliary variables: 
\[
\alpha_n := \frac{C_{\Omega(n)}(n) - \mu_n(C)}{\sigma_n(C)}, \quad 
     \beta_{n,x} := \frac{C_{\Omega(n)}(n) - \mu_x(C)}{\sigma_x(C)}. 
\] 
Let the corresponding densities (whose limiting distributions we must verify) 
be defined by the functions 
\[
\Phi_1(x, z) := \frac{1}{x} \cdot \#\{n \leq x: \alpha_n \leq z\}, 
\]
and 
\[
\Phi_2(x, z) := \frac{1}{x} \cdot \#\{n \leq x: \beta_{n,x} \leq z\}. 
\] 
We first argue that it suffices to consider the distribution of $\Phi_2(x, z)$ as 
$x \rightarrow \infty$ in place of $\Phi_1(x, z)$ to obtain our desired result statement. 
In particular, the difference of the two auxiliary variables is neglibible as 
$x \rightarrow \infty$ for $n,x$ taken over the ranges that contribute the non-trivial 
weight to the main term of each density function. We have for 
$\sqrt{x} \leq n \leq x$ and $C_{\Omega(n)}(n) \leq 2 \cdot \mu_x(C)$ that 
\[
|\alpha_n - \beta_{n,x}| \ll \frac{1}{\sigma_x(C)} \xrightarrow{x \rightarrow \infty} 0. 
\]
So we naturally prefer to estimate the easier forms of the distribution function $\Phi_2(x, z)$ 
when $x$ is large, and for any fixed $z \in \mathbb{R}$. 
That is, we replace $\alpha_n$ by $\beta_{n,x}$ and estimate the limiting 
densities corresponding to these terms. 

We use the formula proved in Corollary \ref{cor_SummatoryFuncsOfUnsignedSeqs_v2}, 
which holds uniformly for $x$ large when $1 \leq k \leq \log\log x$, to estimate the 
densities claimed within the ranges bounded by $z$ as $x \rightarrow \infty$. 
We have already proved in Lemma \ref{lemma_HatCAstxSum_ExactFormulaWithError_v1} 
(in the signed summatory function case analysis) by applying 
Theorem \ref{theorem_MV_Thm7.20-init_stmt} 
that to express an accurate asymptotic main term for these values, it 
suffices to omit the cases of $\Omega(n) = k$ for $k > \log\log x$ where we do not 
recover uniform formulas on these sums. The rest of our argument follows closely 
along with the method in the proof of the related theorem in 
\cite[Thm.\ 7.21; \S 7.4]{MV}. 

Let $k \geq 1$ be a natural number defined by $k := t + P(2) + \log\log x$. 
We write the small parameter $\delta_{t,x} := \frac{t}{P(2) + \log\log x}$. 
When 
$|t| \leq \frac{1}{2} (P(2) + \log\log x)$, we have by Stirling's formula that 
\begin{align*} 
\frac{3}{2\hat{c}} \cdot \frac{x}{(\log x)^2} \frac{(\log\log x + P(2))^{k}}{k!} & \sim 
     \frac{3}{2\hat{c} \sqrt{2\pi}} \cdot \frac{x \cdot e^{P(2) + t}}{ 
     (\log x) (\log\log x + P(2))^{1/2}} 
     (1 + \delta_{t,x})^{-(\log\log x + P(2)) (1 + \delta_{t,x}) + \frac{1}{2}}. 
\end{align*} 
We have the uniform estimate 
$\log(1+\delta_{t,x}) = \delta_{t,x} - \frac{\delta_{t,x}^2}{2} + O(|\delta_{t,x}|^3)$ whenever 
$|\delta_{t,x}| \leq \frac{1}{2}$. Then we can expand the factor involving $\delta_{t,x}$ 
in the previous equation as follows: 
\begin{align*} 
(1+\delta_{t,x})^{-(P(2) + \log\log x) (1+\delta_{t,x}) + \frac{1}{2}} & = 
     \exp\left(\left(\frac{1}{2}-(P(2) + \log\log x) (1+\delta_{t,x})\right) \times 
     \left(\delta_{t,x} - \frac{\delta_{t,x}^2}{2} + O(|\delta_{t,x}|^3)\right)\right) \\ 
     & = \exp\left(-t + \frac{t-t^2}{2\mu_x(C)} - \frac{(t^2-2t^3)}{4\mu_x(C)^2} + 
     O\left(\frac{|t|^3}{\mu_x(C)^2}\right)\right). 
\end{align*} 
For both $|t| \leq (P(2) + \log\log x)^{1/2}$ and 
$(P(2) + \log\log x)^{1/2} < |t| \leq (P(2) + \log\log x)^{2/3}$, 
we see that 
\[
\frac{t}{P(2) \log\log x} \ll \frac{1}{\sqrt{P(2) + \log\log x}} + \frac{|t|^3}{(P(2) + \log\log x)^2}. 
\]
Similarly, for $|t| \leq 1$ and $|t| > 1$, we see that both 
\[
\frac{t^2}{(P(2) + \log\log x)^2} \ll \frac{1}{\sqrt{P(2) + \log\log x}} + 
     \frac{|t|^3}{(P(2) + \log\log x)^2}. 
\] 
Let the error terms in $(x, t)$ be denoted by 
\[
\widetilde{E}(x, t) := O\left(\frac{1}{\sigma_x(C)}\right) + 
     O\left(\frac{|t|^3}{\mu_x(C)^2}\right). 
\]
Combining these estimates with the previous computations, we can deduce that 
uniformly for $|t| \leq (P(2) + \log\log x)^{2/3}$ 
\begin{align*} 
\frac{3}{2\hat{c}} \cdot \frac{x}{(\log x)^2} \frac{(\log\log x + P(2))^{k}}{k!} & \sim 
     \frac{3 e^{P(2)}}{2\hat{c} \sqrt{2\pi}} \cdot \frac{x}{(\log x) \sigma_x(C)} 
     \cdot \exp\left(-\frac{t^2}{2\sigma_x(C)^2}\right) \times 
     \left[1 + \widetilde{E}(x, t)\right]. 
\end{align*} 
Hence, by the formula from Corollary \ref{cor_SummatoryFuncsOfUnsignedSeqs_v2}, 
\begin{align*}
\sum_{\substack{n \leq x \\ \Omega(n)=k}} C_{\Omega(n)}(n) & = 
     \frac{3 e^{P(2)}}{2\hat{c} \sqrt{2\pi}} \cdot \frac{x}{(\log x) \sigma_x(C)} 
     \cdot \exp\left(-\frac{\left(k-\mu_x(C)\right)^2}{2\sigma_x(C)^2}\right) \times 
     \left[1 + \widetilde{E}(x, k - \mu_x(C))\right]. 
\end{align*} 
By the argument in the proof of 
Lemma \ref{lemma_HatCAstxSum_ExactFormulaWithError_v1}, we see that 
the contributions of these summatory functions for 
$k \leq P(2) + \log\log x - (P(2) + \log\log x)^{2/3}$ is negligible. 
We also require that $k \leq \log\log x$ as we have worked out in 
Theorem \ref{theorem_CnkSpCasesScaledSummatoryFuncs}. So we sum over a 
corresponding range of 
\[
P(2) + \log\log x - (P(2) + \log\log x)^{2/3} \leq k \leq R \cdot \log\log x, 
\] 
for $R := 1 + \frac{z}{\sigma_x(C)}$ to approximate the 
stated normalized densities. 
Then finally as $x \rightarrow \infty$, the 
three terms that result (one main term, two error terms) 
can be considered to correspond to a Riemann sum for an associated integral. 
\end{proof} 

\begin{cor} 
\label{cor_CLT_VII} 
Let $Y > 0$ and $z \in [-Y, Y]$. 
Then uniformly for all $-Y \leq z \leq Y$ as $x \rightarrow \infty$ 
we have that 
\begin{align*} 
\frac{1}{x} \cdot \#\left\{2 \leq n \leq x:|g^{-1}(n)| - 
     \mathbb{E}|g^{-1}(n)| \leq z\right\} & = 
     \frac{3 e^{P(2)}}{2\widehat{c} \cdot (\log x)} \left[ 
     \Phi\left(\frac{\frac{\pi^2}{6} z - \mu_x(C)}{\sigma_x(C)}\right) + 
     O\left(\frac{1}{\sqrt{\log\log x}}\right)\right]. 
\end{align*} 
\end{cor} 
\begin{proof} 
We compute using the argument sketched in the proof of 
Corollary \ref{lemma_BddExpectationOfgInvn} from 
Section \ref{subSection_Relating_CknFuncs_to_gInvn} that 
\begin{align*} 
|g^{-1}(n)| - \mathbb{E}|g^{-1}(n)| & \sim \frac{6}{\pi^2} C_{\Omega(n)}(n). 
\end{align*} 
Then the result follows from Theorem \ref{theorem_CLT_VI}. 
We can also compute using Corollary \ref{cor_CLT_VII} that 
\begin{align} 
\label{eqn_remark_ClosenessApproxgInvnByAvgOrder_v1} 
\frac{\pi^2 e^{P(2)}}{4 \hat{c} \cdot (\log x) \cdot \sigma_x(C)} \times 
     \int_{-\infty}^{\infty} 
     z \cdot \Phi^{\prime}\left(\frac{\frac{\pi^2}{6} z - \mu_x(C)}{\sigma_x(C)}\right) dz & = 
     \frac{9 e^{P(2)}}{\pi^2 \hat{c} (\log x)}  \sqrt{\log\log x + P(2)} + o(1) 
     \xrightarrow{x \rightarrow \infty} 0. 
\end{align} 
So we interpret this calculation to mean that the contribution from the sum 
over $|g^{-1}(n)|$ where $g^{-1}(n)$ is not very close to its average order is essentially 
negligible. We will use this property in the proof of 
Theorem \ref{theorem_GInvxLowerBoundByGEInvx_v1} in the next subsection. 
\end{proof} 

\subsection{Establishing initial lower bounds on the summatory functions $G^{-1}(x)$} 
\label{Section_ProofOfValidityOfAverageOrderLowerBounds} 

\begin{definition} 
Let the summatory function $G_E^{-1}(x)$ be defined for $x \geq 1$ by 
\begin{equation} 
\label{eqn_GEInvxSummatoryFuncDef_v1} 
G_E^{-1}(x) := \sum_{n \leq (\log x)^{\frac{7}{3}} (\log\log x)} \lambda(n) \times 
     \sum_{\substack{d|n \\ d > e}} \frac{(\log d)^{\frac{3}{4}}}{\log\log d}. 
\end{equation} 
The subscript of $E$ is a formality of 
notation that does not correspond to an actual parameter or any 
implicit dependence on $E$ in the function defined above. 
\end{definition} 

\begin{theorem} 
\label{theorem_GInvxLowerBoundByGEInvx_v1} 
For all sufficiently large integers $x \rightarrow \infty$, we have that 
\[
|G^{-1}(x)| \gg |G_E^{-1}(x)|. 
\]
\end{theorem} 
\begin{proof} 
First, consider the following upper bound on $|G_E^{-1}(x)|$: 
\begin{align} 
\notag 
|G_E^{-1}(x)| & = \left\lvert \sum_{\substack{e \leq n \leq (\log x)^{7/3} (\log\log x)}} \lambda(n) \times 
     \sum_{\substack{d|n \\ d > e}} \frac{(\log d)^{\frac{3}{4}}}{\log\log d} 
     \right\rvert \\ 
\notag 
     & \ll \sum_{e < d \leq (\log x)^{7/3} (\log\log x)} \frac{(\log d)^{\frac{3}{4}}}{\log\log d} \cdot 
     \Floor{(\log x)^{7/3} (\log\log x)}{d} \\ 
\notag 
     & \ll (\log x)^{7/3} (\log\log x) \times 
     \int_{e}^{(\log x)^{7/3} (\log\log x)} \frac{(\log t)^{\frac{3}{4}}}{t \cdot \log\log t} dt \\ 
\notag 
     & = (\log x)^{7/3} (\log\log x) \times 
     \operatorname{Ei}\left(\frac{7}{4} \log\log\left((\log x)^{7/3} (\log\log x)\right)\right) \\ 
\label{eqn_proof_tag_AbsGEInvx_AsymptoticUpperBound_v1} 
     & \ll (\log x)^{7/3} (\log\log x) (\log\log\log x)^2. 
\end{align} 
We need a couple of observations to sum $G^{-1}(x)$ in absolute value and bound it from below. 
First, as noted in \cite[\S 7.4]{MV}, the function $\mathcal{G}(z)$ from 
Theorem \ref{theorem_HatPi_ExtInTermsOfGz} satisfies 
\[
\mathcal{G}\left(\frac{k-1}{\log\log x}\right) = 1 + O(1), k \leq \log\log x, 
\]
so that uniformly for $1 \leq k \leq \log\log x$ we can write 
\[
\widehat{\pi}_k(x) \asymp \frac{x}{\log x} \cdot \frac{(\log\log x)^{k-1}}{(k-1)!} \left[ 
     1 + O\left(\frac{1}{\log\log x}\right)\right]. 
\]
Now by Corollary \ref{theorem_MV_Thm7.20}, the 
following summatory function represents the asymptotic main term 
in the summation $\sum_{n \leq x} \lambda(n)$ as $x \rightarrow \infty$: 
\begin{align*} 
\widehat{L}_2(x) & = \sum_{k=1}^{\log\log x} (-1)^{k} \widehat{\pi}_k(x) 
     = - \frac{x}{(\log x)^2} \cdot \Gamma(\log\log x, -\log\log x) \\ 
     & \sim \frac{(-1)^{\floor{\log\log x}} \cdot x}{\sqrt{2\pi} \sqrt{\log\log x}}
\end{align*} 
So by Abel summation and integration by parts, we obtain 
\begin{align*} 
|G^{-1}(x)| & = \left\lvert \int_2^x \widehat{L}_2^{\prime}(t) |g^{-1}(t)| dt \right\rvert \\ 
     & \gg \left\lvert \sum_{k=1}^{\frac{\log\log x}{2}} \left[ 
     \widehat{L}_2^{\prime}\left(e^{e^{2k}}\right) \left\lvert g^{-1}\left(e^{e^{2k}}\right) \right\rvert 
     e^{(1-e^{-1})e^{2k}} - 
     \widehat{L}_2^{\prime}\left(e^{e^{2k+1}}\right) \left\lvert g^{-1}\left(e^{e^{2k+1}}\right) \right\rvert 
     e^{(1-e^{-1})e^{2k+1}}\right] \right\rvert \\ 
     & \gg \left\lvert \int_{\frac{\log\log x}{2} - \frac{1}{2}}^{\frac{\log\log x}{2}} 
     \widehat{L}_2^{\prime}\left(e^{e^{2t}}\right) \left\lvert g^{-1}\left(e^{e^{2t}}\right) \right\rvert 
     e^{e^{2t}} dt \right\rvert 
     \gg 2t \cdot e^{2t} e^{e^{2t}} \Biggr\rvert_{t=\frac{\log\log x}{2} - \frac{1}{2}} \\ 
     & \gg x^{e^{-1}} \cdot (\log x) (\log\log x). 
\end{align*} 
In the previous equations, we have used the approximation argument to $g^{-1}(n)$ by its average order 
given by Corollary \ref{cor_ExpectationFormulaAbsgInvn_v2} 
based on the computation in \eqref{eqn_remark_ClosenessApproxgInvnByAvgOrder_v1}. 
So naturally from \eqref{eqn_proof_tag_AbsGEInvx_AsymptoticUpperBound_v1} we 
have proved that as $x \rightarrow \infty$, 
$|G^{-1}(x)| \gg |G_E^{-1}(x)|$. 
\end{proof} 

\begin{cor} 
\label{cor_ASemiForm_ForGInvx_v1} 
We have that for almost every sufficiently large $x$, that as $x \rightarrow \infty$ 
\begin{align*} 
\left\lvert G_E^{-1}(x) \right\rvert & \gg 
     \frac{(\log x)^{\frac{7}{4}} (\log\log x)^{\frac{5}{4}}}{ 
     \sqrt{\log\log\log x}} \times 
     \left\lvert \sum_{e < d \leq \log x} 
     \frac{\lambda(d) (\log d)^{\frac{3}{4}}}{d^{3/4} \cdot \log\log d} 
     \right\rvert. 
\end{align*} 
\end{cor} 
\NBRef{A10-2020.04-26} 
\begin{proof} 
Using the definition in \eqref{eqn_GEInvxSummatoryFuncDef_v1}, we obtain on average that\footnote{ 
     For any arithmetic functions $f,h$, we have that \cite[\cf \S 3.10; \S 3.12]{APOSTOLANUMT} 
     \[
     \sum_{n \leq x} h(n) \times \sum_{d|n} f(d) = \sum_{d \leq x} f(d) \times \sum_{n=1}^{\Floor{x}{d}} h(dn). 
     \] 
}
\begin{align*} 
\left\lvert G_E^{-1}(x) \right\rvert & = 
     \left\lvert \sum_{n \leq (\log x)^{7/3} (\log\log x)} \lambda(n) \times 
     \sum_{\substack{d|n \\ d > e}} \frac{(\log d)^{\frac{3}{4}}}{\log\log d} \right\rvert \\ 
     & = \left\lvert \sum_{e < d \leq (\log x)^{7/3} (\log\log x)} 
     \frac{(\log d)^{\frac{3}{4}}}{\log\log d} \times 
     \sum_{n=1}^{\Floor{(\log x)^{7/3} (\log\log x)}{d}} \lambda(dn) \right\rvert. 
\end{align*} 
We see that by complete additivity of $\Omega(n)$ 
(complete multiplicativity of $\lambda(n)$) that 
\begin{align*} 
\sum_{n=1}^{\Floor{x}{d}} \lambda(dn) & = \sum_{n=1}^{\Floor{x}{d}} \lambda(d) \times \lambda(n) 
     = \lambda(d) \times \sum_{n \leq \Floor{x}{d}} \lambda(n). 
\end{align*} 
From Theorem \ref{theorem_GFs_SymmFuncs_SumsOfRecipOfPowsOfPrimes} and 
Lemma \ref{lemma_lowerBoundsOnLambdaFuncParitySummFuncs} (see below), 
we can establish that 
\begin{align} 
\label{eqn_proof_tag_GEInvxLowerBound_v1} 
\left\lvert \sum_{k \leq \log\log x} (-1)^k \cdot \widehat{\pi}_k(x) \right\rvert 
     & \gg 
     \frac{x^{\frac{3}{4}} (\log x)^{\frac{1}{2}}}{\sqrt{\log\log x}} 
     =: \widehat{L}_0(x), \mathrm{\ as\ } x \rightarrow \infty. 
\end{align} 
The sign of the sum obtained by taking the right-hand-side of 
\eqref{eqn_proof_tag_GEInvxLowerBound_v1} without the 
absolute value operation is given by $(-1)^{1+\floor{\log\log x}}$. 
The precise formula for the 
limiting lower bound stated above for $\widehat{L}_0(x)$ is computed by symbolic summation 
in \emph{Mathematica} using the new bounds on $\widehat{\pi}_k(x)$ guaranteed by 
the theorem, and then by applying subsequent standard asymptotic estimates to the 
resulting formulas for large $x \rightarrow \infty$ 
in the form of \eqref{eqn_IncompleteGamma_PropB} and Stirling's formula. 
It follows that 
\begin{align} 
\label{eqn_proof_tag_GEInvxLowerBound_v2} 
|G_E^{-1}(x)| & \gg \left\lvert \sum_{e < d \leq (\log x)^{7/3} (\log\log x)} 
     \frac{\lambda(d) (\log d)^{\frac{3}{4}}}{\log\log d} \times 
     (-1)^{\floor{\log\log\left(\frac{(\log x)^{7/3} (\log\log x)}{d}\right)}} \cdot 
     \widehat{L}_0\left(\frac{(\log x)^{7/3} (\log\log x)}{d}\right) \right\rvert. 
\end{align} 
\textbf{Outline for the remainder of the proof.} 
We sketch the following steps remaining to prove our claimed lower bound on 
$|G_E^{-1}(x)|$: 
\begin{itemize}[itemsep=0pt,topsep=4pt,leftmargin=0.75in] 
\item[\textbf{(A)}] We identify an initial subinterval $\mathcal{R}_x$ where we can expect 
     constant sign term contributions resulting from the inputs to the function $\widehat{L}_0$ 
     involving both $(d, x)$ for $x$ large and $d$ on this smaller subinterval. 
\item[\textbf{(B)}] We factor out easily bounded terms from the expansion of the 
     monotone $\widehat{L}_0$ on this interval. 
\item[\textbf{(C)}] We determine additional asymptotic formulas we will 
     refer to in later sections for the resulting lower bounds on $|G_E^{-1}(x)|$ 
     that are formed by restricting the range of $d$ in 
     \eqref{eqn_proof_tag_GEInvxLowerBound_v2} to $\mathcal{R}_x$. 
\item[\textbf{(D)}] We argue 
     that the sums of oscillatory terms on the upper end of the deleted interval 
     for $d \in \left(e, (\log x)^{7/3} (\log\log x)\right] \setminus \mathcal{R}_x$ 
     cannot generate trivial bounds by cancellation with the new lower bounds. 
\end{itemize} 
\textbf{Part A.} 
We will simplify \eqref{eqn_proof_tag_GEInvxLowerBound_v2} by proving that there are 
ranges of consecutive integers over which we obtain essentially 
constant sign contributions from the 
function $\widehat{L}_0((\log x)^{7/3} (\log\log x) / d)$ as $x \rightarrow \infty$. 
In particular, consider that 
\begin{align*} 
\log\log\left(\frac{(\log x)^{7/3} (\log\log x)}{d}\right) & = 
     \log\log\left((\log x)^{7/3} (\log\log x)\right) \\ 
     & \phantom{=\ } + \log\left(1 - 
     \frac{\log d}{(\log x)^{7/3} (\log\log x) \log\left( 
     (\log x)^{7/3} (\log\log x)\right)}\right), 
     \mathrm{\ as\ } x \rightarrow \infty. 
\end{align*} 
If we take $d \in (e, \log x] =: \mathcal{R}_x$, we have that 
$$\frac{\log d}{(\log x)^{7/3} (\log\log x) \log\left( 
 (\log x)^{7/3} (\log\log x)\right)} = o(1) \rightarrow 0, \mathrm{\ as\ } 
 x \rightarrow \infty.$$  
For $d$ within $\mathcal{R}_x$, 
we expect that for almost every $x$ there are at most 
a handful of negligible cases of comparitively small order 
$d \leq d_{0,x}$ such that 
\[
\floor{\log\log\left(\frac{(\log x)^{7/3} (\log\log x)}{d}\right)} \sim 
     \floor{\log\log\left((\log x)^{7/3} (\log\log x)\right) + o(1)}, 
\]
changes in parity transitioning from $d \mapsto d+1$. 
An argument making this assertion precise brings leads us to 
two primary cases that rely on the small-order distribution of the fractional parts 
$f_x := \left\{\log\log\left((\log x)^{7/3} (\log\log x)\right)\right\}$ within $[0, 1)$ for 
large $x \rightarrow \infty$ and any $\log d \in \mathcal{R}_x$: 
\begin{itemize}[itemsep=0pt,topsep=0pt,leftmargin=0.35in] 
\item[\textbf{(1)}] If the fractional part 
     $f_x = 0$, then 
     \begin{align*} 
     \floor{\log\log\left(\frac{(\log x)^{7/3} (\log\log x)}{d}\right)} & = 
          \floor{\log\log\left((\log x)^{7/3} (\log\log x)\right)} \\ 
          & \phantom{=\ } + 
          \floor{-\frac{\log d}{(\log x)^{7/3} (\log\log x) \log\left( 
          (\log x)^{7/3} (\log\log x)\right)}}. 
     \end{align*} 
     This implies that provided that 
     \[
     -1 \leq -\frac{\log d}{(\log x)^{7/3} (\log\log x) \log\left( 
          (\log x)^{7/3} (\log\log x)\right)} < 0, 
     \]
     we obtain a constant multplier as 
     $\operatorname{sgn}\left(\widehat{L}_0\left(\frac{(\log x)^{7/3} (\log\log x)}{d}\right)\right)$ 
     whenever $d \in \mathcal{R}_x$. 
     Since $d$ is positive and maximized at $\log x$, 
     this condition clearly happens for any sufficiently large $x$. 
\item[\textbf{(2)}] If the fractional part $f_x \in (0, 1)$, then 
     \begin{align*} 
     & \floor{\log\log\left(\frac{(\log x)^{7/3} (\log\log x)}{d}\right)} = 
          \floor{\log\log\left((\log x)^{7/3} (\log\log x)\right)} \\ 
          & \phantom{\qquad =\ } + 
          \floor{\left\{\log\log\left((\log x)^{7/3} (\log\log x)\right)\right\} - 
          \frac{\log d}{(\log x)^{7/3} (\log\log x) \log\left( 
          (\log x)^{7/3} (\log\log x)\right)}}. 
     \end{align*} 
     Define shorthand notation for the function 
     $\mathcal{B}(x) := (\log x)^{7/3} (\log\log x) \log\left((\log x)^{7/3} (\log\log x)\right)$. 
     We require that 
     \begin{align*} 
     -1 & \leq f_x - \frac{\log d}{\mathcal{B}(x)} < 0 \iff 
          (1 + f_x) \cdot \mathcal{B}(x) \geq \log d > 0. 
     \end{align*} 
     This property is similarly clearly attained for $d \in \mathcal{R}_x$ 
     since $(1 + f_x) \cdot \mathcal{B}(x) \geq \mathcal{B}(x)$ 
     as $x \rightarrow \infty$ . 
\end{itemize} 
\textbf{Part B.} 
Provided that the sign term involving both $d$ and $x$ 
from \eqref{eqn_proof_tag_GEInvxLowerBound_v2} does not change for 
$d \in \mathcal{R}_x$, 
we can remove any oscillations in the sums due to sign changes in the monotonically 
decreasing function 
$\widehat{L}_0(d, x) := \widehat{L}_0\left((\log x)^{7/3} (\log\log x)/d\right)$. 
The function $\widehat{L}_0(d, x)$ is monotone decreasing 
in the variable $d$ for fixed $x$ as we sum along the 
subinterval $\mathcal{R}_x$ in ascending order. 
We can see that this function is decreasing 
in $d$ by computing its partial derivative and 
evaluating the asymptotic main terms as having a leading negative sign 
for all large $x$. 
Thus we should select $d := \log x$ in 
\eqref{eqn_proof_tag_GEInvxLowerBound_v2} to 
obtain a global lower bound on $|G_E^{-1}(x)|$ if we truncate the sum 
to range only over the subset of original indices $d \in \mathcal{R}_x$. \\ 
\textbf{Part C.} 
Let the magnitudes of the signed remainder term sums be 
defined for all sufficiently large $x$ by 
\[
R_E(x) := \left\lvert \sum_{\log x < d \leq \frac{(\log x)^{7/3} (\log\log x)}{e^2}} 
     \frac{\lambda(d) (\log d)^{\frac{3}{4}}}{\log\log d} \times 
     (-1)^{\floor{\log\log\left(\frac{(\log x)^{7/3} (\log\log x)}{d}\right)}} \cdot 
     \widehat{L}_0\left(\frac{(\log x)^{7/3} (\log\log x)}{d}\right) \right\rvert. 
\]
Set the function $T_E(x)$ to correspond to the 
easily factored dependence of the less simply integrable factors 
in $\widehat{L}_0(d, x)$ when we set $d := \log x$ on $\mathcal{R}_x$. 
This function is defined for all large enough $x$ as 
\begin{equation} 
\label{eqn_proof_tag_TExFuncDefAndBounds_v1} 
T_E(x) \gg \frac{\log\left[(\log x)^{4/3} (\log\log x)\right]^{\frac{1}{2}}}{ 
     \sqrt{\log\log\left[(\log x)^{4/3} (\log\log x)\right]}} \gg 
     \frac{(\log\log x)^{\frac{1}{2}}}{\sqrt{\log\log\log x}}. 
\end{equation} 
Then in limiting cases the lower bounding function satisfies 
\begin{align} 
\notag 
S_{E,1}(x) & := \left\lvert \sum_{e < d \leq (\log x)^{7/3} (\log\log x)} 
     \frac{\lambda(d) (\log d)^{\frac{3}{4}}}{\log\log d} \times 
     (-1)^{\floor{\log\log\left(\frac{(\log x)^{7/3} (\log\log x)}{d}\right)}} 
     \widehat{L}_0\left(\frac{(\log x)^{7/3} (\log\log x)}{d}\right) 
     \right\rvert \\ 
\label{eqn_proof_tag_SE1xFuncExp_v1} 
     & \gg 
     (\log x)^{\frac{4}{3}} (\log\log x) 
     T_E(x) \times 
     \left\lvert \sum_{e < d \leq \log x} 
     \frac{\lambda(d) (\log d)^{\frac{3}{4}}}{d^{3/4} \cdot \log\log d} 
     \right\rvert \\ 
\notag 
     & \gg 
     \frac{(\log x)^{\frac{4}{3}} (\log\log x)^{\frac{3}{2}}}{ 
     \sqrt{\log\log\log x}} \times 
     \left\lvert \sum_{e < d \leq \log x} 
     \frac{\lambda(d) (\log d)^{\frac{3}{4}}}{d^{3/4} \cdot \log\log d} 
     \right\rvert. 
\end{align} 
The formulas in 
\eqref{eqn_proof_tag_GEInvxLowerBound_v2} and \eqref{eqn_proof_tag_SE1xFuncExp_v1} 
imply the following lower bound by the triangle inequality 
as $x \rightarrow \infty$: 
\begin{align} 
\label{eqn_proof_tag_GEInvxLowerBound_v3}
|G_E^{-1}(x)| & \gg 
     \Biggl\lvert S_{E,1}(x) - R_E(x) \Biggr\rvert \gg S_{E,1}(x), \mathrm{\ as\ } 
     x \rightarrow \infty. 
\end{align} 
We have claimed that we can in fact drop the sum terms over upper range of 
$d \notin \mathcal{R}_x$ and still 
obtain the asymptotic lower bound on $|G_E^{-1}(x)|$ stated in 
\eqref{eqn_proof_tag_GEInvxLowerBound_v3}. 
To justify this step in the proof, 
we will provide limiting lower bounds on $R_E(x)$ that show that the 
contribution from the deleted interval in absolute value exceeds the magnitude of the 
corresponding sums over $d \in \mathcal{R}_x$ defined by 
$S_{E,1}(x)$ when $x$ is large. \\ 
\textbf{Part D.} 
We want to arrange the signed weight coefficients $\varepsilon_{x,d} \mapsto \{\pm 1\}$ 
so that the function 
\[
M_{\pm}(x) := \min\limits_{\varepsilon_{x,d} = \pm 1} 
     \left\lvert \sum_{\log x < d \leq \frac{(\log x)^{7/3} (\log\log x)}{e^2}} 
     \frac{\varepsilon_{x,d} \cdot 
     \lambda(d) (\log d)^{\frac{3}{4}}}{\log\log d} \times 
     \widehat{L}_0\left(\frac{(\log x)^{7/3} (\log\log x)}{d}\right) \right\rvert, 
\]
is minimal. We need to prove that this minimal sum exceeds the bound 
for $S_E(x)$ given in \eqref{eqn_proof_tag_SE1xFuncExp_v1} in asymptotic order. 
That is, we prove that 
\[
S_{E,1}^{(\ell)}(x) := 
     \frac{(\log x)^{\frac{4}{3}} (\log\log x)^{\frac{3}{2}}}{ 
     \sqrt{\log\log\log x}} \times 
     \left\lvert \sum_{e < d \leq \log x} 
     \frac{\lambda(d) (\log d)^{\frac{3}{4}}}{d^{3/4} \cdot \log\log d} 
     \right\rvert = o\left(M_{\pm}(x)\right), \mathrm{\ as\ } x \rightarrow \infty. 
\] 
Notice that by considering the sum term in the previous definition as being unsigned, 
we have that 
\begin{align} 
\notag 
S_{E,1}^{(\ell)}(x) & \ll \frac{(\log x)^{\frac{4}{3}} (\log\log x)^{\frac{3}{2}}}{ 
     \sqrt{\log\log\log x}} \times \int_e^{\log x} \frac{(\log t)^{3/4}}{t \cdot (\log\log t)} dt \\ 
\notag 
     & \ll \frac{(\log x)^{\frac{19}{12}} (\log\log x)^{\frac{3}{2}}}{ 
     \sqrt{\log\log\log x}} \times \operatorname{Ei}\left(\frac{7}{4} \log\log\log x\right) \\ 
\label{eqn_proof_tag_SE1Ellx_BoundFunc_MaximalOrder_v1} 
     & \ll (\log x)^{\frac{19}{12}} (\log\log x)^{\frac{3}{2}} (\log\log\log x)^{\frac{3}{2}}. 
\end{align} 
We need to show that $M_{\pm}(x)$ always exceeds this bound. 
Since the function $L_0(x, d)$ is decreasing in $d$ for 
$d \in \left(\log x, \frac{(\log x)^{7/3} (\log\log x)}{e^2}\right] =: \overline{\mathcal{R}}_x$, 
we obtain that 
\[
\widehat{L}_0\left(\frac{(\log x)^{5} (\log\log x)}{d}\right) \asymp
     \frac{(\log x) (\log\log x)^{5/4}}{d^{3/4} \cdot \sqrt{\log\log\log x}}, 
     d \in \overline{\mathcal{R}}_x. 
\]
So we need to find a global lower bound on the sum 
\[
S_{\pm}(x) := 
     \frac{(\log x) (\log\log x)^{5/4}}{\sqrt{\log\log\log x}} \times 
     \left\lvert \sum_{\log x < d \leq \frac{(\log x)^{7/3} (\log\log x)}{e^2}} 
     \frac{\varepsilon_{x,d} \cdot 
     \lambda(d) (\log d)^{\frac{3}{4}}}{d^{3/4} \cdot \log\log d} \right\rvert, 
\]
that holds for any choice of the signed weights $\varepsilon_{x,d}$. 
Notice that for any $d > \log x$ and $\delta \geq 1$, by an expansion of 
convergent geometric and binomial series, the next 
difference of terms satisfies 
\begin{align*} 
 & \left\lvert \frac{(\log d)^{\frac{3}{4}}}{d^{\frac{3}{4}} \cdot (\log\log d)} - 
     \frac{\log(d + \delta)^{\frac{3}{4}}}{(d + \delta)^{\frac{3}{4}} \cdot \log\log(d + \delta)} 
     \right\rvert \\ 
     & \qquad \sim 
     \frac{\log(d + \delta)^{\frac{3}{4}}}{(d + \delta)^{\frac{3}{4}} \cdot \log\log(d + \delta)} \times 
     \left\lvert 
     \frac{\left(1 - \frac{\delta}{\log(d + \delta)}\right)^{\frac{3}{4}}}{ 
     \left(1 - \frac{\delta}{(d + \delta)}\right)^{\frac{3}{4}} 
     \left(1 - \frac{\delta}{(d + \delta) \log(d + \delta) \log\log(d + \delta)}\right)} - 1 
     \right\rvert \\ 
     & \qquad \gg \frac{\delta}{(d + \delta)^{\frac{3}{4}} \log^{\frac{1}{4}}(d + \delta) 
     \log\log(d + \delta)}. 
\end{align*} 
Let the number of sign changes of the terms in our sum on the interval 
$\overline{\mathcal{R}}_x$ be defined by 
\[
N_x := \#\left\{d \in \overline{\mathcal{R}}_x: 
     \varepsilon_{x,d+1} \lambda(d+1) = -\varepsilon_{x,d} \lambda(d)\right\}. 
\] 
Define the maximum (minimum) number of consecutively signed terms on this interval to be 
$\delta_{\max}(x), \delta_{\min}(x) \geq 1$. 
Then by the difference property we noted above, we have that for 
$t_k(x) := \log x + (2k+2) \delta_{\max}(x)$ 
\begin{align*} 
\frac{S_{\pm}(x) \sqrt{\log\log\log x}}{(\log x) (\log\log x)^{5/4}} & 
     \gg \left\lvert \sum_{k=0}^{\frac{N_x}{2}} \frac{\delta_{\min}(x)}{t_k(x)^{\frac{3}{4}} 
     \log(t_k(x))^{\frac{1}{4}} \log\log(t_k(x))} - 
     \frac{\log^{\frac{3}{4}}(N_x)}{N_x^{\frac{3}{4}} \log\log(N_x)} \right\rvert \\ 
     & 
     \gg \left\lvert \sum_{k=0}^{\frac{N_x}{2}} \frac{t_0(x)^{\frac{1}{4}} \cdot \delta_{\min}(x)}{t_k(x)  
     \log(t_k(x))^{\frac{1}{4}} \log\log(t_k(x))} - 
     \frac{\log^{\frac{3}{4}}(N_x)}{N_x^{\frac{3}{4}} \log\log(N_x)} \right\rvert \\ 
     & \gg (\log x + 2 \delta_{\max}(x))^{1/4} \times \int_0^{\frac{N_x}{2}} 
     \frac{dk}{t_k(x) \log(t_k(x))^{\frac{1}{4}} \log\log(t_k(x))} \\ 
     & \gg (\log x + 2 \delta_{\max}(x))^{1/4} \times \frac{\log\log\log(t_{\frac{N_x}{2}}(x))}{2 \delta_{\max}(x)}. 
\end{align*} 
Now because $\delta_{\max}(x) \in [1, u_x - N_x]$ for $u_x := (\log x)^{7/3} (\log\log x)$, 
we have that 
\begin{align} 
\label{eqn_proof_tag_SpmxScaledRHSBound_v3} 
\frac{S_{\pm}(x) \sqrt{\log\log\log x}}{(\log x) (\log\log x)^{5/4}} & \gg 
     \log x \times \frac{\log\log\log((u_x - \delta_{\max}(x)) 
     \delta_{\max}(x))}{(u_x - \delta_{\max}(x)) \delta_{\max}(x))} 
\end{align} 
By differentiating the right-hand-side of the previous equation scaled by 
$(\log x)^{-1}$, setting the derivative equal to zero, and 
solving a differential equation for $\delta_{\max}(x)$, we see that a lower bound occurs 
when $\delta_{\max}(x) = C$ or when $\delta_{\max}(x) \approx u_x$. In either case, we see that the 
right-hand-side of \eqref{eqn_proof_tag_SpmxScaledRHSBound_v3} is non-negligible. 
This property clearly implies that $S_{\pm}(x)$ is asymptotically larger than the 
maximum order bound on $S_{E,1}^{(\ell)}(x)$ we proved above in 
\eqref{eqn_proof_tag_SE1Ellx_BoundFunc_MaximalOrder_v1}. 
\end{proof} 

\newpage 
\section{Lower bounds for $M(x)$ along infinite subsequences} 
\label{Section_KeyApplications} 

\subsection{Expanding the new formula for $M(x)$} 

\begin{prop} 
\label{prop_Mx_SBP_IntegralFormula} 
For all sufficiently large $x$, we have that 
\begin{align} 
\label{eqn_pf_tag_v2-restated_v2} 
M(x) & = G^{-1}(x) + G^{-1}\left(\frac{x}{2}\right) - 
     \sum_{k=1}^{\sqrt{x}} G^{-1}(k) \left[ 
     \pi\left(\Floor{x}{k}\right) - \pi\left(\Floor{x}{k+1}\right) 
     \right]. 
\end{align} 
\end{prop} 
\begin{proof} 
We know by applying Corollary \ref{cor_Mx_gInvnPixk_formula} that 
\begin{align} 
\notag
M(x) & = \sum_{k=1}^{x} g^{-1}(k) \left(\pi\left(\Floor{x}{k}\right)+1\right) \\ 
\label{eqn_proof_tag_MxFormulaInitSepTerms_v1} 
     & = G^{-1}(x) + \sum_{k=1}^{x/2} g^{-1}(k) \pi\left(\Floor{x}{k}\right) \\ 
     & = G^{-1}(x) + G^{-1}\left(\frac{x}{2}\right) - 
     \sum_{k=1}^{x/2-1} G^{-1}(k) \left[ 
     \pi\left(\Floor{x}{k}\right) - \pi\left(\Floor{x}{k+1}\right) 
     \right] 
\end{align} 
where the upper bound on the sum is truncated by the fact that $\pi(1) = 0$. 
We see that 
\[
\frac{x}{k} - \frac{x}{k+1} = \frac{x}{k(k+1)} \sim \frac{x}{k^2}, 
\]
so that $\frac{x}{k^2} \geq 1$ $\implies$ $k \leq \sqrt{x}$. 
Thus we can re-write the latter sum to obtain 
\begin{align*} 
\notag
M(x) & = G^{-1}(x) + G^{-1}\left(\frac{x}{2}\right) - 
     \sum_{k=1}^{\sqrt{x}} G^{-1}(k) \left[ 
     \pi\left(\Floor{x}{k}\right) - \pi\left(\Floor{x}{k+1}\right) 
     \right].
\end{align*} 
We will require more assumptions and information about the behavior 
of the summatory functions, $G^{-1}(x)$, before we can further bound and 
simplify this expression for $M(x)$. 
\end{proof} 

\subsubsection{A few more necessary results} 
\label{subsubSection_RoutineProofsNeededForMainBoundOnGInvxFunc} 

We now use the superscript and subscript notation of 
$(\ell)$ not to denote a formal parameter to 
the functions we define below, but instead to denote that these functions form 
\emph{lower bound} (rather than exact) 
approximations to other forms of the functions without the scripted $(\ell)$. 

\begin{lemma} 
\label{lemma_lowerBoundsOnLambdaFuncParitySummFuncs} 
Suppose that $\widehat{\pi}_k^{(\ell)}(x) = o\left(\widehat{\pi}_k(x)\right)$ where 
$\widehat{\pi}_k^{(\ell)}(x) \geq 1$ 
for all integers $1 \leq k \leq \log\log x$ as $x \rightarrow \infty$. 
Let the weighted summatory functions be defined as 
\begin{align*} 
A_{\Omega}^{(\ell)}(x) & := \sum_{k \leq \log\log x} (-1)^k \widehat{\pi}_k^{(\ell)}(x) \\ 
A_{\Omega}(x) & := \sum_{k \leq \log\log x} (-1)^k \widehat{\pi}_k(x). 
\end{align*} 
Futhermore, suppose that $|A_{\Omega}(x)| \nrightarrow 0$ as $x \rightarrow \infty$ and that 
\begin{align*} 
\liminf_{k \rightarrow \infty} \frac{\widehat{\pi}_k^{(\ell)}(x)}{\widehat{\pi}_k(x)} & \geq 
     x^{-\rho_0} \\ 
\limsup_{k \rightarrow \infty} \frac{\widehat{\pi}_k^{(\ell)}(x)}{\widehat{\pi}_k(x)} & \leq 
     x^{-\rho_1}, 
\end{align*} 
as $x \rightarrow \infty$ for some $\rho_0, \rho_1 > 0$. 
Then for all sufficiently large $x$, we have that 
$$|A_{\Omega}(x)| \gg |A_{\Omega}^{(\ell)}(x)|.$$ 
\end{lemma} 
\begin{proof} 
By the second conditions above, we find that 
\begin{align*} 
\left\lvert A_{\Omega}(x) - A_{\Omega}^{(\ell)}(x) \right\rvert & \leq 
     |A_{\Omega}(x)| \left(1 - \inf_{1 \leq k \leq \log\log x} 
     \frac{\widehat{\pi}_k^{(\ell)}(x)}{\widehat{\pi}_k(x)}\right) = 
     |A_{\Omega}(x)| (1 + o(1)) \\ 
\left\lvert A_{\Omega}(x) - A_{\Omega}^{(\ell)}(x) \right\rvert & \geq 
     |A_{\Omega}(x)| \left(1 - \sup_{1 \leq k \leq \log\log x} 
     \frac{\widehat{\pi}_k^{(\ell)}(x)}{\widehat{\pi}_k(x)}\right) = 
     |A_{\Omega}(x)| (1 + o(1)). 
\end{align*} 
Similarly, we can see that 
\[
|A_{\Omega}(x)| (1 + o(1)) \leq \left\lvert A_{\Omega}(x) + A_{\Omega}^{(\ell)}(x) \right\rvert 
     \leq |A_{\Omega}(x)| (1 + o(1)). 
\]
This implies that 
\[
|A_{\Omega}(x)|(1+o(1)) \ll \left\lvert |A_{\Omega}(x)| \pm |A_{\Omega}^{(\ell)}(x)| \right\rvert \ll 
     |A_{\Omega}(x)|(1+o(1)), \mathrm{\ as\ } x \rightarrow \infty. 
\]
Because we have that 
$|A_{\Omega}(x)| \nrightarrow 0$, the previous equation shows that 
$|A_{\Omega}^{(\ell)}(x)|$ is bounded above and below by a constant times 
$|A_{\Omega}(x)|$. In other words, $|A_{\Omega}(x)| \gg |A_{\Omega}^{(\ell)}(x)|$ whenever 
$x$ is sufficiently large. 
\end{proof} 

\begin{proof}[Proof of Lemma \ref{lemma_CLT_and_AbelSummation}] 
We can form an accurate $C^{1}(\mathbb{R})$ approximation by the smoothness of 
$\widehat{\pi}_k^{(\ell)}(x)$ that allows us to apply the Abel summation formula using the summatory 
function $A_{\Omega}(t)$ for $t$ on any bounded connected subinterval of $[1, \infty)$. 
Namely, we obtain 
\begin{align} 
\notag 
|F_{\lambda}(x)| & \gg 
     \left\lvert A_{\Omega}(x) f(x) - \int_{u_0}^{x} 
     A_{\Omega}(t) f^{\prime}(t) dt \right\rvert \\ 
\label{eqn_Flambdax_RHA_AbelSummationFormula_v2} 
     & \gg 
     \left\lvert |A_{\Omega}(x) f(x)| - \int_{u_0}^{x} 
     |A_{\Omega}(t) f^{\prime}(t)| dt \right\rvert \\ 
\notag 
     & \gg 
     \left\lvert |A_{\Omega}^{(\ell)}(x) \widehat{\tau}_{\ell}(x)| - \int_{u_0}^{x} 
     |A_{\Omega}(t) f^{\prime}(t)| dt \right\rvert. 
\end{align} 
The stated lower bound formula for $|F_{\lambda}(x)|$ in 
\eqref{eqn_Flambdax_RHA_AbelSummationFormula_v2} 
above is valid  whenever 
\[
0 \leq \left\lvert \frac{\displaystyle\sum\limits_{\log\log t < k \leq \frac{\log t}{\log 2}} 
     (-1)^k \widehat{\pi}_k(t)}{A_{\Omega}(t)}\right\rvert \ll 2, 
     \mathrm{\ as\ } t \rightarrow \infty, 
\]
Indeed, by Corollary \ref{theorem_MV_Thm7.20}, we have that 
the assertion above holds as $t \rightarrow \infty$.  

Let the function 
\[
\widehat{I}_{\ell}(x) := \int_{\frac{\log\log x}{2} - \frac{1}{2}}^{\frac{\log\log x}{2}} 
     \left\lvert A_{\Omega}^{(\ell)}\left(e^{e^{2t}}\right) 
     \widehat{\tau}_{\ell}^{\prime}\left(e^{e^{2t}}\right) 
     \right\rvert e^{e^{2t}} dt. 
\]
We have to argue that following property of this function holds as $x \rightarrow \infty$: 
$$\int_{u_0}^{x} 
     |A_{\Omega}(t) f^{\prime}(t)| dt \gg \widehat{I}_{\ell}(x).$$
To prove the property in the previous equation, observe that by hypothesis since 
$|A_{\Omega}(x)| \gg |A_{\Omega}^{(\ell)}(x)|$ as $x \rightarrow \infty$, 
we have that 
\begin{align*} 
\int_{u_0}^{x} |A_{\Omega}(t) f^{\prime}(t)| dt & \gg 
     \int_{u_0}^{x} |A_{\Omega}(t) \widehat{\tau}_{\ell}^{\prime}(t)| dt \\ 
     & \gg \left\lvert \sum_{k=u_0}^{\log\log x} (-1)^{k} 
     \left\lvert A_{\Omega}\left(e^{e^{k}}\right) 
     \widehat{\tau}_{\ell}^{\prime}\left(e^{e^{k}}\right) \right\rvert \cdot \left( 
     e^{e^{k}} - e^{e^{k-1}}\right) \right\rvert \\ 
     & \gg \left\lvert \sum_{k=u_0}^{\frac{\log\log x}{2}} \left[ 
     \left\lvert A_{\Omega}\left(e^{e^{2k}}\right) 
     \widehat{\tau}_{\ell}^{\prime}\left(e^{e^{2k}}\right) \right\rvert \cdot e^{e^{2k}} - 
     \left\lvert A_{\Omega}\left(e^{e^{2k-1}}\right) 
     \widehat{\tau}_{\ell}^{\prime}\left(e^{e^{2k-1}}\right) \right\rvert \cdot e^{e^{2k-1}} 
     \right] \right\rvert \\ 
     & \gg 
     \int_{\frac{\log\log x}{2} - \frac{1}{2}}^{\frac{\log\log x}{2}} 
     \left\lvert A_{\Omega}\left(e^{e^{2t}}\right) 
     \widehat{\tau}_{\ell}^{\prime}\left(e^{e^{2t}}\right) 
     \right\rvert e^{e^{2t}} dt \\ 
     & \gg 
     \int_{\frac{\log\log x}{2} - \frac{1}{2}}^{\frac{\log\log x}{2}} 
     \left\lvert A_{\Omega}^{(\ell)}\left(e^{e^{2t}}\right) 
     \widehat{\tau}_{\ell}^{\prime}\left(e^{e^{2t}}\right) 
     \right\rvert e^{e^{2t}} dt. 
     \qedhere 
\end{align*} 
\end{proof} 

\begin{cor} 
\label{cor_CondsOnCentralBoundingFuncs_v3} 
Let the smooth bounding functions be defined for large $t \gg e$ as 
\begin{align*} 
\widehat{\tau}_{\ell}(t) & := \frac{(\log t)^{\frac{3}{4}}}{t^{\frac{3}{4}} \cdot (\log\log t)},  \\ 
A_{\Omega}^{(\ell)}(t) & := 
     \frac{t^{\frac{3}{4}} (\log t)^{\frac{1}{2}}}{\sqrt{\log\log t}}. 
\end{align*} 
Then we have that as $x \rightarrow \infty$ 
\[
|G_E^{-1}(x)| \gg 
     \frac{(\log x)^{7/4} (\log\log x)^{5/4}}{\sqrt{\log\log\log x}} \times 
     \left\lvert A_{\Omega}^{(\ell)}(\log x) \widehat{\tau}_{\ell}(\log x) - 
     \int_{\frac{\log\log\log x}{2} - \frac{1}{2}}^{\frac{\log\log\log x}{2}} 
     A_{\Omega}^{(\ell)}\left(e^{e^{2t}}\right) 
     \widehat{\tau}_{\ell}\left(e^{e^{2t}}\right) e^{e^{2t}} dt
     \right\rvert. 
\]
\end{cor} 
\begin{proof} 
By Corollary \ref{cor_ASemiForm_ForGInvx_v1}, we have that 
\begin{equation} 
\label{eqn_proof_tag_AbsGEInvLowerBoundByAbelSummation_v1} 
|G_E^{-1}(x)| \gg 
     \frac{(\log x)^{7/4} (\log\log x)^{5/4}}{\sqrt{\log\log\log x}} \times 
     \left\lvert \sum_{e < d \leq \log x} \frac{\lambda(d) (\log d)^{3/4}}{ 
     d^{3/4} \cdot \log\log d} \right\rvert, 
     \mathrm{\ as\ } x \rightarrow \infty.  
\end{equation} 
The crux of the remainder of the proof boils down to checking hypotheses in 
Lemma \ref{lemma_lowerBoundsOnLambdaFuncParitySummFuncs} and 
Lemma \ref{lemma_CLT_and_AbelSummation}. 

We first apply Lemma \ref{lemma_lowerBoundsOnLambdaFuncParitySummFuncs} with 
the lower bound function resulting from 
Theorem \ref{theorem_GFs_SymmFuncs_SumsOfRecipOfPowsOfPrimes} as follows: 
\[
\widehat{\pi}_k^{(\ell)}(x) \asymp  
     \frac{x^{\frac{3}{4}}}{\sqrt{\log x}} \cdot 
     \frac{(\log\log x)^{k-1}}{(k-1)!}. 
\] 
This shows that the necessary hypotheses on the function 
$A_{\Omega}^{(\ell)}(t)$ required by 
Lemma \ref{lemma_CLT_and_AbelSummation} 
are satisfied according to the sums for the function 
approximated by \eqref{eqn_proof_tag_GEInvxLowerBound_v1} for large $t$. 
This argument proves that all of the requirements in 
Lemma \ref{lemma_CLT_and_AbelSummation} 
on our choice of $\widehat{\tau}_{\ell}(t)$ are also satisfied. 
So the stated result follows from 
\eqref{eqn_proof_tag_AbsGEInvLowerBoundByAbelSummation_v1} and 
Lemma \ref{lemma_CLT_and_AbelSummation}. 
\end{proof} 

\subsubsection{The proof of a central lower bound on the magnitude of $G_{E}^{-1}(x)$} 

The next central theorem is the last barrier required to prove 
Theorem \ref{cor_ThePipeDreamResult_v1} 
in the next subsection. 
Combined with Theorem \ref{theorem_GInvxLowerBoundByGEInvx_v1} 
proved in the last section, the new lower bounds we establish below provide us 
with a sufficient mechanism to bound the formula from 
Proposition \ref{prop_Mx_SBP_IntegralFormula}. 

\begin{theorem}[Asymptotics and bounds for the summatory function $G^{-1}(x)$] 
\label{theorem_gInv_GeneralAsymptoticsForms}
We obtain the following limiting estimate for the bounding function 
$G_{E}^{-1}(x)$ as $x \rightarrow \infty$: 
\textbf{(TODO) ... } 
\begin{align*} 
 & \left\lvert G_{E}^{-1}\left(x\right) \right\rvert
     \gg \frac{(\log x)^{5/4}}{ 
     \sqrt{\log\log x} \cdot (\log\log\log x)^2}. 
\end{align*} 
\end{theorem} 
\NBRef{A10-2020.04-26} 
\begin{proof} 
We can form a lower summatory function indicating the signed contributions over the distinct 
parity of $\Omega(n)$ for all $n \leq x$ as follows by applying 
\eqref{eqn_IncompleteGamma_PropA} and Stirling's approximation as already noted in the 
proof of Corollary \ref{cor_ASemiForm_ForGInvx_v1}: 
\begin{align} 
\label{proof_thm_GInvFunc_v0} 
\left\lvert A_{\Omega}^{(\ell)}(t) \right\rvert & = 
     \left\lvert \sum_{k \leq \log\log t} (-1)^k \widehat{\pi}_k(t) \right\rvert 
     \gg 
     \frac{t^{\frac{3}{4}} (\log t)^{1/2}}{\sqrt{\log\log t}}, 
     \mathrm{\ as\ } t \rightarrow \infty. 
\end{align} 
We select the functions 
$\widehat{\tau}_0(t) := \frac{(\log t)^{3/4}}{t^{3/4} \cdot \log\log t}$ and 
compute the main term of its derivative 
in the form of the next equation using 
the notation in Corollary \ref{cor_CondsOnCentralBoundingFuncs_v3}. 
\begin{align} 
\label{eqn_HatTauPrimet_summation_weight_func_exp_v2} 
-\widehat{\tau}_0^{\prime}(t) & = -\frac{d}{dt}\left[ 
     \frac{(\log t)^{\frac{3}{4}}}{t^{\frac{3}{4}} (\log\log t)} 
     \right] \gg \frac{(\log t)^{3/4}}{t^{\frac{7}{4}} (\log\log t)} 
\end{align} 
Moreover, we have that we can select 
the initial form of the lower bound to be defined as follows: 
\begin{align} 
\label{proof_thm_GInvFunc_v1} 
G_{E}^{-1}(x) & \gg 
     \frac{(\log x)^{7/4} (\log\log x)^{5/4}}{\sqrt{\log\log\log x}} \times \\ 
\notag 
     & \phantom{:=\qquad\ } \times 
     \left\lvert A_{\Omega}^{(\ell)}(\log x) \widehat{\tau}_0(\log x) - 
     \int_{\frac{\log\log\log x}{2}-\frac{1}{2}}^{\frac{\log\log\log x}{2}} 
     \left\lvert 
     A_{\Omega}^{(\ell)}\left(e^{e^{2t}}\right) \widehat{\tau}_0^{\prime}\left(e^{e^{2t}}\right) 
     \right\rvert e^{e^{2t}} dt 
     \right\rvert. 
\end{align} 
We express the integrand function as the following function of $t$: 
\begin{equation} 
\label{eqn_proof_thm_GInvFunc_v3v2_approx} 
\widehat{I}_{\ell}(t) := \left\lvert 
     A_{\Omega}^{(\ell)}\left(e^{e^{2t}}\right) \widehat{\tau}_0^{\prime}\left(e^{e^{2t}}\right) 
     \right\rvert e^{e^{2t}} \asymp \frac{e^{5t/2}}{t^{3/2}}. 
\end{equation} 
We find from the mean value theorem applied to the monotone function from 
\eqref{eqn_proof_thm_GInvFunc_v3v2_approx} that 
\begin{align} 
\label{eqn_proof_thm_GInvFunc_v4_approx} 
\frac{(\log x)^{7/4} (\log\log x)^{5/4}}{\sqrt{\log\log\log x}} \times 
     \int_{\frac{\log\log\log x}{2}-\frac{1}{2}}^{\frac{\log\log\log x}{2}} 
     \widehat{I}_{\ell}(t) dt & \asymp 
     \widehat{I}_{\ell}\left(\frac{\log\log\log x}{2}-\frac{1}{2}\right) 
     \asymp \frac{(\log x)^{7/4} (\log\log x)^{5/2}}{(\log\log\log x)^2}. 
\end{align} 
Consider the following expansion for the leading term in 
the Abel summation formula from \eqref{proof_thm_GInvFunc_v1} for comparison with 
\eqref{eqn_proof_thm_GInvFunc_v4_approx}: 
\begin{align} 
\label{eqn_proof_thm_GInvFunc_v5_approx} 
 & \frac{(\log x)^{7/4} (\log\log x)^{5/4}}{\sqrt{\log\log\log x}} \times 
     \left\lvert A_{\Omega}^{(\ell)}(\log x) \widehat{\tau}_0(\log x) \right\rvert 
     \gg 
     \frac{(\log x)^{5/4} (\log\log x)^{5/2}}{(\log\log\log x)^2}
\end{align} 
Hence, we conclude that we can take $\left\lvert G_{E}^{-1}\left(x\right) \right\rvert$ 
bounded below by the difference of terms in 
\eqref{eqn_proof_thm_GInvFunc_v5_approx} and 
\eqref{eqn_proof_thm_GInvFunc_v4_approx}. 
\end{proof} 

\subsection{Proof of the unboundedness of the scaled Mertens function}
\label{subSection_TheCoreResultProof} 

\begin{lemma}
\label{lemma_PrimePix_ErrorBoundDiffs_SimplifyingConditions_v1} 
For sufficiently large $x$ we have that 
\begin{equation} 
\tag{A} 
\sum_{k=1}^{\sqrt{x}} G^{-1}(k)\left[\frac{x}{k \cdot \log\left(\frac{x}{k}\right)} - 
     \frac{x}{(k+1) \cdot \log\left(\frac{x}{k+1}\right)}\right] \sim 
     \sum_{k=1}^{\sqrt{x}} G^{-1}(k)\left[\frac{x}{k \cdot \log\left(\frac{x}{k}\right)} - 
     \frac{x}{(k+1) \cdot \log\left(\frac{x}{k}\right)}\right], 
\end{equation} 
and 
\begin{equation} 
\tag{B} 
\sum_{k=1}^{\sqrt{x}} G^{-1}(k)\left[\frac{x}{k \cdot \log\left(\frac{x}{k}\right)} - 
     \frac{x}{(k+1) \cdot \log\left(\frac{x}{k+1}\right)}\right] \approx 
     \sum_{k=1}^{\sqrt{x}} G^{-1}(k) \frac{x}{k^2 \cdot \log(x/k)}. 
\end{equation} 
\end{lemma} 
\begin{proof}[Proof of (A)] 
Indeed, this step is justified by writing 
\begin{align*} 
\frac{x}{(k+1) \log\left(\frac{x}{k+1}\right)} & = \frac{x}{k+1} \cdot 
     \frac{1}{\left[\log\left(\frac{x}{k}\right) + \log\left(1 - \frac{1}{k+1}\right)\right]} 
     = \frac{x}{(k+1) \log\left(\frac{x}{k}\right)} \cdot 
     \frac{1}{1 + \frac{\log\left(1 - \frac{1}{k+1}\right)}{\log x \left[ 
     1 - \frac{\log k}{\log x}\right]}} \\ 
     & \sim \frac{x}{(k+1) \log\left(\frac{x}{k}\right)}, \mathrm{\ as\ } x \rightarrow \infty. 
     \qedhere 
\end{align*} 
\end{proof} 
\begin{proof}[Proof of (B)] 
The correctness of this step is 
verified by seeing that for $\Re(s) > 1$, we have that 
\[
\left\lvert \sum_{k \geq 1} \frac{G^{-1}(k)}{k^{s+1}} \right\rvert = 
      \left\lvert \int_1^{\infty} \frac{G^{-1}(x)}{x^{s+1}} dx \right\rvert = 
      \left\lvert \frac{1}{s \cdot (P(s) + 1) \zeta(s)} \right\rvert < 
      \infty. 
\]
When $s := \frac{3}{2}$, we obtain that 
\[
0 \leq \left\lvert \sum_{k \geq 1} \frac{G^{-1}(k)}{k^{2} (k+1)} \right\rvert \leq 
     \left\lvert \sum_{k \geq 1} \frac{G^{-1}(k)}{k^{\frac{5}{2}}} \right\rvert < \infty. 
\]
The difference of the terms in forming the approximation in this step 
is bounded above and below by absolute constants as 
\[
\left\lvert \sum_{k=1}^{\frac{x}{2}} G^{-1}(k) \left[\frac{1}{k^2} - \frac{1}{k(k+1)}\right] \right\rvert \leq 
     \left\lvert\sum_{k=1}^{\frac{x}{2}} \frac{G^{-1}(k)}{k^2 (k+1)} \right\rvert = O(1). 
     \qedhere
\]
\end{proof} 

We finally address the main conclusion of our arguments given so far with the 
following proof: 

\begin{proof}[Proof of Theorem \ref{cor_ThePipeDreamResult_v1}] 
\label{proofOf_cor_ThePipeDreamResult_v1} 
Define the infinite increasing subsequence, 
$\{x_{0,y}\}_{y \geq Y_0}$, by $x_{0,y} := e^{2e^{e^{2y+1}}}$ for the sequence indices $y$ 
starting at some sufficiently 
large finite integer $Y_0 \gg 1$. 
We can verify that for sufficiently large $y \rightarrow \infty$, this infinitely 
tending subsequence is well defined as $x_{0,y+1} > x_{0,y}$ whenever $y \geq Y_0$. 
Given a fixed large infinitely tending $y$, we have some (at least one) point 
$\widehat{x}_0 \in \left[\sqrt{x}, \frac{x}{2}\right]$ defined such that 
$|G^{-1}(t)|$ is minimal and non-vanishing on the interval 
$\mathbb{X}_y := (\sqrt{x_{0,y}}, \sqrt{x_{0,y+1}}]$ 
in the form of 
\[
\left\lvert G^{-1}(\widehat{x}_0) \right\rvert := 
     \min_{\substack{\sqrt{x_{0,y}} < t \leq \sqrt{x_{0,y+1}} \\ G^{-1}(t) \neq 0}} |G^{-1}(t)|. 
\] 
Let the shorthand notation $|G_{\min}^{-1}(x_y)| := |G^{-1}(\widehat{x_0})|$. 
In the last step, we observe that $G^{-1}(x) = 0$ for $x$ on a set of 
asymptotic density \emph{at least} bounded below by $\frac{1}{2}$, so that our 
claim is accurate as the integrand lower bound on this interval 
does not trivially vanish at large $y$. This happens since the sequence 
$g^{-1}(n)$ is non-zero for all $n \geq 1$, so that if we do encounter a zero of the 
summatory function at $x$, we find a non-zero function value at $x+1$. 

We need to bound the prime counting function differences in the formula given by 
Proposition \ref{prop_Mx_SBP_IntegralFormula} in tandem with enforcing minimal values of the 
absolute value of $G^{-1}(k)$ for $k \in \mathbb{X}_y$. 
We will require the following known bounds on the prime counting 
function due to Rosser and Schoenfeld \cite[Thm.\ 1]{ROSSER-SCHOENFELD-1962} 
for large $x \gg 59$: 
\begin{equation} 
\label{eqn_RosserSchoenfeld_PrimePixBounds_v2} 
\frac{x}{\log x}\left(1 + \frac{1}{2\log x}\right) \leq \pi(x) \leq 
     \frac{x}{\log x}\left(1 + \frac{3}{2 \log x}\right). 
\end{equation} 
Let the component function $U_M(y)$ be defined for all large $y$ as 
\[
U_M(y) := -\sum_{k=1}^{\sqrt{\hat{x}_{0,y+1}}} |G^{-1}(k)| \left[ 
     \pi\left(\frac{\hat{x}_{0,y+1}}{k}\right) - 
     \pi\left(\frac{\hat{x}_{0,y+1}}{k+1}\right)
     \right]. 
\]
Combined with Lemma \ref{lemma_PrimePix_ErrorBoundDiffs_SimplifyingConditions_v1}, 
these estimates on $\pi(x)$ lead to the following approximations that hold on the 
increasing sequences taken within the subintervals defined by $\widehat{x}_0$: 
\begin{align*} 
U_M(y) & \gg -\sum_{k=1}^{\sqrt{\hat{x}_{0,y+1}}} |G^{-1}(k)| \left[ 
     \frac{\hat{x}_{0,y+1}}{k \cdot \log\left(\frac{\hat{x}_{0,y+1}}{k}\right)} + 
     \frac{\hat{x}_{0,y+1}}{2k \cdot \log^2\left(\frac{\hat{x}_{0,y+1}}{k}\right)} - 
     \frac{\hat{x}_{0,y+1}}{(k+1) \cdot \log\left(\frac{\hat{x}_{0,y+1}}{k+1}\right)} - 
     \frac{3 \hat{x}_{0,y+1}}{2(k+1) \cdot \log^2\left(\frac{\hat{x}_{0,y+1}}{k+1}\right)}
     \right] \\ 
     & \sim 
     -\sum_{k=1}^{\sqrt{\hat{x}_{0,y+1}}} |G^{-1}(k)| \left[ 
     \frac{\hat{x}_{0,y+1}}{k^2 \cdot \log\left(\frac{\hat{x}_{0,y+1}}{k}\right)} + 
     \frac{\hat{x}_{0,y+1}}{2 k^2 \cdot \log^2\left(\frac{\hat{x}_{0,y+1}}{k}\right)} 
     \right] \\ 
     & \gg -\sum_{k=1}^{\sqrt{\hat{x}_{0,y+1}}} \frac{\hat{x}_{0,y+1} \cdot |G^{-1}(k)|}{k^2} \left[ 
     \frac{1}{\log(\hat{x}_{0,y+1})} + \frac{1}{2 \log^2(\hat{x}_{0,y+1})}\right] \\ 
     & \gg -\hat{x}_{0,y+1} |G_{\min}^{-1}(\hat{x_0})| \left(\frac{1}{\log(\hat{x}_{0,y+1})} + 
     \frac{1}{2 \log^2(\hat{x}_{0,y+1})}\right) \times \int_{\hat{x}_{0,y}}^{\hat{x}_{0,y+1}} 
     \frac{dt}{t^2} \\ 
     & \gg \sqrt{\hat{x}_{0,y+1}} \frac{|G_{\min}^{-1}(\hat{x_0})|}{\log(\hat{x}_{0,y+1})} \times 
     \left(1 + \frac{1}{\log(\hat{x}_{0,y+1})}\right). 
\end{align*} 
Now by applying the lower bounds proved in 
Theorem \ref{theorem_GInvxLowerBoundByGEInvx_v1}, we can see that in fact the 
following is true: 
\begin{align*} 
U_M(y) & \gg \sqrt{\hat{x}_{0,y+1}} \times 
     \frac{|G_{\min}^{-1}(\hat{x_0})|}{\log(\hat{x}_{0,y+1})} 
     + o(1), \mathrm{\ as\ } y \rightarrow \infty. 
\end{align*} 
Now we need to assemble this bound on the summation term in the 
formula for $M(x)$ from 
Proposition \ref{prop_Mx_SBP_IntegralFormula} with the 
leading terms involving the summatory function $G^{-1}$. 
In particular, we need to argue that we can effectively drop these leading terms to 
obtain a lower bound. Then we succeed by applying 
Theorem \ref{theorem_GInvxLowerBoundByGEInvx_v1} since the remaining terms given by the 
function $U_M(y)$ are infinitely tending as $y \rightarrow \infty$. 

Namely, we clearly see from Theorem \ref{theorem_GInvxLowerBoundByGEInvx_v1} and the 
proposition that 
\begin{align} 
\notag 
\frac{|M(\hat{x}_{0,y+1})|}{\sqrt{\hat{x}_{0,y+1}}} & \gg \frac{1}{\sqrt{\hat{x}_{0,y+1}}} \times 
     \left\lvert \left\lvert 
     G^{-1}(\hat{x}_{0,y+1}) + G^{-1}\left(\frac{\hat{x}_{0,y+1}}{2}\right) \right\rvert + 
     U_M(y) \right\rvert \\ 
\notag 
     & \gg \frac{1}{\sqrt{\hat{x}_{0,y+1}}} \times \left\lvert U_M(y) \right\rvert \\ 
\label{eqn_MxGInvxLowerBound_stmt_v3} 
     & \gg \frac{\log\left(\sqrt{\hat{x}_{0,y+1}}\right)^{3/4} 
     \log\log\left(\sqrt{\hat{x}_{0,y+1}}\right)^{5/2}}{ 
     \log\log\log\left(\sqrt{\hat{x}_{0,y+1}}\right)^{2}}. 
\end{align} 
Finally, we evaluate the following limit to conclude unboundedness 
where $\sqrt{x_{0,y}} \rightarrow +\infty$ as $y \rightarrow +\infty$: 
\[
\lim_{x \rightarrow \infty} \left[\frac{(\log x)^{\frac{3}{4}} 
     (\log\log x)^{\frac{5}{2}}}{(\log\log\log x)^2}  
     \right] = +\infty. 
\] 
\textbf{Remarks on this lower bound construction.} 
There is a small, but nonetheless insightful point to explain about a 
technicality in stating \eqref{eqn_MxGInvxLowerBound_stmt_v3}. 
Namely, we are not asserting that 
$|M(x)| / \sqrt{x}$ grows unbounded along the precise subsequence of 
$x \mapsto \hat{x}_{0,y+1}$ itself as $y \rightarrow \infty$. 
Rather, we are asserting that the unboundedness of this function 
can be witnessed along some subsequence whose points are taken within a 
large interval window of 
$x \in \left(\sqrt{\hat{x}_{0,y}}, \sqrt{\hat{x}_{0,y+1}}\right]$ as 
$y \rightarrow \infty$. 
We choose to state the lower bound given on the right-hand-side of 
\eqref{eqn_MxGInvxLowerBound_stmt_v3} using the nicely formulated 
monotone lower bound on $|G_E^{-1}(x)|$ we proved in 
Theorem \ref{theorem_gInv_GeneralAsymptoticsForms} 
with $\hat{x}_0 \geq \sqrt{\hat{x}_{0,y}}$ for all $y \geq Y_0$. 
\end{proof} 

\newpage 
\renewcommand{\refname}{References} 
\bibliography{glossaries-bibtex/thesis-references}{}
\bibliographystyle{plain}

\newpage
\setcounter{section}{0} 
\renewcommand{\thesection}{T.\arabic{section}} 

\section{Table: The Dirichlet inverse function $g^{-1}(n)$ and the 
         distribution of its summatory function} 
\label{table_conjecture_Mertens_ginvSeq_approx_values}

\begin{table}[ht!]

\centering

\tiny
\begin{equation*}
\boxed{
\begin{array}{cc|cc|ccc|cc|ccc}
 n & \mathbf{Primes} & \mathbf{Sqfree} & \mathbf{PPower} & g^{-1}(n) & 
 \lambda(n) g^{-1}(n) - \widehat{f}_1(n) & 
 \frac{\sum_{d|n} C_{\Omega(d)}(d)}{|g^{-1}(n)|} & 
 \mathcal{L}_{+}(n) & \mathcal{L}_{-}(n) & 
 G^{-1}(n) & G^{-1}_{+}(n) & G^{-1}_{-}(n) \\ \hline 
1 & 1^1 & \text{Y} & \text{N} & 1 & 0 & 1.0000000 & 1.000000 & 0.000000 & 1 & 1 & 0 \\
 2 & 2^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.500000 & 0.500000 & -1 & 1 & -2 \\
 3 & 3^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.333333 & 0.666667 & -3 & 1 & -4 \\
 4 & 2^2 & \text{N} & \text{Y} & 2 & 0 & 1.5000000 & 0.500000 & 0.500000 & -1 & 3 & -4 \\
 5 & 5^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.400000 & 0.600000 & -3 & 3 & -6 \\
 6 & 2^1 3^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.500000 & 0.500000 & 2 & 8 & -6 \\
 7 & 7^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.428571 & 0.571429 & 0 & 8 & -8 \\
 8 & 2^3 & \text{N} & \text{Y} & -2 & 0 & 2.0000000 & 0.375000 & 0.625000 & -2 & 8 & -10 \\
 9 & 3^2 & \text{N} & \text{Y} & 2 & 0 & 1.5000000 & 0.444444 & 0.555556 & 0 & 10 & -10 \\
 10 & 2^1 5^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.500000 & 0.500000 & 5 & 15 & -10 \\
 11 & 11^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.454545 & 0.545455 & 3 & 15 & -12 \\
 12 & 2^2 3^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.416667 & 0.583333 & -4 & 15 & -19 \\
 13 & 13^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.384615 & 0.615385 & -6 & 15 & -21 \\
 14 & 2^1 7^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.428571 & 0.571429 & -1 & 20 & -21 \\
 15 & 3^1 5^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.466667 & 0.533333 & 4 & 25 & -21 \\
 16 & 2^4 & \text{N} & \text{Y} & 2 & 0 & 2.5000000 & 0.500000 & 0.500000 & 6 & 27 & -21 \\
 17 & 17^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.470588 & 0.529412 & 4 & 27 & -23 \\
 18 & 2^1 3^2 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.444444 & 0.555556 & -3 & 27 & -30 \\
 19 & 19^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.421053 & 0.578947 & -5 & 27 & -32 \\
 20 & 2^2 5^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.400000 & 0.600000 & -12 & 27 & -39 \\
 21 & 3^1 7^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.428571 & 0.571429 & -7 & 32 & -39 \\
 22 & 2^1 11^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.454545 & 0.545455 & -2 & 37 & -39 \\
 23 & 23^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.434783 & 0.565217 & -4 & 37 & -41 \\
 24 & 2^3 3^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.458333 & 0.541667 & 5 & 46 & -41 \\
 25 & 5^2 & \text{N} & \text{Y} & 2 & 0 & 1.5000000 & 0.480000 & 0.520000 & 7 & 48 & -41 \\
 26 & 2^1 13^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.500000 & 0.500000 & 12 & 53 & -41 \\
 27 & 3^3 & \text{N} & \text{Y} & -2 & 0 & 2.0000000 & 0.481481 & 0.518519 & 10 & 53 & -43 \\
 28 & 2^2 7^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.464286 & 0.535714 & 3 & 53 & -50 \\
 29 & 29^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.448276 & 0.551724 & 1 & 53 & -52 \\
 30 & 2^1 3^1 5^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.433333 & 0.566667 & -15 & 53 & -68 \\
 31 & 31^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.419355 & 0.580645 & -17 & 53 & -70 \\
 32 & 2^5 & \text{N} & \text{Y} & -2 & 0 & 3.0000000 & 0.406250 & 0.593750 & -19 & 53 & -72 \\
 33 & 3^1 11^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.424242 & 0.575758 & -14 & 58 & -72 \\
 34 & 2^1 17^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.441176 & 0.558824 & -9 & 63 & -72 \\
 35 & 5^1 7^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.457143 & 0.542857 & -4 & 68 & -72 \\
 36 & 2^2 3^2 & \text{N} & \text{N} & 14 & 9 & 1.3571429 & 0.472222 & 0.527778 & 10 & 82 & -72 \\
 37 & 37^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.459459 & 0.540541 & 8 & 82 & -74 \\
 38 & 2^1 19^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.473684 & 0.526316 & 13 & 87 & -74 \\
 39 & 3^1 13^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.487179 & 0.512821 & 18 & 92 & -74 \\
 40 & 2^3 5^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.500000 & 0.500000 & 27 & 101 & -74 \\
 41 & 41^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.487805 & 0.512195 & 25 & 101 & -76 \\
 42 & 2^1 3^1 7^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.476190 & 0.523810 & 9 & 101 & -92 \\
 43 & 43^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.465116 & 0.534884 & 7 & 101 & -94 \\
 44 & 2^2 11^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.454545 & 0.545455 & 0 & 101 & -101 \\
 45 & 3^2 5^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.444444 & 0.555556 & -7 & 101 & -108 \\
 46 & 2^1 23^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.456522 & 0.543478 & -2 & 106 & -108 \\
 47 & 47^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.446809 & 0.553191 & -4 & 106 & -110 \\
 48 & 2^4 3^1 & \text{N} & \text{N} & -11 & 6 & 1.8181818 & 0.437500 & 0.562500 & -15 & 106 & -121 \\ 
\end{array}
}
\end{equation*}

\bigskip\hrule\smallskip 

\captionsetup{singlelinecheck=off} 
\caption*{\textbf{\rm \bf Table \thesection:} 
          \textbf{Computations with $\mathbf{g^{-1}(n) \equiv (\omega+1)^{-1}(n)}$ 
          for $\mathbf{1 \leq n \leq 500}$.} 
          \begin{itemize}[noitemsep,topsep=0pt,leftmargin=0.23in] 
          \item[$\blacktriangleright$] 
          The column labeled \texttt{Primes} provides the prime factorization of each $n$ so that the values of 
          $\omega(n)$ and $\Omega(n)$ are easily extracted. 
          The columns labeled \texttt{Sqfree} and \texttt{PPower}, respectively, 
          list inclusion of $n$ in the sets of squarefree integers and the prime powers. 
          \item[$\blacktriangleright$] 
          The next three columns provide the 
          explicit values of the inverse function $g^{-1}(n)$ and compare its explicit value with other estimates. 
          We define the function $\widehat{f}_1(n) := \sum_{k=0}^{\omega(n)} \binom{\omega(n)}{k} \cdot k!$. 
          \item[$\blacktriangleright$] 
          The last several columns indicate properties of the summatory function of $g^{-1}(n)$. 
          The notation for the densities of the sign weight of $g^{-1}(n)$ is defined as 
          $\mathcal{L}_{\pm}(x) := \frac{1}{n} \cdot \#\left\{n \leq x: \lambda(n) = \pm 1\right\}$. 
          The last three 
          columns then show the explicit components to the signed summatory function, 
          $G^{-1}(x) := \sum_{n \leq x} g^{-1}(n)$, decomposed into its 
          respective positive and negative magnitude sum contributions: $G^{-1}(x) = G^{-1}_{+}(x) + G^{-1}_{-}(x)$ where 
          $G^{-1}_{+}(x) > 0$ and $G^{-1}_{-}(x) < 0$ for all $x \geq 1$. 
          \end{itemize} 
          } 
\clearpage 

\end{table}

\newpage
\begin{table}[ht]

\centering

\tiny
\begin{equation*}
\boxed{
\begin{array}{cc|cc|ccc|cc|ccc}
 n & \mathbf{Primes} & \mathbf{Sqfree} & \mathbf{PPower} & g^{-1}(n) & 
 \lambda(n) g^{-1}(n) - \widehat{f}_1(n) & 
 \frac{\sum_{d|n} C_{\Omega(d)}(d)}{|g^{-1}(n)|} & 
 \mathcal{L}_{+}(n) & \mathcal{L}_{-}(n) & 
 G^{-1}(n) & G^{-1}_{+}(n) & G^{-1}_{-}(n) \\ \hline 
 49 & 7^2 & \text{N} & \text{Y} & 2 & 0 & 1.5000000 & 0.448980 & 0.551020 & -13 & 108 & -121 \\
 50 & 2^1 5^2 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.440000 & 0.560000 & -20 & 108 & -128 \\
 51 & 3^1 17^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.450980 & 0.549020 & -15 & 113 & -128 \\
 52 & 2^2 13^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.442308 & 0.557692 & -22 & 113 & -135 \\
 53 & 53^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.433962 & 0.566038 & -24 & 113 & -137 \\
 54 & 2^1 3^3 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.444444 & 0.555556 & -15 & 122 & -137 \\
 55 & 5^1 11^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.454545 & 0.545455 & -10 & 127 & -137 \\
 56 & 2^3 7^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.464286 & 0.535714 & -1 & 136 & -137 \\
 57 & 3^1 19^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.473684 & 0.526316 & 4 & 141 & -137 \\
 58 & 2^1 29^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.482759 & 0.517241 & 9 & 146 & -137 \\
 59 & 59^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.474576 & 0.525424 & 7 & 146 & -139 \\
 60 & 2^2 3^1 5^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.483333 & 0.516667 & 37 & 176 & -139 \\
 61 & 61^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.475410 & 0.524590 & 35 & 176 & -141 \\
 62 & 2^1 31^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.483871 & 0.516129 & 40 & 181 & -141 \\
 63 & 3^2 7^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.476190 & 0.523810 & 33 & 181 & -148 \\
 64 & 2^6 & \text{N} & \text{Y} & 2 & 0 & 3.5000000 & 0.484375 & 0.515625 & 35 & 183 & -148 \\
 65 & 5^1 13^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.492308 & 0.507692 & 40 & 188 & -148 \\
 66 & 2^1 3^1 11^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.484848 & 0.515152 & 24 & 188 & -164 \\
 67 & 67^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.477612 & 0.522388 & 22 & 188 & -166 \\
 68 & 2^2 17^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.470588 & 0.529412 & 15 & 188 & -173 \\
 69 & 3^1 23^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.478261 & 0.521739 & 20 & 193 & -173 \\
 70 & 2^1 5^1 7^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.471429 & 0.528571 & 4 & 193 & -189 \\
 71 & 71^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.464789 & 0.535211 & 2 & 193 & -191 \\
 72 & 2^3 3^2 & \text{N} & \text{N} & -23 & 18 & 1.4782609 & 0.458333 & 0.541667 & -21 & 193 & -214 \\
 73 & 73^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.452055 & 0.547945 & -23 & 193 & -216 \\
 74 & 2^1 37^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.459459 & 0.540541 & -18 & 198 & -216 \\
 75 & 3^1 5^2 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.453333 & 0.546667 & -25 & 198 & -223 \\
 76 & 2^2 19^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.447368 & 0.552632 & -32 & 198 & -230 \\
 77 & 7^1 11^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.454545 & 0.545455 & -27 & 203 & -230 \\
 78 & 2^1 3^1 13^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.448718 & 0.551282 & -43 & 203 & -246 \\
 79 & 79^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.443038 & 0.556962 & -45 & 203 & -248 \\
 80 & 2^4 5^1 & \text{N} & \text{N} & -11 & 6 & 1.8181818 & 0.437500 & 0.562500 & -56 & 203 & -259 \\
 81 & 3^4 & \text{N} & \text{Y} & 2 & 0 & 2.5000000 & 0.444444 & 0.555556 & -54 & 205 & -259 \\
 82 & 2^1 41^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.451220 & 0.548780 & -49 & 210 & -259 \\
 83 & 83^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.445783 & 0.554217 & -51 & 210 & -261 \\
 84 & 2^2 3^1 7^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.452381 & 0.547619 & -21 & 240 & -261 \\
 85 & 5^1 17^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.458824 & 0.541176 & -16 & 245 & -261 \\
 86 & 2^1 43^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.465116 & 0.534884 & -11 & 250 & -261 \\
 87 & 3^1 29^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.471264 & 0.528736 & -6 & 255 & -261 \\
 88 & 2^3 11^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.477273 & 0.522727 & 3 & 264 & -261 \\
 89 & 89^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.471910 & 0.528090 & 1 & 264 & -263 \\
 90 & 2^1 3^2 5^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.477778 & 0.522222 & 31 & 294 & -263 \\
 91 & 7^1 13^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.483516 & 0.516484 & 36 & 299 & -263 \\
 92 & 2^2 23^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.478261 & 0.521739 & 29 & 299 & -270 \\
 93 & 3^1 31^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.483871 & 0.516129 & 34 & 304 & -270 \\
 94 & 2^1 47^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.489362 & 0.510638 & 39 & 309 & -270 \\
 95 & 5^1 19^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.494737 & 0.505263 & 44 & 314 & -270 \\
 96 & 2^5 3^1 & \text{N} & \text{N} & 13 & 8 & 2.0769231 & 0.500000 & 0.500000 & 57 & 327 & -270 \\
 97 & 97^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.494845 & 0.505155 & 55 & 327 & -272 \\
 98 & 2^1 7^2 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.489796 & 0.510204 & 48 & 327 & -279 \\
 99 & 3^2 11^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.484848 & 0.515152 & 41 & 327 & -286 \\
 100 & 2^2 5^2 & \text{N} & \text{N} & 14 & 9 & 1.3571429 & 0.490000 & 0.510000 & 55 & 341 & -286 \\
 101 & 101^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.485149 & 0.514851 & 53 & 341 & -288 \\
 102 & 2^1 3^1 17^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.480392 & 0.519608 & 37 & 341 & -304 \\
 103 & 103^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.475728 & 0.524272 & 35 & 341 & -306 \\
 104 & 2^3 13^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.480769 & 0.519231 & 44 & 350 & -306 \\
 105 & 3^1 5^1 7^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.476190 & 0.523810 & 28 & 350 & -322 \\
 106 & 2^1 53^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.481132 & 0.518868 & 33 & 355 & -322 \\
 107 & 107^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.476636 & 0.523364 & 31 & 355 & -324 \\
 108 & 2^2 3^3 & \text{N} & \text{N} & -23 & 18 & 1.4782609 & 0.472222 & 0.527778 & 8 & 355 & -347 \\
 109 & 109^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.467890 & 0.532110 & 6 & 355 & -349 \\
 110 & 2^1 5^1 11^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.463636 & 0.536364 & -10 & 355 & -365 \\
 111 & 3^1 37^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.468468 & 0.531532 & -5 & 360 & -365 \\
 112 & 2^4 7^1 & \text{N} & \text{N} & -11 & 6 & 1.8181818 & 0.464286 & 0.535714 & -16 & 360 & -376 \\
 113 & 113^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.460177 & 0.539823 & -18 & 360 & -378 \\
 114 & 2^1 3^1 19^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.456140 & 0.543860 & -34 & 360 & -394 \\
 115 & 5^1 23^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.460870 & 0.539130 & -29 & 365 & -394 \\
 116 & 2^2 29^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.456897 & 0.543103 & -36 & 365 & -401 \\
 117 & 3^2 13^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.452991 & 0.547009 & -43 & 365 & -408 \\
 118 & 2^1 59^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.457627 & 0.542373 & -38 & 370 & -408 \\
 119 & 7^1 17^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.462185 & 0.537815 & -33 & 375 & -408 \\
 120 & 2^3 3^1 5^1 & \text{N} & \text{N} & -48 & 32 & 1.3333333 & 0.458333 & 0.541667 & -81 & 375 & -456 \\
 121 & 11^2 & \text{N} & \text{Y} & 2 & 0 & 1.5000000 & 0.462810 & 0.537190 & -79 & 377 & -456 \\
 122 & 2^1 61^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.467213 & 0.532787 & -74 & 382 & -456 \\
 123 & 3^1 41^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.471545 & 0.528455 & -69 & 387 & -456 \\
 124 & 2^2 31^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.467742 & 0.532258 & -76 & 387 & -463 \\ 
\end{array}
}
\end{equation*}
\clearpage 

\end{table} 


\newpage
\begin{table}[ht]

\centering

\tiny
\begin{equation*}
\boxed{
\begin{array}{cc|cc|ccc|cc|ccc}
 n & \mathbf{Primes} & \mathbf{Sqfree} & \mathbf{PPower} & g^{-1}(n) & 
 \lambda(n) g^{-1}(n) - \widehat{f}_1(n) & 
 \frac{\sum_{d|n} C_{\Omega(d)}(d)}{|g^{-1}(n)|} & 
 \mathcal{L}_{+}(n) & \mathcal{L}_{-}(n) & 
 G^{-1}(n) & G^{-1}_{+}(n) & G^{-1}_{-}(n) \\ \hline 
 125 & 5^3 & \text{N} & \text{Y} & -2 & 0 & 2.0000000 & 0.464000 & 0.536000 & -78 & 387 & -465 \\
 126 & 2^1 3^2 7^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.468254 & 0.531746 & -48 & 417 & -465 \\
 127 & 127^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.464567 & 0.535433 & -50 & 417 & -467 \\
 128 & 2^7 & \text{N} & \text{Y} & -2 & 0 & 4.0000000 & 0.460938 & 0.539062 & -52 & 417 & -469 \\
 129 & 3^1 43^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.465116 & 0.534884 & -47 & 422 & -469 \\
 130 & 2^1 5^1 13^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.461538 & 0.538462 & -63 & 422 & -485 \\
 131 & 131^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.458015 & 0.541985 & -65 & 422 & -487 \\
 132 & 2^2 3^1 11^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.462121 & 0.537879 & -35 & 452 & -487 \\
 133 & 7^1 19^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.466165 & 0.533835 & -30 & 457 & -487 \\
 134 & 2^1 67^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.470149 & 0.529851 & -25 & 462 & -487 \\
 135 & 3^3 5^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.474074 & 0.525926 & -16 & 471 & -487 \\
 136 & 2^3 17^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.477941 & 0.522059 & -7 & 480 & -487 \\
 137 & 137^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.474453 & 0.525547 & -9 & 480 & -489 \\
 138 & 2^1 3^1 23^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.471014 & 0.528986 & -25 & 480 & -505 \\
 139 & 139^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.467626 & 0.532374 & -27 & 480 & -507 \\
 140 & 2^2 5^1 7^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.471429 & 0.528571 & 3 & 510 & -507 \\
 141 & 3^1 47^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.475177 & 0.524823 & 8 & 515 & -507 \\
 142 & 2^1 71^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.478873 & 0.521127 & 13 & 520 & -507 \\
 143 & 11^1 13^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.482517 & 0.517483 & 18 & 525 & -507 \\
 144 & 2^4 3^2 & \text{N} & \text{N} & 34 & 29 & 1.6176471 & 0.486111 & 0.513889 & 52 & 559 & -507 \\
 145 & 5^1 29^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.489655 & 0.510345 & 57 & 564 & -507 \\
 146 & 2^1 73^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.493151 & 0.506849 & 62 & 569 & -507 \\
 147 & 3^1 7^2 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.489796 & 0.510204 & 55 & 569 & -514 \\
 148 & 2^2 37^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.486486 & 0.513514 & 48 & 569 & -521 \\
 149 & 149^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.483221 & 0.516779 & 46 & 569 & -523 \\
 150 & 2^1 3^1 5^2 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.486667 & 0.513333 & 76 & 599 & -523 \\
 151 & 151^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.483444 & 0.516556 & 74 & 599 & -525 \\
 152 & 2^3 19^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.486842 & 0.513158 & 83 & 608 & -525 \\
 153 & 3^2 17^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.483660 & 0.516340 & 76 & 608 & -532 \\
 154 & 2^1 7^1 11^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.480519 & 0.519481 & 60 & 608 & -548 \\
 155 & 5^1 31^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.483871 & 0.516129 & 65 & 613 & -548 \\
 156 & 2^2 3^1 13^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.487179 & 0.512821 & 95 & 643 & -548 \\
 157 & 157^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.484076 & 0.515924 & 93 & 643 & -550 \\
 158 & 2^1 79^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.487342 & 0.512658 & 98 & 648 & -550 \\
 159 & 3^1 53^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.490566 & 0.509434 & 103 & 653 & -550 \\
 160 & 2^5 5^1 & \text{N} & \text{N} & 13 & 8 & 2.0769231 & 0.493750 & 0.506250 & 116 & 666 & -550 \\
 161 & 7^1 23^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.496894 & 0.503106 & 121 & 671 & -550 \\
 162 & 2^1 3^4 & \text{N} & \text{N} & -11 & 6 & 1.8181818 & 0.493827 & 0.506173 & 110 & 671 & -561 \\
 163 & 163^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.490798 & 0.509202 & 108 & 671 & -563 \\
 164 & 2^2 41^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.487805 & 0.512195 & 101 & 671 & -570 \\
 165 & 3^1 5^1 11^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.484848 & 0.515152 & 85 & 671 & -586 \\
 166 & 2^1 83^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.487952 & 0.512048 & 90 & 676 & -586 \\
 167 & 167^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.485030 & 0.514970 & 88 & 676 & -588 \\
 168 & 2^3 3^1 7^1 & \text{N} & \text{N} & -48 & 32 & 1.3333333 & 0.482143 & 0.517857 & 40 & 676 & -636 \\
 169 & 13^2 & \text{N} & \text{Y} & 2 & 0 & 1.5000000 & 0.485207 & 0.514793 & 42 & 678 & -636 \\
 170 & 2^1 5^1 17^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.482353 & 0.517647 & 26 & 678 & -652 \\
 171 & 3^2 19^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.479532 & 0.520468 & 19 & 678 & -659 \\
 172 & 2^2 43^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.476744 & 0.523256 & 12 & 678 & -666 \\
 173 & 173^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.473988 & 0.526012 & 10 & 678 & -668 \\
 174 & 2^1 3^1 29^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.471264 & 0.528736 & -6 & 678 & -684 \\
 175 & 5^2 7^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.468571 & 0.531429 & -13 & 678 & -691 \\
 176 & 2^4 11^1 & \text{N} & \text{N} & -11 & 6 & 1.8181818 & 0.465909 & 0.534091 & -24 & 678 & -702 \\
 177 & 3^1 59^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.468927 & 0.531073 & -19 & 683 & -702 \\
 178 & 2^1 89^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.471910 & 0.528090 & -14 & 688 & -702 \\
 179 & 179^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.469274 & 0.530726 & -16 & 688 & -704 \\
 180 & 2^2 3^2 5^1 & \text{N} & \text{N} & -74 & 58 & 1.2162162 & 0.466667 & 0.533333 & -90 & 688 & -778 \\
 181 & 181^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.464088 & 0.535912 & -92 & 688 & -780 \\
 182 & 2^1 7^1 13^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.461538 & 0.538462 & -108 & 688 & -796 \\
 183 & 3^1 61^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.464481 & 0.535519 & -103 & 693 & -796 \\
 184 & 2^3 23^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.467391 & 0.532609 & -94 & 702 & -796 \\
 185 & 5^1 37^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.470270 & 0.529730 & -89 & 707 & -796 \\
 186 & 2^1 3^1 31^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.467742 & 0.532258 & -105 & 707 & -812 \\
 187 & 11^1 17^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.470588 & 0.529412 & -100 & 712 & -812 \\
 188 & 2^2 47^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.468085 & 0.531915 & -107 & 712 & -819 \\
 189 & 3^3 7^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.470899 & 0.529101 & -98 & 721 & -819 \\
 190 & 2^1 5^1 19^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.468421 & 0.531579 & -114 & 721 & -835 \\
 191 & 191^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.465969 & 0.534031 & -116 & 721 & -837 \\
 192 & 2^6 3^1 & \text{N} & \text{N} & -15 & 10 & 2.3333333 & 0.463542 & 0.536458 & -131 & 721 & -852 \\
 193 & 193^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.461140 & 0.538860 & -133 & 721 & -854 \\
 194 & 2^1 97^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.463918 & 0.536082 & -128 & 726 & -854 \\
 195 & 3^1 5^1 13^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.461538 & 0.538462 & -144 & 726 & -870 \\
 196 & 2^2 7^2 & \text{N} & \text{N} & 14 & 9 & 1.3571429 & 0.464286 & 0.535714 & -130 & 740 & -870 \\
 197 & 197^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.461929 & 0.538071 & -132 & 740 & -872 \\
 198 & 2^1 3^2 11^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.464646 & 0.535354 & -102 & 770 & -872 \\
 199 & 199^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.462312 & 0.537688 & -104 & 770 & -874 \\
 200 & 2^3 5^2 & \text{N} & \text{N} & -23 & 18 & 1.4782609 & 0.460000 & 0.540000 & -127 & 770 & -897 \\ 
\end{array}
}
\end{equation*}
\clearpage 

\end{table} 

\newpage
\begin{table}[ht]

\centering

\tiny
\begin{equation*}
\boxed{
\begin{array}{cc|cc|ccc|cc|ccc}
 n & \mathbf{Primes} & \mathbf{Sqfree} & \mathbf{PPower} & g^{-1}(n) & 
 \lambda(n) g^{-1}(n) - \widehat{f}_1(n) & 
 \frac{\sum_{d|n} C_{\Omega(d)}(d)}{|g^{-1}(n)|} & 
 \mathcal{L}_{+}(n) & \mathcal{L}_{-}(n) & 
 G^{-1}(n) & G^{-1}_{+}(n) & G^{-1}_{-}(n) \\ \hline 
 201 & 3^1 67^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.462687 & 0.537313 & -122 & 775 & -897 \\
 202 & 2^1 101^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.465347 & 0.534653 & -117 & 780 & -897 \\
 203 & 7^1 29^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.467980 & 0.532020 & -112 & 785 & -897 \\
 204 & 2^2 3^1 17^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.470588 & 0.529412 & -82 & 815 & -897 \\
 205 & 5^1 41^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.473171 & 0.526829 & -77 & 820 & -897 \\
 206 & 2^1 103^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.475728 & 0.524272 & -72 & 825 & -897 \\
 207 & 3^2 23^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.473430 & 0.526570 & -79 & 825 & -904 \\
 208 & 2^4 13^1 & \text{N} & \text{N} & -11 & 6 & 1.8181818 & 0.471154 & 0.528846 & -90 & 825 & -915 \\
 209 & 11^1 19^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.473684 & 0.526316 & -85 & 830 & -915 \\
 210 & 2^1 3^1 5^1 7^1 & \text{Y} & \text{N} & 65 & 0 & 1.0000000 & 0.476190 & 0.523810 & -20 & 895 & -915 \\
 211 & 211^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.473934 & 0.526066 & -22 & 895 & -917 \\
 212 & 2^2 53^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.471698 & 0.528302 & -29 & 895 & -924 \\
 213 & 3^1 71^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.474178 & 0.525822 & -24 & 900 & -924 \\
 214 & 2^1 107^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.476636 & 0.523364 & -19 & 905 & -924 \\
 215 & 5^1 43^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.479070 & 0.520930 & -14 & 910 & -924 \\
 216 & 2^3 3^3 & \text{N} & \text{N} & 46 & 41 & 1.5000000 & 0.481481 & 0.518519 & 32 & 956 & -924 \\
 217 & 7^1 31^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.483871 & 0.516129 & 37 & 961 & -924 \\
 218 & 2^1 109^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.486239 & 0.513761 & 42 & 966 & -924 \\
 219 & 3^1 73^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.488584 & 0.511416 & 47 & 971 & -924 \\
 220 & 2^2 5^1 11^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.490909 & 0.509091 & 77 & 1001 & -924 \\
 221 & 13^1 17^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.493213 & 0.506787 & 82 & 1006 & -924 \\
 222 & 2^1 3^1 37^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.490991 & 0.509009 & 66 & 1006 & -940 \\
 223 & 223^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.488789 & 0.511211 & 64 & 1006 & -942 \\
 224 & 2^5 7^1 & \text{N} & \text{N} & 13 & 8 & 2.0769231 & 0.491071 & 0.508929 & 77 & 1019 & -942 \\
 225 & 3^2 5^2 & \text{N} & \text{N} & 14 & 9 & 1.3571429 & 0.493333 & 0.506667 & 91 & 1033 & -942 \\
 226 & 2^1 113^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.495575 & 0.504425 & 96 & 1038 & -942 \\
 227 & 227^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.493392 & 0.506608 & 94 & 1038 & -944 \\
 228 & 2^2 3^1 19^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.495614 & 0.504386 & 124 & 1068 & -944 \\
 229 & 229^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.493450 & 0.506550 & 122 & 1068 & -946 \\
 230 & 2^1 5^1 23^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.491304 & 0.508696 & 106 & 1068 & -962 \\
 231 & 3^1 7^1 11^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.489177 & 0.510823 & 90 & 1068 & -978 \\
 232 & 2^3 29^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.491379 & 0.508621 & 99 & 1077 & -978 \\
 233 & 233^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.489270 & 0.510730 & 97 & 1077 & -980 \\
 234 & 2^1 3^2 13^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.491453 & 0.508547 & 127 & 1107 & -980 \\
 235 & 5^1 47^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.493617 & 0.506383 & 132 & 1112 & -980 \\
 236 & 2^2 59^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.491525 & 0.508475 & 125 & 1112 & -987 \\
 237 & 3^1 79^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.493671 & 0.506329 & 130 & 1117 & -987 \\
 238 & 2^1 7^1 17^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.491597 & 0.508403 & 114 & 1117 & -1003 \\
 239 & 239^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.489540 & 0.510460 & 112 & 1117 & -1005 \\
 240 & 2^4 3^1 5^1 & \text{N} & \text{N} & 70 & 54 & 1.5000000 & 0.491667 & 0.508333 & 182 & 1187 & -1005 \\
 241 & 241^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.489627 & 0.510373 & 180 & 1187 & -1007 \\
 242 & 2^1 11^2 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.487603 & 0.512397 & 173 & 1187 & -1014 \\
 243 & 3^5 & \text{N} & \text{Y} & -2 & 0 & 3.0000000 & 0.485597 & 0.514403 & 171 & 1187 & -1016 \\
 244 & 2^2 61^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.483607 & 0.516393 & 164 & 1187 & -1023 \\
 245 & 5^1 7^2 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.481633 & 0.518367 & 157 & 1187 & -1030 \\
 246 & 2^1 3^1 41^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.479675 & 0.520325 & 141 & 1187 & -1046 \\
 247 & 13^1 19^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.481781 & 0.518219 & 146 & 1192 & -1046 \\
 248 & 2^3 31^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.483871 & 0.516129 & 155 & 1201 & -1046 \\
 249 & 3^1 83^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.485944 & 0.514056 & 160 & 1206 & -1046 \\
 250 & 2^1 5^3 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.488000 & 0.512000 & 169 & 1215 & -1046 \\
 251 & 251^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.486056 & 0.513944 & 167 & 1215 & -1048 \\
 252 & 2^2 3^2 7^1 & \text{N} & \text{N} & -74 & 58 & 1.2162162 & 0.484127 & 0.515873 & 93 & 1215 & -1122 \\
 253 & 11^1 23^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.486166 & 0.513834 & 98 & 1220 & -1122 \\
 254 & 2^1 127^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.488189 & 0.511811 & 103 & 1225 & -1122 \\
 255 & 3^1 5^1 17^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.486275 & 0.513725 & 87 & 1225 & -1138 \\
 256 & 2^8 & \text{N} & \text{Y} & 2 & 0 & 4.5000000 & 0.488281 & 0.511719 & 89 & 1227 & -1138 \\
 257 & 257^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.486381 & 0.513619 & 87 & 1227 & -1140 \\
 258 & 2^1 3^1 43^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.484496 & 0.515504 & 71 & 1227 & -1156 \\
 259 & 7^1 37^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.486486 & 0.513514 & 76 & 1232 & -1156 \\
 260 & 2^2 5^1 13^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.488462 & 0.511538 & 106 & 1262 & -1156 \\
 261 & 3^2 29^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.486590 & 0.513410 & 99 & 1262 & -1163 \\
 262 & 2^1 131^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.488550 & 0.511450 & 104 & 1267 & -1163 \\
 263 & 263^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.486692 & 0.513308 & 102 & 1267 & -1165 \\
 264 & 2^3 3^1 11^1 & \text{N} & \text{N} & -48 & 32 & 1.3333333 & 0.484848 & 0.515152 & 54 & 1267 & -1213 \\
 265 & 5^1 53^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.486792 & 0.513208 & 59 & 1272 & -1213 \\
 266 & 2^1 7^1 19^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.484962 & 0.515038 & 43 & 1272 & -1229 \\
 267 & 3^1 89^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.486891 & 0.513109 & 48 & 1277 & -1229 \\
 268 & 2^2 67^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.485075 & 0.514925 & 41 & 1277 & -1236 \\
 269 & 269^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.483271 & 0.516729 & 39 & 1277 & -1238 \\
 270 & 2^1 3^3 5^1 & \text{N} & \text{N} & -48 & 32 & 1.3333333 & 0.481481 & 0.518519 & -9 & 1277 & -1286 \\
 271 & 271^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.479705 & 0.520295 & -11 & 1277 & -1288 \\
 272 & 2^4 17^1 & \text{N} & \text{N} & -11 & 6 & 1.8181818 & 0.477941 & 0.522059 & -22 & 1277 & -1299 \\
 273 & 3^1 7^1 13^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.476190 & 0.523810 & -38 & 1277 & -1315 \\
 274 & 2^1 137^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.478102 & 0.521898 & -33 & 1282 & -1315 \\
 275 & 5^2 11^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.476364 & 0.523636 & -40 & 1282 & -1322 \\
 276 & 2^2 3^1 23^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.478261 & 0.521739 & -10 & 1312 & -1322 \\
 277 & 277^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.476534 & 0.523466 & -12 & 1312 & -1324 \\ 
\end{array}
}
\end{equation*}
\clearpage 

\end{table} 

\newpage
\begin{table}[ht]

\centering

\tiny
\begin{equation*}
\boxed{
\begin{array}{cc|cc|ccc|cc|ccc}
 n & \mathbf{Primes} & \mathbf{Sqfree} & \mathbf{PPower} & g^{-1}(n) & 
 \lambda(n) g^{-1}(n) - \widehat{f}_1(n) & 
 \frac{\sum_{d|n} C_{\Omega(d)}(d)}{|g^{-1}(n)|} & 
 \mathcal{L}_{+}(n) & \mathcal{L}_{-}(n) & 
 G^{-1}(n) & G^{-1}_{+}(n) & G^{-1}_{-}(n) \\ \hline 
 278 & 2^1 139^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.478417 & 0.521583 & -7 & 1317 & -1324 \\
 279 & 3^2 31^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.476703 & 0.523297 & -14 & 1317 & -1331 \\
 280 & 2^3 5^1 7^1 & \text{N} & \text{N} & -48 & 32 & 1.3333333 & 0.475000 & 0.525000 & -62 & 1317 & -1379 \\
 281 & 281^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.473310 & 0.526690 & -64 & 1317 & -1381 \\
 282 & 2^1 3^1 47^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.471631 & 0.528369 & -80 & 1317 & -1397 \\
 283 & 283^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.469965 & 0.530035 & -82 & 1317 & -1399 \\
 284 & 2^2 71^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.468310 & 0.531690 & -89 & 1317 & -1406 \\
 285 & 3^1 5^1 19^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.466667 & 0.533333 & -105 & 1317 & -1422 \\
 286 & 2^1 11^1 13^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.465035 & 0.534965 & -121 & 1317 & -1438 \\
 287 & 7^1 41^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.466899 & 0.533101 & -116 & 1322 & -1438 \\
 288 & 2^5 3^2 & \text{N} & \text{N} & -47 & 42 & 1.7659574 & 0.465278 & 0.534722 & -163 & 1322 & -1485 \\
 289 & 17^2 & \text{N} & \text{Y} & 2 & 0 & 1.5000000 & 0.467128 & 0.532872 & -161 & 1324 & -1485 \\
 290 & 2^1 5^1 29^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.465517 & 0.534483 & -177 & 1324 & -1501 \\
 291 & 3^1 97^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.467354 & 0.532646 & -172 & 1329 & -1501 \\
 292 & 2^2 73^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.465753 & 0.534247 & -179 & 1329 & -1508 \\
 293 & 293^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.464164 & 0.535836 & -181 & 1329 & -1510 \\
 294 & 2^1 3^1 7^2 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.465986 & 0.534014 & -151 & 1359 & -1510 \\
 295 & 5^1 59^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.467797 & 0.532203 & -146 & 1364 & -1510 \\
 296 & 2^3 37^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.469595 & 0.530405 & -137 & 1373 & -1510 \\
 297 & 3^3 11^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.471380 & 0.528620 & -128 & 1382 & -1510 \\
 298 & 2^1 149^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.473154 & 0.526846 & -123 & 1387 & -1510 \\
 299 & 13^1 23^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.474916 & 0.525084 & -118 & 1392 & -1510 \\
 300 & 2^2 3^1 5^2 & \text{N} & \text{N} & -74 & 58 & 1.2162162 & 0.473333 & 0.526667 & -192 & 1392 & -1584 \\
 301 & 7^1 43^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.475083 & 0.524917 & -187 & 1397 & -1584 \\
 302 & 2^1 151^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.476821 & 0.523179 & -182 & 1402 & -1584 \\
 303 & 3^1 101^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.478548 & 0.521452 & -177 & 1407 & -1584 \\
 304 & 2^4 19^1 & \text{N} & \text{N} & -11 & 6 & 1.8181818 & 0.476974 & 0.523026 & -188 & 1407 & -1595 \\
 305 & 5^1 61^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.478689 & 0.521311 & -183 & 1412 & -1595 \\
 306 & 2^1 3^2 17^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.480392 & 0.519608 & -153 & 1442 & -1595 \\
 307 & 307^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.478827 & 0.521173 & -155 & 1442 & -1597 \\
 308 & 2^2 7^1 11^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.480519 & 0.519481 & -125 & 1472 & -1597 \\
 309 & 3^1 103^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.482201 & 0.517799 & -120 & 1477 & -1597 \\
 310 & 2^1 5^1 31^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.480645 & 0.519355 & -136 & 1477 & -1613 \\
 311 & 311^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.479100 & 0.520900 & -138 & 1477 & -1615 \\
 312 & 2^3 3^1 13^1 & \text{N} & \text{N} & -48 & 32 & 1.3333333 & 0.477564 & 0.522436 & -186 & 1477 & -1663 \\
 313 & 313^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.476038 & 0.523962 & -188 & 1477 & -1665 \\
 314 & 2^1 157^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.477707 & 0.522293 & -183 & 1482 & -1665 \\
 315 & 3^2 5^1 7^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.479365 & 0.520635 & -153 & 1512 & -1665 \\
 316 & 2^2 79^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.477848 & 0.522152 & -160 & 1512 & -1672 \\
 317 & 317^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.476341 & 0.523659 & -162 & 1512 & -1674 \\
 318 & 2^1 3^1 53^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.474843 & 0.525157 & -178 & 1512 & -1690 \\
 319 & 11^1 29^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.476489 & 0.523511 & -173 & 1517 & -1690 \\
 320 & 2^6 5^1 & \text{N} & \text{N} & -15 & 10 & 2.3333333 & 0.475000 & 0.525000 & -188 & 1517 & -1705 \\
 321 & 3^1 107^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.476636 & 0.523364 & -183 & 1522 & -1705 \\
 322 & 2^1 7^1 23^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.475155 & 0.524845 & -199 & 1522 & -1721 \\
 323 & 17^1 19^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.476780 & 0.523220 & -194 & 1527 & -1721 \\
 324 & 2^2 3^4 & \text{N} & \text{N} & 34 & 29 & 1.6176471 & 0.478395 & 0.521605 & -160 & 1561 & -1721 \\
 325 & 5^2 13^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.476923 & 0.523077 & -167 & 1561 & -1728 \\
 326 & 2^1 163^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.478528 & 0.521472 & -162 & 1566 & -1728 \\
 327 & 3^1 109^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.480122 & 0.519878 & -157 & 1571 & -1728 \\
 328 & 2^3 41^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.481707 & 0.518293 & -148 & 1580 & -1728 \\
 329 & 7^1 47^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.483283 & 0.516717 & -143 & 1585 & -1728 \\
 330 & 2^1 3^1 5^1 11^1 & \text{Y} & \text{N} & 65 & 0 & 1.0000000 & 0.484848 & 0.515152 & -78 & 1650 & -1728 \\
 331 & 331^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.483384 & 0.516616 & -80 & 1650 & -1730 \\
 332 & 2^2 83^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.481928 & 0.518072 & -87 & 1650 & -1737 \\
 333 & 3^2 37^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.480480 & 0.519520 & -94 & 1650 & -1744 \\
 334 & 2^1 167^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.482036 & 0.517964 & -89 & 1655 & -1744 \\
 335 & 5^1 67^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.483582 & 0.516418 & -84 & 1660 & -1744 \\
 336 & 2^4 3^1 7^1 & \text{N} & \text{N} & 70 & 54 & 1.5000000 & 0.485119 & 0.514881 & -14 & 1730 & -1744 \\
 337 & 337^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.483680 & 0.516320 & -16 & 1730 & -1746 \\
 338 & 2^1 13^2 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.482249 & 0.517751 & -23 & 1730 & -1753 \\
 339 & 3^1 113^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.483776 & 0.516224 & -18 & 1735 & -1753 \\
 340 & 2^2 5^1 17^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.485294 & 0.514706 & 12 & 1765 & -1753 \\
 341 & 11^1 31^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.486804 & 0.513196 & 17 & 1770 & -1753 \\
 342 & 2^1 3^2 19^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.488304 & 0.511696 & 47 & 1800 & -1753 \\
 343 & 7^3 & \text{N} & \text{Y} & -2 & 0 & 2.0000000 & 0.486880 & 0.513120 & 45 & 1800 & -1755 \\
 344 & 2^3 43^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.488372 & 0.511628 & 54 & 1809 & -1755 \\
 345 & 3^1 5^1 23^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.486957 & 0.513043 & 38 & 1809 & -1771 \\
 346 & 2^1 173^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.488439 & 0.511561 & 43 & 1814 & -1771 \\
 347 & 347^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.487032 & 0.512968 & 41 & 1814 & -1773 \\
 348 & 2^2 3^1 29^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.488506 & 0.511494 & 71 & 1844 & -1773 \\
 349 & 349^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.487106 & 0.512894 & 69 & 1844 & -1775 \\
 350 & 2^1 5^2 7^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.488571 & 0.511429 & 99 & 1874 & -1775 \\ 
\end{array}
}
\end{equation*}
\clearpage 

\end{table} 

\newpage
\begin{table}[ht]

\centering
\tiny
\begin{equation*}
\boxed{
\begin{array}{cc|cc|ccc|cc|ccc}
 n & \mathbf{Primes} & \mathbf{Sqfree} & \mathbf{PPower} & g^{-1}(n) & 
 \lambda(n) g^{-1}(n) - \widehat{f}_1(n) & 
 \frac{\sum_{d|n} C_{\Omega(d)}(d)}{|g^{-1}(n)|} & 
 \mathcal{L}_{+}(n) & \mathcal{L}_{-}(n) & 
 G^{-1}(n) & G^{-1}_{+}(n) & G^{-1}_{-}(n) \\ \hline 
 351 & 3^3 13^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.490028 & 0.509972 & 108 & 1883 & -1775 \\
 352 & 2^5 11^1 & \text{N} & \text{N} & 13 & 8 & 2.0769231 & 0.491477 & 0.508523 & 121 & 1896 & -1775 \\
 353 & 353^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.490085 & 0.509915 & 119 & 1896 & -1777 \\
 354 & 2^1 3^1 59^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.488701 & 0.511299 & 103 & 1896 & -1793 \\
 355 & 5^1 71^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.490141 & 0.509859 & 108 & 1901 & -1793 \\
 356 & 2^2 89^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.488764 & 0.511236 & 101 & 1901 & -1800 \\
 357 & 3^1 7^1 17^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.487395 & 0.512605 & 85 & 1901 & -1816 \\
 358 & 2^1 179^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.488827 & 0.511173 & 90 & 1906 & -1816 \\
 359 & 359^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.487465 & 0.512535 & 88 & 1906 & -1818 \\
 360 & 2^3 3^2 5^1 & \text{N} & \text{N} & 145 & 129 & 1.3034483 & 0.488889 & 0.511111 & 233 & 2051 & -1818 \\
 361 & 19^2 & \text{N} & \text{Y} & 2 & 0 & 1.5000000 & 0.490305 & 0.509695 & 235 & 2053 & -1818 \\
 362 & 2^1 181^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.491713 & 0.508287 & 240 & 2058 & -1818 \\
 363 & 3^1 11^2 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.490358 & 0.509642 & 233 & 2058 & -1825 \\
 364 & 2^2 7^1 13^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.491758 & 0.508242 & 263 & 2088 & -1825 \\
 365 & 5^1 73^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.493151 & 0.506849 & 268 & 2093 & -1825 \\
 366 & 2^1 3^1 61^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.491803 & 0.508197 & 252 & 2093 & -1841 \\
 367 & 367^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.490463 & 0.509537 & 250 & 2093 & -1843 \\
 368 & 2^4 23^1 & \text{N} & \text{N} & -11 & 6 & 1.8181818 & 0.489130 & 0.510870 & 239 & 2093 & -1854 \\
 369 & 3^2 41^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.487805 & 0.512195 & 232 & 2093 & -1861 \\
 370 & 2^1 5^1 37^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.486486 & 0.513514 & 216 & 2093 & -1877 \\
 371 & 7^1 53^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.487871 & 0.512129 & 221 & 2098 & -1877 \\
 372 & 2^2 3^1 31^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.489247 & 0.510753 & 251 & 2128 & -1877 \\
 373 & 373^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.487936 & 0.512064 & 249 & 2128 & -1879 \\
 374 & 2^1 11^1 17^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.486631 & 0.513369 & 233 & 2128 & -1895 \\
 375 & 3^1 5^3 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.488000 & 0.512000 & 242 & 2137 & -1895 \\
 376 & 2^3 47^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.489362 & 0.510638 & 251 & 2146 & -1895 \\
 377 & 13^1 29^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.490716 & 0.509284 & 256 & 2151 & -1895 \\
 378 & 2^1 3^3 7^1 & \text{N} & \text{N} & -48 & 32 & 1.3333333 & 0.489418 & 0.510582 & 208 & 2151 & -1943 \\
 379 & 379^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.488127 & 0.511873 & 206 & 2151 & -1945 \\
 380 & 2^2 5^1 19^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.489474 & 0.510526 & 236 & 2181 & -1945 \\
 381 & 3^1 127^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.490814 & 0.509186 & 241 & 2186 & -1945 \\
 382 & 2^1 191^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.492147 & 0.507853 & 246 & 2191 & -1945 \\
 383 & 383^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.490862 & 0.509138 & 244 & 2191 & -1947 \\
 384 & 2^7 3^1 & \text{N} & \text{N} & 17 & 12 & 2.5882353 & 0.492188 & 0.507812 & 261 & 2208 & -1947 \\
 385 & 5^1 7^1 11^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.490909 & 0.509091 & 245 & 2208 & -1963 \\
 386 & 2^1 193^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.492228 & 0.507772 & 250 & 2213 & -1963 \\
 387 & 3^2 43^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.490956 & 0.509044 & 243 & 2213 & -1970 \\
 388 & 2^2 97^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.489691 & 0.510309 & 236 & 2213 & -1977 \\
 389 & 389^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.488432 & 0.511568 & 234 & 2213 & -1979 \\
 390 & 2^1 3^1 5^1 13^1 & \text{Y} & \text{N} & 65 & 0 & 1.0000000 & 0.489744 & 0.510256 & 299 & 2278 & -1979 \\
 391 & 17^1 23^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.491049 & 0.508951 & 304 & 2283 & -1979 \\
 392 & 2^3 7^2 & \text{N} & \text{N} & -23 & 18 & 1.4782609 & 0.489796 & 0.510204 & 281 & 2283 & -2002 \\
 393 & 3^1 131^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.491094 & 0.508906 & 286 & 2288 & -2002 \\
 394 & 2^1 197^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.492386 & 0.507614 & 291 & 2293 & -2002 \\
 395 & 5^1 79^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.493671 & 0.506329 & 296 & 2298 & -2002 \\
 396 & 2^2 3^2 11^1 & \text{N} & \text{N} & -74 & 58 & 1.2162162 & 0.492424 & 0.507576 & 222 & 2298 & -2076 \\
 397 & 397^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.491184 & 0.508816 & 220 & 2298 & -2078 \\
 398 & 2^1 199^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.492462 & 0.507538 & 225 & 2303 & -2078 \\
 399 & 3^1 7^1 19^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.491228 & 0.508772 & 209 & 2303 & -2094 \\
 400 & 2^4 5^2 & \text{N} & \text{N} & 34 & 29 & 1.6176471 & 0.492500 & 0.507500 & 243 & 2337 & -2094 \\
 401 & 401^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.491272 & 0.508728 & 241 & 2337 & -2096 \\
 402 & 2^1 3^1 67^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.490050 & 0.509950 & 225 & 2337 & -2112 \\
 403 & 13^1 31^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.491315 & 0.508685 & 230 & 2342 & -2112 \\
 404 & 2^2 101^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.490099 & 0.509901 & 223 & 2342 & -2119 \\
 405 & 3^4 5^1 & \text{N} & \text{N} & -11 & 6 & 1.8181818 & 0.488889 & 0.511111 & 212 & 2342 & -2130 \\
 406 & 2^1 7^1 29^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.487685 & 0.512315 & 196 & 2342 & -2146 \\
 407 & 11^1 37^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.488943 & 0.511057 & 201 & 2347 & -2146 \\
 408 & 2^3 3^1 17^1 & \text{N} & \text{N} & -48 & 32 & 1.3333333 & 0.487745 & 0.512255 & 153 & 2347 & -2194 \\
 409 & 409^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.486553 & 0.513447 & 151 & 2347 & -2196 \\
 410 & 2^1 5^1 41^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.485366 & 0.514634 & 135 & 2347 & -2212 \\
 411 & 3^1 137^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.486618 & 0.513382 & 140 & 2352 & -2212 \\
 412 & 2^2 103^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.485437 & 0.514563 & 133 & 2352 & -2219 \\
 413 & 7^1 59^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.486683 & 0.513317 & 138 & 2357 & -2219 \\
 414 & 2^1 3^2 23^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.487923 & 0.512077 & 168 & 2387 & -2219 \\
 415 & 5^1 83^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.489157 & 0.510843 & 173 & 2392 & -2219 \\
 416 & 2^5 13^1 & \text{N} & \text{N} & 13 & 8 & 2.0769231 & 0.490385 & 0.509615 & 186 & 2405 & -2219 \\
 417 & 3^1 139^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.491607 & 0.508393 & 191 & 2410 & -2219 \\
 418 & 2^1 11^1 19^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.490431 & 0.509569 & 175 & 2410 & -2235 \\
 419 & 419^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.489260 & 0.510740 & 173 & 2410 & -2237 \\
 420 & 2^2 3^1 5^1 7^1 & \text{N} & \text{N} & -155 & 90 & 1.1032258 & 0.488095 & 0.511905 & 18 & 2410 & -2392 \\
 421 & 421^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.486936 & 0.513064 & 16 & 2410 & -2394 \\
 422 & 2^1 211^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.488152 & 0.511848 & 21 & 2415 & -2394 \\
 423 & 3^2 47^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.486998 & 0.513002 & 14 & 2415 & -2401 \\
 424 & 2^3 53^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.488208 & 0.511792 & 23 & 2424 & -2401 \\
 425 & 5^2 17^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.487059 & 0.512941 & 16 & 2424 & -2408 \\ 
\end{array}
}
\end{equation*}
\clearpage 

\end{table} 

\newpage

\begin{table}[ht]
\label{table_conjecture_Mertens_ginvSeq_approx_values_LastPage} 

\centering
\tiny
\begin{equation*}
\boxed{
\begin{array}{cc|cc|ccc|cc|ccc}
 n & \mathbf{Primes} & \mathbf{Sqfree} & \mathbf{PPower} & g^{-1}(n) & 
 \lambda(n) g^{-1}(n) - \widehat{f}_1(n) & 
 \frac{\sum_{d|n} C_{\Omega(d)}(d)}{|g^{-1}(n)|} & 
 \mathcal{L}_{+}(n) & \mathcal{L}_{-}(n) & 
 G^{-1}(n) & G^{-1}_{+}(n) & G^{-1}_{-}(n) \\ \hline 
 426 & 2^1 3^1 71^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.485915 & 0.514085 & 0 & 2424 & -2424 \\
 427 & 7^1 61^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.487119 & 0.512881 & 5 & 2429 & -2424 \\
 428 & 2^2 107^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.485981 & 0.514019 & -2 & 2429 & -2431 \\
 429 & 3^1 11^1 13^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.484848 & 0.515152 & -18 & 2429 & -2447 \\
 430 & 2^1 5^1 43^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.483721 & 0.516279 & -34 & 2429 & -2463 \\
 431 & 431^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.482599 & 0.517401 & -36 & 2429 & -2465 \\
 432 & 2^4 3^3 & \text{N} & \text{N} & -80 & 75 & 1.5625000 & 0.481481 & 0.518519 & -116 & 2429 & -2545 \\
 433 & 433^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.480370 & 0.519630 & -118 & 2429 & -2547 \\
 434 & 2^1 7^1 31^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.479263 & 0.520737 & -134 & 2429 & -2563 \\
 435 & 3^1 5^1 29^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.478161 & 0.521839 & -150 & 2429 & -2579 \\
 436 & 2^2 109^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.477064 & 0.522936 & -157 & 2429 & -2586 \\
 437 & 19^1 23^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.478261 & 0.521739 & -152 & 2434 & -2586 \\
 438 & 2^1 3^1 73^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.477169 & 0.522831 & -168 & 2434 & -2602 \\
 439 & 439^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.476082 & 0.523918 & -170 & 2434 & -2604 \\
 440 & 2^3 5^1 11^1 & \text{N} & \text{N} & -48 & 32 & 1.3333333 & 0.475000 & 0.525000 & -218 & 2434 & -2652 \\
 441 & 3^2 7^2 & \text{N} & \text{N} & 14 & 9 & 1.3571429 & 0.476190 & 0.523810 & -204 & 2448 & -2652 \\
 442 & 2^1 13^1 17^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.475113 & 0.524887 & -220 & 2448 & -2668 \\
 443 & 443^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.474041 & 0.525959 & -222 & 2448 & -2670 \\
 444 & 2^2 3^1 37^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.475225 & 0.524775 & -192 & 2478 & -2670 \\
 445 & 5^1 89^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.476404 & 0.523596 & -187 & 2483 & -2670 \\
 446 & 2^1 223^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.477578 & 0.522422 & -182 & 2488 & -2670 \\
 447 & 3^1 149^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.478747 & 0.521253 & -177 & 2493 & -2670 \\
 448 & 2^6 7^1 & \text{N} & \text{N} & -15 & 10 & 2.3333333 & 0.477679 & 0.522321 & -192 & 2493 & -2685 \\
 449 & 449^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.476615 & 0.523385 & -194 & 2493 & -2687 \\
 450 & 2^1 3^2 5^2 & \text{N} & \text{N} & -74 & 58 & 1.2162162 & 0.475556 & 0.524444 & -268 & 2493 & -2761 \\
 451 & 11^1 41^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.476718 & 0.523282 & -263 & 2498 & -2761 \\
 452 & 2^2 113^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.475664 & 0.524336 & -270 & 2498 & -2768 \\
 453 & 3^1 151^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.476821 & 0.523179 & -265 & 2503 & -2768 \\
 454 & 2^1 227^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.477974 & 0.522026 & -260 & 2508 & -2768 \\
 455 & 5^1 7^1 13^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.476923 & 0.523077 & -276 & 2508 & -2784 \\
 456 & 2^3 3^1 19^1 & \text{N} & \text{N} & -48 & 32 & 1.3333333 & 0.475877 & 0.524123 & -324 & 2508 & -2832 \\
 457 & 457^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.474836 & 0.525164 & -326 & 2508 & -2834 \\
 458 & 2^1 229^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.475983 & 0.524017 & -321 & 2513 & -2834 \\
 459 & 3^3 17^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.477124 & 0.522876 & -312 & 2522 & -2834 \\
 460 & 2^2 5^1 23^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.478261 & 0.521739 & -282 & 2552 & -2834 \\
 461 & 461^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.477223 & 0.522777 & -284 & 2552 & -2836 \\
 462 & 2^1 3^1 7^1 11^1 & \text{Y} & \text{N} & 65 & 0 & 1.0000000 & 0.478355 & 0.521645 & -219 & 2617 & -2836 \\
 463 & 463^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.477322 & 0.522678 & -221 & 2617 & -2838 \\
 464 & 2^4 29^1 & \text{N} & \text{N} & -11 & 6 & 1.8181818 & 0.476293 & 0.523707 & -232 & 2617 & -2849 \\
 465 & 3^1 5^1 31^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.475269 & 0.524731 & -248 & 2617 & -2865 \\
 466 & 2^1 233^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.476395 & 0.523605 & -243 & 2622 & -2865 \\
 467 & 467^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.475375 & 0.524625 & -245 & 2622 & -2867 \\
 468 & 2^2 3^2 13^1 & \text{N} & \text{N} & -74 & 58 & 1.2162162 & 0.474359 & 0.525641 & -319 & 2622 & -2941 \\
 469 & 7^1 67^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.475480 & 0.524520 & -314 & 2627 & -2941 \\
 470 & 2^1 5^1 47^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.474468 & 0.525532 & -330 & 2627 & -2957 \\
 471 & 3^1 157^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.475584 & 0.524416 & -325 & 2632 & -2957 \\
 472 & 2^3 59^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.476695 & 0.523305 & -316 & 2641 & -2957 \\
 473 & 11^1 43^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.477801 & 0.522199 & -311 & 2646 & -2957 \\
 474 & 2^1 3^1 79^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.476793 & 0.523207 & -327 & 2646 & -2973 \\
 475 & 5^2 19^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.475789 & 0.524211 & -334 & 2646 & -2980 \\
 476 & 2^2 7^1 17^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.476891 & 0.523109 & -304 & 2676 & -2980 \\
 477 & 3^2 53^1 & \text{N} & \text{N} & -7 & 2 & 1.2857143 & 0.475891 & 0.524109 & -311 & 2676 & -2987 \\
 478 & 2^1 239^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.476987 & 0.523013 & -306 & 2681 & -2987 \\
 479 & 479^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.475992 & 0.524008 & -308 & 2681 & -2989 \\
 480 & 2^5 3^1 5^1 & \text{N} & \text{N} & -96 & 80 & 1.6666667 & 0.475000 & 0.525000 & -404 & 2681 & -3085 \\
 481 & 13^1 37^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.476091 & 0.523909 & -399 & 2686 & -3085 \\
 482 & 2^1 241^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.477178 & 0.522822 & -394 & 2691 & -3085 \\
 483 & 3^1 7^1 23^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.476190 & 0.523810 & -410 & 2691 & -3101 \\
 484 & 2^2 11^2 & \text{N} & \text{N} & 14 & 9 & 1.3571429 & 0.477273 & 0.522727 & -396 & 2705 & -3101 \\
 485 & 5^1 97^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.478351 & 0.521649 & -391 & 2710 & -3101 \\
 486 & 2^1 3^5 & \text{N} & \text{N} & 13 & 8 & 2.0769231 & 0.479424 & 0.520576 & -378 & 2723 & -3101 \\
 487 & 487^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.478439 & 0.521561 & -380 & 2723 & -3103 \\
 488 & 2^3 61^1 & \text{N} & \text{N} & 9 & 4 & 1.5555556 & 0.479508 & 0.520492 & -371 & 2732 & -3103 \\
 489 & 3^1 163^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.480573 & 0.519427 & -366 & 2737 & -3103 \\
 490 & 2^1 5^1 7^2 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.481633 & 0.518367 & -336 & 2767 & -3103 \\
 491 & 491^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.480652 & 0.519348 & -338 & 2767 & -3105 \\
 492 & 2^2 3^1 41^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.481707 & 0.518293 & -308 & 2797 & -3105 \\
 493 & 17^1 29^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.482759 & 0.517241 & -303 & 2802 & -3105 \\
 494 & 2^1 13^1 19^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.481781 & 0.518219 & -319 & 2802 & -3121 \\
 495 & 3^2 5^1 11^1 & \text{N} & \text{N} & 30 & 14 & 1.1666667 & 0.482828 & 0.517172 & -289 & 2832 & -3121 \\
 496 & 2^4 31^1 & \text{N} & \text{N} & -11 & 6 & 1.8181818 & 0.481855 & 0.518145 & -300 & 2832 & -3132 \\
 497 & 7^1 71^1 & \text{Y} & \text{N} & 5 & 0 & 1.0000000 & 0.482897 & 0.517103 & -295 & 2837 & -3132 \\
 498 & 2^1 3^1 83^1 & \text{Y} & \text{N} & -16 & 0 & 1.0000000 & 0.481928 & 0.518072 & -311 & 2837 & -3148 \\
 499 & 499^1 & \text{Y} & \text{Y} & -2 & 0 & 1.0000000 & 0.480962 & 0.519038 & -313 & 2837 & -3150 \\
 500 & 2^2 5^3 & \text{N} & \text{N} & -23 & 18 & 1.4782609 & 0.480000 & 0.520000 & -336 & 2837 & -3173 \\  
\end{array}
}
\end{equation*}

\end{table} 

\clearpage 

\newpage
\section{Table: Approximations of the summatory functions of $\lambda(n)$ and $\lambda_{\ast}(n)$} 
\label{table_LAstxSummatoryFuncCompsWithExact_v2} 

\begin{table}[ht!] 

\centering
\tiny 
\begin{equation*} 
\boxed{
\begin{array}{ccccc|ccc|ccccc|ccc} 
x & L(x) & \frac{\operatorname{sgn}(L(x))}{(-1)^{\floor{\log\log x}}} & 
    \frac{L(x)}{L_{\approx,1}(x)} & \frac{L(x)}{L_{\approx,2}(x)} & 
    x & L_{\ast}(x) & \frac{L(x)}{L_{\approx}^{\ast}(x)} & 
x & L(x) & \frac{\operatorname{sgn}(L(x))}{(-1)^{\floor{\log\log x}}} & 
    \frac{L(x)}{L_{\approx,1}(x)} & \frac{L(x)}{L_{\approx,2}(x)} & 
    x & L_{\ast}(x) & \frac{L(x)}{L_{\approx}^{\ast}(x)} \\ \hline 
 210 & -10 & 1 & -0.2546 & -0.1015 & 210 & 98 & 0.462138 & 255 & -7 & 1 & -0.1521 & -0.06098 & 255 & 125 & 0.485439 \\
 211 & -11 & 1 & -0.2790 & -0.1112 & 211 & 99 & 0.464641 & 256 & -6 & 1 & -0.1300 & -0.05211 & 256 & 124 & 0.479674 \\
 212 & -12 & 1 & -0.3032 & -0.1209 & 212 & 98 & 0.457778 & 257 & -7 & 1 & -0.1511 & -0.06060 & 257 & 125 & 0.481661 \\
 213 & -11 & 1 & -0.2769 & -0.1104 & 213 & 99 & 0.460278 & 258 & -8 & 1 & -0.1722 & -0.06905 & 258 & 126 & 0.483632 \\
 214 & -10 & 1 & -0.2507 & -0.1000 & 214 & 100 & 0.462755 & 259 & -7 & 1 & -0.1502 & -0.06023 & 259 & 127 & 0.485589 \\
 215 & -9 & 1 & -0.2248 & -0.08968 & 215 & 101 & 0.465208 & 260 & -6 & 1 & -0.1283 & -0.05147 & 260 & 126 & 0.479912 \\
 216 & -8 & 1 & -0.1991 & -0.07942 & 216 & 102 & 0.467639 & 261 & -7 & 1 & -0.1492 & -0.05987 & 261 & 125 & 0.474279 \\
 217 & -7 & 1 & -0.1735 & -0.06924 & 217 & 103 & 0.470048 & 262 & -6 & 1 & -0.1275 & -0.05116 & 262 & 126 & 0.476249 \\
 218 & -6 & 1 & -0.1482 & -0.05914 & 218 & 104 & 0.472434 & 263 & -7 & 1 & -0.1483 & -0.05951 & 263 & 127 & 0.478203 \\
 219 & -5 & 1 & -0.1230 & -0.04910 & 219 & 105 & 0.474799 & 264 & -8 & 1 & -0.1690 & -0.06781 & 264 & 128 & 0.480143 \\
 220 & -4 & 1 & -0.09807 & -0.03914 & 220 & 104 & 0.46814 & 265 & -7 & 1 & -0.1474 & -0.05916 & 265 & 129 & 0.482068 \\
 221 & -3 & 1 & -0.07328 & -0.02925 & 221 & 105 & 0.470502 & 266 & -8 & 1 & -0.1679 & -0.06741 & 266 & 130 & 0.483979 \\
 222 & -4 & 1 & -0.09735 & -0.03886 & 222 & 106 & 0.472844 & 267 & -7 & 1 & -0.1465 & -0.05881 & 267 & 131 & 0.485875 \\
 223 & -5 & 1 & -0.1212 & -0.04841 & 223 & 107 & 0.475164 & 268 & -8 & 1 & -0.1669 & -0.06701 & 268 & 130 & 0.480367 \\
 224 & -4 & 1 & -0.09664 & -0.03859 & 224 & 108 & 0.477464 & 269 & -9 & 1 & -0.1872 & -0.07517 & 269 & 131 & 0.482263 \\
 225 & -3 & 1 & -0.07221 & -0.02884 & 225 & 109 & 0.479743 & 270 & -10 & 1 & -0.2073 & -0.08328 & 270 & 132 & 0.484144 \\
 226 & -2 & 1 & -0.04797 & -0.01916 & 226 & 110 & 0.482002 & 271 & -11 & 1 & -0.2274 & -0.09134 & 271 & 133 & 0.486012 \\
 227 & -3 & 1 & -0.07170 & -0.02864 & 227 & 111 & 0.484241 & 272 & -12 & 1 & -0.2473 & -0.09935 & 272 & 132 & 0.480584 \\
 228 & -2 & 1 & -0.04763 & -0.01903 & 228 & 110 & 0.477774 & 273 & -13 & 1 & -0.2671 & -0.1073 & 273 & 133 & 0.482451 \\
 229 & -3 & 1 & -0.07118 & -0.02844 & 229 & 111 & 0.480012 & 274 & -12 & 1 & -0.2458 & -0.09878 & 274 & 134 & 0.484305 \\
 230 & -4 & 1 & -0.09458 & -0.03779 & 230 & 112 & 0.482231 & 275 & -13 & 1 & -0.2655 & -0.1067 & 275 & 133 & 0.478943 \\
 231 & -5 & 1 & -0.1178 & -0.04708 & 231 & 113 & 0.48443 & 276 & -12 & 1 & -0.2444 & -0.09822 & 276 & 132 & 0.473619 \\
 232 & -4 & 1 & -0.09391 & -0.03754 & 232 & 114 & 0.486611 & 277 & -13 & 1 & -0.2639 & -0.1061 & 277 & 133 & 0.475485 \\
 233 & -5 & 1 & -0.1170 & -0.04676 & 233 & 115 & 0.488772 & 278 & -12 & 1 & -0.2429 & -0.09766 & 278 & 134 & 0.477336 \\
 234 & -4 & 1 & -0.09325 & -0.03728 & 234 & 114 & 0.482451 & 279 & -13 & 1 & -0.2624 & -0.1055 & 279 & 133 & 0.472076 \\
 235 & -3 & 1 & -0.06970 & -0.02787 & 235 & 115 & 0.484612 & 280 & -14 & 1 & -0.2817 & -0.1133 & 280 & 134 & 0.473927 \\
 236 & -4 & 1 & -0.09261 & -0.03704 & 236 & 114 & 0.478363 & 281 & -15 & 1 & -0.3010 & -0.1210 & 281 & 135 & 0.475765 \\
 237 & -3 & 1 & -0.06922 & -0.02768 & 237 & 115 & 0.480523 & 282 & -16 & 1 & -0.3201 & -0.1288 & 282 & 136 & 0.477589 \\
 238 & -4 & 1 & -0.09197 & -0.03679 & 238 & 116 & 0.482665 & 283 & -17 & 1 & -0.3391 & -0.1364 & 283 & 137 & 0.479401 \\
 239 & -5 & 1 & -0.1146 & -0.04584 & 239 & 117 & 0.484789 & 284 & -18 & 1 & -0.3580 & -0.1440 & 284 & 136 & 0.474226 \\
 240 & -4 & 1 & -0.09134 & -0.03655 & 240 & 116 & 0.478643 & 285 & -19 & 1 & -0.3768 & -0.1516 & 285 & 137 & 0.476037 \\
 241 & -5 & 1 & -0.1138 & -0.04554 & 241 & 117 & 0.480766 & 286 & -20 & 1 & -0.3955 & -0.1592 & 286 & 138 & 0.477835 \\
 242 & -6 & 1 & -0.1361 & -0.05447 & 242 & 116 & 0.474687 & 287 & -19 & 1 & -0.3747 & -0.1508 & 287 & 139 & 0.47962 \\
 243 & -7 & 1 & -0.1582 & -0.06334 & 243 & 117 & 0.476809 & 288 & -20 & 1 & -0.3933 & -0.1583 & 288 & 138 & 0.474516 \\
 244 & -8 & 1 & -0.1802 & -0.07215 & 244 & 116 & 0.470796 & 289 & -19 & 1 & -0.3725 & -0.1500 & 289 & 137 & 0.469448 \\
 245 & -9 & 1 & -0.2021 & -0.08091 & 245 & 115 & 0.464832 & 290 & -20 & 1 & -0.3910 & -0.1574 & 290 & 138 & 0.471244 \\
 246 & -10 & 1 & -0.2238 & -0.08961 & 246 & 116 & 0.466968 & 291 & -19 & 1 & -0.3704 & -0.1492 & 291 & 139 & 0.473028 \\
 247 & -9 & 1 & -0.2007 & -0.08039 & 247 & 117 & 0.469087 & 292 & -20 & 1 & -0.3888 & -0.1566 & 292 & 138 & 0.468016 \\
 248 & -8 & 1 & -0.1779 & -0.07123 & 248 & 118 & 0.471189 & 293 & -21 & 1 & -0.4071 & -0.1640 & 293 & 139 & 0.469799 \\
 249 & -7 & 1 & -0.1551 & -0.06213 & 249 & 119 & 0.473274 & 294 & -20 & 1 & -0.3866 & -0.1558 & 294 & 138 & 0.464832 \\
 250 & -6 & 1 & -0.1325 & -0.05309 & 250 & 120 & 0.475342 & 295 & -19 & 1 & -0.3663 & -0.1476 & 295 & 139 & 0.466614 \\
 251 & -7 & 1 & -0.1541 & -0.06174 & 251 & 121 & 0.477393 & 296 & -18 & 1 & -0.3460 & -0.1394 & 296 & 140 & 0.468383 \\
 252 & -8 & 1 & -0.1755 & -0.07034 & 252 & 122 & 0.479429 & 297 & -17 & 1 & -0.3259 & -0.1313 & 297 & 141 & 0.47014 \\
 253 & -7 & 1 & -0.1531 & -0.06136 & 253 & 123 & 0.481448 & 298 & -16 & 1 & -0.3059 & -0.1233 & 298 & 142 & 0.471886 \\
 254 & -6 & 1 & -0.1308 & -0.05243 & 254 & 124 & 0.483451 & 299 & -15 & 1 & -0.2860 & -0.1153 & 299 & 143 & 0.473619 \\
\end{array}
}
\end{equation*} 

\bigskip\hrule\smallskip 

\captionsetup{singlelinecheck=off} 
\caption*{\textbf{\rm \bf Table \thesection:} 
          \textbf{Approximations to the summatory functions of $\lambda(n)$ and $\lambda_{\ast}(n)$. } 
          \begin{itemize}[noitemsep,topsep=0pt,leftmargin=0.23in] 
          \item[$\blacktriangleright$] 
          We define the exact summatory functions over these sequences by 
          $L(x) := \sum_{n \leq x} \lambda(n)$ and $L_{\ast}(n) := \sum_{n \leq x} \lambda_{\ast}(n)$. 
          \item[$\blacktriangleright$] 
          We compare the ratios of the following two functions with $L(x)$: 
          $L_{\approx,1}(x) := \sum_{k=1}^{\log\log x} \frac{x}{\log x} \cdot \frac{(-\log\log x)^{k-1}}{(k-1)!}$ and 
          $L_{\approx,2}(x) := \frac{x^{3/4} (\log x)^{1/2}}{\sqrt{\log\log x}}$. 
          \item[$\blacktriangleright$] Finally, we compare the approximations (very accurate) to 
          $L_{\ast}(x)$ by the summatory function $\sum_{k \leq x} \widehat{c} (-1)^{k} \cdot 2^{-k}$ using the 
          approximation $L_{\approx}^{\ast}(x) := \frac{2\widehat{c}}{3} x$. 
          \end{itemize} 
          } 

\end{table}

\textbf{(TODO) ... Are these ratios inverted, or possibly need to take much, much larger $x$ to 
        demonstrate this point? } \\ 
\textbf{(TODO) ... Are going to need \texttt{SageMath} to compute these functions for very large $x$, 
        say for $x \gg 12000$ ... } 

\clearpage 

\newpage 
\begin{table}[ht]

\centering
\tiny
\begin{equation*}
\boxed{
\begin{array}{ccccc|ccc|ccccc|ccc}
x & L(x) & \frac{\operatorname{sgn}(L(x))}{(-1)^{\floor{\log\log x}}} & 
    \frac{L(x)}{L_{\approx,1}(x)} & \frac{L(x)}{L_{\approx,2}(x)} & 
    x & L_{\ast}(x) & \frac{L(x)}{L_{\approx}^{\ast}(x)} & 
x & L(x) & \frac{\operatorname{sgn}(L(x))}{(-1)^{\floor{\log\log x}}} & 
    \frac{L(x)}{L_{\approx,1}(x)} & \frac{L(x)}{L_{\approx,2}(x)} & 
    x & L_{\ast}(x) & \frac{L(x)}{L_{\approx}^{\ast}(x)} \\ \hline 
 300 & -16 & 1 & -0.3042 & -0.1226 & 300 & 144 & 0.475342 & 375 & -9 & 1 & -0.1422 & -0.05787 & 375 & 173 & 0.456856 \\
 301 & -15 & 1 & -0.2844 & -0.1147 & 301 & 145 & 0.477052 & 376 & -8 & 1 & -0.1262 & -0.05133 & 376 & 174 & 0.458275 \\
 302 & -14 & 1 & -0.2647 & -0.1067 & 302 & 146 & 0.478752 & 377 & -7 & 1 & -0.1101 & -0.04482 & 377 & 175 & 0.459686 \\
 303 & -13 & 1 & -0.2451 & -0.09886 & 303 & 147 & 0.48044 & 378 & -8 & 1 & -0.1256 & -0.05112 & 378 & 176 & 0.46109 \\
 304 & -14 & 1 & -0.2633 & -0.1062 & 304 & 146 & 0.475602 & 379 & -9 & 1 & -0.1410 & -0.05739 & 379 & 177 & 0.462486 \\
 305 & -13 & 1 & -0.2438 & -0.09835 & 305 & 147 & 0.47729 & 380 & -8 & 1 & -0.1251 & -0.05091 & 380 & 176 & 0.458663 \\
 306 & -12 & 1 & -0.2245 & -0.09055 & 306 & 146 & 0.472494 & 381 & -7 & 1 & -0.1092 & -0.04445 & 381 & 177 & 0.460058 \\
 307 & -13 & 1 & -0.2425 & -0.09785 & 307 & 147 & 0.47418 & 382 & -6 & 1 & -0.09338 & -0.03802 & 382 & 178 & 0.461446 \\
 308 & -12 & 1 & -0.2233 & -0.09009 & 308 & 146 & 0.469426 & 383 & -7 & 1 & -0.1087 & -0.04427 & 383 & 179 & 0.462827 \\
 309 & -11 & 1 & -0.2041 & -0.08237 & 309 & 147 & 0.471111 & 384 & -6 & 1 & -0.09298 & -0.03787 & 384 & 180 & 0.464201 \\
 310 & -12 & 1 & -0.2221 & -0.08963 & 310 & 148 & 0.472786 & 385 & -7 & 1 & -0.1082 & -0.04409 & 385 & 181 & 0.465567 \\
 311 & -13 & 1 & -0.2399 & -0.09686 & 311 & 149 & 0.47445 & 386 & -6 & 1 & -0.09258 & -0.03771 & 386 & 182 & 0.466927 \\
 312 & -14 & 1 & -0.2577 & -0.1040 & 312 & 150 & 0.476103 & 387 & -7 & 1 & -0.1078 & -0.04391 & 387 & 181 & 0.463161 \\
 313 & -15 & 1 & -0.2754 & -0.1112 & 313 & 151 & 0.477746 & 388 & -8 & 1 & -0.1229 & -0.05008 & 388 & 180 & 0.459415 \\
 314 & -14 & 1 & -0.2563 & -0.1035 & 314 & 152 & 0.479379 & 389 & -9 & 1 & -0.1380 & -0.05622 & 389 & 181 & 0.46078 \\
 315 & -13 & 1 & -0.2374 & -0.09589 & 315 & 151 & 0.474713 & 390 & -8 & 1 & -0.1224 & -0.04988 & 390 & 182 & 0.462138 \\
 316 & -14 & 1 & -0.2550 & -0.1030 & 316 & 150 & 0.470077 & 391 & -7 & 1 & -0.1069 & -0.04355 & 391 & 183 & 0.463489 \\
 317 & -15 & 1 & -0.2725 & -0.1101 & 317 & 151 & 0.471718 & 392 & -8 & 1 & -0.1219 & -0.04968 & 392 & 182 & 0.45978 \\
 318 & -16 & 1 & -0.2899 & -0.1171 & 318 & 152 & 0.473349 & 393 & -7 & 1 & -0.1064 & -0.04338 & 393 & 183 & 0.46113 \\
 319 & -15 & 1 & -0.2711 & -0.1095 & 319 & 153 & 0.474969 & 394 & -6 & 1 & -0.09101 & -0.03711 & 394 & 184 & 0.462473 \\
 320 & -16 & 1 & -0.2884 & -0.1166 & 320 & 152 & 0.47039 & 395 & -5 & 1 & -0.07568 & -0.03086 & 395 & 185 & 0.463809 \\
 321 & -15 & 1 & -0.2697 & -0.1090 & 321 & 153 & 0.47201 & 396 & -6 & 1 & -0.09063 & -0.03696 & 396 & 186 & 0.465139 \\
 322 & -16 & 1 & -0.2869 & -0.1160 & 322 & 154 & 0.473619 & 397 & -7 & 1 & -0.1055 & -0.04304 & 397 & 187 & 0.466461 \\
 323 & -15 & 1 & -0.2683 & -0.1085 & 323 & 155 & 0.475219 & 398 & -6 & 1 & -0.09025 & -0.03681 & 398 & 188 & 0.467778 \\
 324 & -14 & 1 & -0.2498 & -0.1010 & 324 & 156 & 0.476809 & 399 & -7 & 1 & -0.1051 & -0.04287 & 399 & 189 & 0.469087 \\
 325 & -15 & 1 & -0.2669 & -0.1079 & 325 & 155 & 0.472295 & 400 & -6 & 1 & -0.08987 & -0.03667 & 400 & 190 & 0.47039 \\
 326 & -14 & 1 & -0.2485 & -0.1005 & 326 & 156 & 0.473884 & 401 & -7 & 1 & -0.1046 & -0.04270 & 401 & 191 & 0.471687 \\
 327 & -13 & 1 & -0.2302 & -0.09310 & 327 & 157 & 0.475463 & 402 & -8 & 1 & -0.1193 & -0.04870 & 402 & 192 & 0.472977 \\
 328 & -12 & 1 & -0.2119 & -0.08574 & 328 & 158 & 0.477032 & 403 & -7 & 1 & -0.1042 & -0.04253 & 403 & 193 & 0.47426 \\
 329 & -11 & 1 & -0.1938 & -0.07840 & 329 & 159 & 0.478592 & 404 & -8 & 1 & -0.1188 & -0.04851 & 404 & 192 & 0.470635 \\
 330 & -10 & 1 & -0.1757 & -0.07111 & 330 & 160 & 0.480143 & 405 & -9 & 1 & -0.1334 & -0.05447 & 405 & 191 & 0.467028 \\
 331 & -11 & 1 & -0.1928 & -0.07803 & 331 & 161 & 0.481684 & 406 & -10 & 1 & -0.1479 & -0.06040 & 406 & 192 & 0.468317 \\
 332 & -12 & 1 & -0.2098 & -0.08492 & 332 & 160 & 0.477251 & 407 & -9 & 1 & -0.1329 & -0.05426 & 407 & 193 & 0.469599 \\
 333 & -13 & 1 & -0.2267 & -0.09178 & 333 & 159 & 0.472844 & 408 & -10 & 1 & -0.1473 & -0.06017 & 408 & 194 & 0.470876 \\
 334 & -12 & 1 & -0.2088 & -0.08452 & 334 & 160 & 0.474393 & 409 & -11 & 1 & -0.1617 & -0.06606 & 409 & 195 & 0.472146 \\
 335 & -11 & 1 & -0.1909 & -0.07730 & 335 & 161 & 0.475933 & 410 & -12 & 1 & -0.1761 & -0.07193 & 410 & 196 & 0.473409 \\
 336 & -10 & 1 & -0.1731 & -0.07010 & 336 & 160 & 0.471569 & 411 & -11 & 1 & -0.1611 & -0.06581 & 411 & 197 & 0.474667 \\
 337 & -11 & 1 & -0.1900 & -0.07694 & 337 & 161 & 0.473108 & 412 & -12 & 1 & -0.1754 & -0.07165 & 412 & 196 & 0.471111 \\
 338 & -12 & 1 & -0.2067 & -0.08373 & 338 & 160 & 0.468779 & 413 & -11 & 1 & -0.1604 & -0.06556 & 413 & 197 & 0.472368 \\
 339 & -11 & 1 & -0.1890 & -0.07658 & 339 & 161 & 0.470317 & 414 & -10 & 1 & -0.1456 & -0.05948 & 414 & 196 & 0.468835 \\
 340 & -10 & 1 & -0.1714 & -0.06945 & 340 & 160 & 0.466021 & 415 & -9 & 1 & -0.1307 & -0.05343 & 415 & 197 & 0.470092 \\
 341 & -9 & 1 & -0.1539 & -0.06236 & 341 & 161 & 0.467559 & 416 & -8 & 1 & -0.1160 & -0.04741 & 416 & 198 & 0.471342 \\
 342 & -8 & 1 & -0.1365 & -0.05531 & 342 & 160 & 0.463296 & 417 & -7 & 1 & -0.1013 & -0.04140 & 417 & 199 & 0.472587 \\
 343 & -9 & 1 & -0.1532 & -0.06208 & 343 & 161 & 0.464832 & 418 & -8 & 1 & -0.1155 & -0.04723 & 418 & 200 & 0.473825 \\
 344 & -8 & 1 & -0.1358 & -0.05505 & 344 & 162 & 0.46636 & 419 & -9 & 1 & -0.1297 & -0.05303 & 419 & 201 & 0.475058 \\
 345 & -9 & 1 & -0.1524 & -0.06180 & 345 & 163 & 0.467879 & 420 & -10 & 1 & -0.1438 & -0.05881 & 420 & 200 & 0.471569 \\
 346 & -8 & 1 & -0.1352 & -0.05480 & 346 & 164 & 0.469388 & 421 & -11 & 1 & -0.1579 & -0.06457 & 421 & 201 & 0.472801 \\
 347 & -9 & 1 & -0.1517 & -0.06151 & 347 & 165 & 0.47089 & 422 & -10 & 1 & -0.1432 & -0.05860 & 422 & 202 & 0.474028 \\
 348 & -8 & 1 & -0.1345 & -0.05456 & 348 & 164 & 0.466691 & 423 & -11 & 1 & -0.1573 & -0.06433 & 423 & 201 & 0.470566 \\
 349 & -9 & 1 & -0.1510 & -0.06124 & 349 & 165 & 0.468191 & 424 & -10 & 1 & -0.1427 & -0.05838 & 424 & 202 & 0.471792 \\
 350 & -8 & 1 & -0.1339 & -0.05431 & 350 & 164 & 0.464024 & 425 & -11 & 1 & -0.1566 & -0.06410 & 425 & 201 & 0.468351 \\
 351 & -7 & 1 & -0.1169 & -0.04741 & 351 & 165 & 0.465523 & 426 & -12 & 1 & -0.1705 & -0.06979 & 426 & 202 & 0.469577 \\
 352 & -6 & 1 & -0.09995 & -0.04055 & 352 & 166 & 0.467014 & 427 & -11 & 1 & -0.1560 & -0.06386 & 427 & 203 & 0.470796 \\
 353 & -7 & 1 & -0.1163 & -0.04720 & 353 & 167 & 0.468497 & 428 & -12 & 1 & -0.1699 & -0.06954 & 428 & 202 & 0.467382 \\
 354 & -8 & 1 & -0.1326 & -0.05383 & 354 & 168 & 0.469971 & 429 & -13 & 1 & -0.1837 & -0.07519 & 429 & 203 & 0.468601 \\
 355 & -7 & 1 & -0.1158 & -0.04699 & 355 & 169 & 0.471436 & 430 & -14 & 1 & -0.1974 & -0.08083 & 430 & 204 & 0.469814 \\
 356 & -8 & 1 & -0.1320 & -0.05359 & 356 & 168 & 0.46733 & 431 & -15 & 1 & -0.2111 & -0.08645 & 431 & 205 & 0.471022 \\
 357 & -9 & 1 & -0.1482 & -0.06015 & 357 & 169 & 0.468795 & 432 & -16 & 1 & -0.2248 & -0.09204 & 432 & 204 & 0.467639 \\
 358 & -8 & 1 & -0.1314 & -0.05335 & 358 & 170 & 0.470252 & 433 & -17 & 1 & -0.2383 & -0.09762 & 433 & 205 & 0.468846 \\
 359 & -9 & 1 & -0.1475 & -0.05989 & 359 & 171 & 0.4717 & 434 & -18 & 1 & -0.2519 & -0.1032 & 434 & 206 & 0.470048 \\
 360 & -8 & 1 & -0.1308 & -0.05312 & 360 & 170 & 0.467639 & 435 & -19 & 1 & -0.2654 & -0.1087 & 435 & 207 & 0.471244 \\
 361 & -7 & 1 & -0.1142 & -0.04638 & 361 & 169 & 0.463601 & 436 & -20 & 1 & -0.2788 & -0.1142 & 436 & 206 & 0.467892 \\
 362 & -6 & 1 & -0.09765 & -0.03967 & 362 & 170 & 0.465056 & 437 & -19 & 1 & -0.2643 & -0.1083 & 437 & 207 & 0.469087 \\
 363 & -7 & 1 & -0.1137 & -0.04618 & 363 & 169 & 0.461046 & 438 & -20 & 1 & -0.2777 & -0.1138 & 438 & 208 & 0.470277 \\
 364 & -6 & 1 & -0.09721 & -0.03949 & 364 & 168 & 0.457059 & 439 & -21 & 1 & -0.2911 & -0.1193 & 439 & 209 & 0.471462 \\
 365 & -5 & 1 & -0.08082 & -0.03284 & 365 & 169 & 0.45852 & 440 & -22 & 1 & -0.3043 & -0.1247 & 440 & 210 & 0.472641 \\
 366 & -6 & 1 & -0.09676 & -0.03932 & 366 & 170 & 0.459973 & 441 & -21 & 1 & -0.2900 & -0.1189 & 441 & 211 & 0.473815 \\
 367 & -7 & 1 & -0.1126 & -0.04578 & 367 & 171 & 0.461418 & 442 & -22 & 1 & -0.3032 & -0.1243 & 442 & 212 & 0.474983 \\
 368 & -8 & 1 & -0.1284 & -0.05221 & 368 & 170 & 0.457473 & 443 & -23 & 1 & -0.3164 & -0.1297 & 443 & 213 & 0.476146 \\
 369 & -9 & 1 & -0.1442 & -0.05861 & 369 & 169 & 0.45355 & 444 & -22 & 1 & -0.3020 & -0.1239 & 444 & 212 & 0.472844 \\
 370 & -10 & 1 & -0.1598 & -0.06498 & 370 & 170 & 0.455 & 445 & -21 & 1 & -0.2878 & -0.1180 & 445 & 213 & 0.474006 \\
 371 & -9 & 1 & -0.1435 & -0.05836 & 371 & 171 & 0.456443 & 446 & -20 & 1 & -0.2736 & -0.1122 & 446 & 214 & 0.475164 \\
 372 & -8 & 1 & -0.1273 & -0.05177 & 372 & 170 & 0.452554 & 447 & -19 & 1 & -0.2594 & -0.1064 & 447 & 215 & 0.476316 \\
 373 & -9 & 1 & -0.1429 & -0.05811 & 373 & 171 & 0.453996 & 448 & -20 & 1 & -0.2725 & -0.1118 & 448 & 214 & 0.473043 \\
 374 & -10 & 1 & -0.1584 & -0.06444 & 374 & 172 & 0.45543 & 449 & -21 & 1 & -0.2856 & -0.1172 & 449 & 215 & 0.474195 \\
\end{array}
}
\end{equation*}

\end{table} 

\clearpage 

\newpage 
\begin{table}[ht]

\centering
\tiny
\begin{equation*}
\boxed{
\begin{array}{ccccc|ccc|ccccc|ccc}
x & L(x) & \frac{\operatorname{sgn}(L(x))}{(-1)^{\floor{\log\log x}}} & 
    \frac{L(x)}{L_{\approx,1}(x)} & \frac{L(x)}{L_{\approx,2}(x)} & 
    x & L_{\ast}(x) & \frac{L(x)}{L_{\approx}^{\ast}(x)} & 
x & L(x) & \frac{\operatorname{sgn}(L(x))}{(-1)^{\floor{\log\log x}}} & 
    \frac{L(x)}{L_{\approx,1}(x)} & \frac{L(x)}{L_{\approx,2}(x)} & 
    x & L_{\ast}(x) & \frac{L(x)}{L_{\approx}^{\ast}(x)} \\ \hline 
450 & -22 & 1 & -0.2987 & -0.1226 & 450 & 216 & 0.475342 & 525 & -17 & 1 & -0.2028 & -0.08389 & 525 & 255 & 0.481 \\
 451 & -21 & 1 & -0.2846 & -0.1168 & 451 & 217 & 0.476483 & 526 & -16 & 1 & -0.1906 & -0.07884 & 526 & 256 & 0.481969 \\
 452 & -22 & 1 & -0.2976 & -0.1221 & 452 & 216 & 0.473238 & 527 & -15 & 1 & -0.1784 & -0.07380 & 527 & 257 & 0.482933 \\
 453 & -21 & 1 & -0.2835 & -0.1164 & 453 & 217 & 0.47438 & 528 & -14 & 1 & -0.1662 & -0.06878 & 528 & 256 & 0.480143 \\
 454 & -20 & 1 & -0.2695 & -0.1106 & 454 & 218 & 0.475516 & 529 & -13 & 1 & -0.1541 & -0.06377 & 529 & 255 & 0.477363 \\
 455 & -21 & 1 & -0.2825 & -0.1160 & 455 & 219 & 0.476648 & 530 & -14 & 1 & -0.1657 & -0.06857 & 530 & 256 & 0.478331 \\
 456 & -22 & 1 & -0.2954 & -0.1213 & 456 & 220 & 0.477774 & 531 & -15 & 1 & -0.1773 & -0.07336 & 531 & 255 & 0.475565 \\
 457 & -23 & 1 & -0.3082 & -0.1266 & 457 & 221 & 0.478895 & 532 & -14 & 1 & -0.1652 & -0.06837 & 532 & 254 & 0.47281 \\
 458 & -22 & 1 & -0.2943 & -0.1209 & 458 & 222 & 0.480012 & 533 & -13 & 1 & -0.1531 & -0.06339 & 533 & 255 & 0.473781 \\
 459 & -21 & 1 & -0.2804 & -0.1152 & 459 & 223 & 0.481124 & 534 & -14 & 1 & -0.1647 & -0.06817 & 534 & 256 & 0.474748 \\
 460 & -20 & 1 & -0.2666 & -0.1095 & 460 & 222 & 0.477925 & 535 & -13 & 1 & -0.1527 & -0.06321 & 535 & 257 & 0.475712 \\
 461 & -21 & 1 & -0.2794 & -0.1148 & 461 & 223 & 0.479036 & 536 & -12 & 1 & -0.1407 & -0.05826 & 536 & 258 & 0.476672 \\
 462 & -20 & 1 & -0.2656 & -0.1091 & 462 & 224 & 0.480143 & 537 & -11 & 1 & -0.1288 & -0.05333 & 537 & 259 & 0.477628 \\
 463 & -21 & 1 & -0.2784 & -0.1144 & 463 & 225 & 0.481245 & 538 & -10 & 1 & -0.1169 & -0.04841 & 538 & 260 & 0.478581 \\
 464 & -22 & 1 & -0.2911 & -0.1196 & 464 & 224 & 0.478074 & 539 & -11 & 1 & -0.1284 & -0.05317 & 539 & 259 & 0.475856 \\
 465 & -23 & 1 & -0.3038 & -0.1249 & 465 & 225 & 0.479175 & 540 & -10 & 1 & -0.1165 & -0.04827 & 540 & 258 & 0.473141 \\
 466 & -22 & 1 & -0.2901 & -0.1192 & 466 & 226 & 0.480272 & 541 & -11 & 1 & -0.1280 & -0.05302 & 541 & 259 & 0.474097 \\
 467 & -23 & 1 & -0.3027 & -0.1244 & 467 & 227 & 0.481364 & 542 & -10 & 1 & -0.1161 & -0.04813 & 542 & 260 & 0.475049 \\
 468 & -24 & 1 & -0.3153 & -0.1296 & 468 & 228 & 0.482451 & 543 & -9 & 1 & -0.1044 & -0.04325 & 543 & 261 & 0.475998 \\
 469 & -23 & 1 & -0.3016 & -0.1240 & 469 & 229 & 0.483534 & 544 & -8 & 1 & -0.09263 & -0.03839 & 544 & 262 & 0.476944 \\
 470 & -24 & 1 & -0.3142 & -0.1292 & 470 & 230 & 0.484612 & 545 & -7 & 1 & -0.08093 & -0.03354 & 545 & 263 & 0.477886 \\
 471 & -23 & 1 & -0.3006 & -0.1236 & 471 & 231 & 0.485686 & 546 & -6 & 1 & -0.06926 & -0.02871 & 546 & 264 & 0.478824 \\
 472 & -22 & 1 & -0.2870 & -0.1180 & 472 & 232 & 0.486755 & 547 & -7 & 1 & -0.08068 & -0.03345 & 547 & 265 & 0.479759 \\
 473 & -21 & 1 & -0.2734 & -0.1125 & 473 & 233 & 0.48782 & 548 & -8 & 1 & -0.09206 & -0.03817 & 548 & 264 & 0.477076 \\
 474 & -22 & 1 & -0.2860 & -0.1176 & 474 & 234 & 0.48888 & 549 & -9 & 1 & -0.1034 & -0.04288 & 549 & 263 & 0.474404 \\
 475 & -23 & 1 & -0.2984 & -0.1228 & 475 & 233 & 0.485766 & 550 & -8 & 1 & -0.09178 & -0.03806 & 550 & 262 & 0.471741 \\
 476 & -22 & 1 & -0.2850 & -0.1173 & 476 & 232 & 0.482665 & 551 & -7 & 1 & -0.08019 & -0.03325 & 551 & 263 & 0.472682 \\
 477 & -23 & 1 & -0.2974 & -0.1224 & 477 & 231 & 0.479577 & 552 & -8 & 1 & -0.09150 & -0.03795 & 552 & 264 & 0.473619 \\
 478 & -22 & 1 & -0.2840 & -0.1169 & 478 & 232 & 0.480645 & 553 & -7 & 1 & -0.07994 & -0.03316 & 553 & 265 & 0.474554 \\
 479 & -23 & 1 & -0.2963 & -0.1220 & 479 & 233 & 0.481709 & 554 & -6 & 1 & -0.06842 & -0.02838 & 554 & 266 & 0.475485 \\
 480 & -24 & 1 & -0.3087 & -0.1271 & 480 & 234 & 0.482769 & 555 & -7 & 1 & -0.07970 & -0.03307 & 555 & 267 & 0.476412 \\
 481 & -23 & 1 & -0.2953 & -0.1216 & 481 & 235 & 0.483824 & 556 & -8 & 1 & -0.09095 & -0.03774 & 556 & 266 & 0.473774 \\
 482 & -22 & 1 & -0.2820 & -0.1161 & 482 & 236 & 0.484875 & 557 & -9 & 1 & -0.1022 & -0.04239 & 557 & 267 & 0.474702 \\
 483 & -23 & 1 & -0.2943 & -0.1212 & 483 & 237 & 0.485921 & 558 & -8 & 1 & -0.09067 & -0.03763 & 558 & 266 & 0.472076 \\
 484 & -22 & 1 & -0.2810 & -0.1157 & 484 & 238 & 0.486963 & 559 & -7 & 1 & -0.07922 & -0.03288 & 559 & 267 & 0.473003 \\
 485 & -21 & 1 & -0.2678 & -0.1103 & 485 & 239 & 0.488001 & 560 & -6 & 1 & -0.06780 & -0.02814 & 560 & 266 & 0.47039 \\
 486 & -20 & 1 & -0.2546 & -0.1049 & 486 & 240 & 0.489035 & 561 & -7 & 1 & -0.07898 & -0.03279 & 561 & 267 & 0.471317 \\
 487 & -21 & 1 & -0.2668 & -0.1099 & 487 & 241 & 0.490064 & 562 & -6 & 1 & -0.06760 & -0.02806 & 562 & 268 & 0.47224 \\
 488 & -20 & 1 & -0.2537 & -0.1045 & 488 & 242 & 0.491089 & 563 & -7 & 1 & -0.07874 & -0.03270 & 563 & 269 & 0.473161 \\
 489 & -19 & 1 & -0.2406 & -0.09915 & 489 & 243 & 0.49211 & 564 & -6 & 1 & -0.06739 & -0.02799 & 564 & 268 & 0.470566 \\
 490 & -18 & 1 & -0.2275 & -0.09378 & 490 & 242 & 0.489085 & 565 & -5 & 1 & -0.05608 & -0.02329 & 565 & 269 & 0.471486 \\
 491 & -19 & 1 & -0.2398 & -0.09883 & 491 & 243 & 0.490105 & 566 & -4 & 1 & -0.04480 & -0.01861 & 566 & 270 & 0.472402 \\
 492 & -18 & 1 & -0.2268 & -0.09348 & 492 & 242 & 0.487096 & 567 & -5 & 1 & -0.05591 & -0.02322 & 567 & 269 & 0.469823 \\
 493 & -17 & 1 & -0.2138 & -0.08814 & 493 & 243 & 0.488117 & 568 & -4 & 1 & -0.04466 & -0.01855 & 568 & 270 & 0.470739 \\
 494 & -18 & 1 & -0.2260 & -0.09318 & 494 & 244 & 0.489134 & 569 & -5 & 1 & -0.05575 & -0.02316 & 569 & 271 & 0.471652 \\
 495 & -17 & 1 & -0.2131 & -0.08786 & 495 & 243 & 0.486145 & 570 & -4 & 1 & -0.04453 & -0.01850 & 570 & 272 & 0.472562 \\
 496 & -18 & 1 & -0.2252 & -0.09288 & 496 & 242 & 0.483168 & 571 & -5 & 1 & -0.05558 & -0.02310 & 571 & 273 & 0.473469 \\
 497 & -17 & 1 & -0.2124 & -0.08758 & 497 & 243 & 0.484189 & 572 & -4 & 1 & -0.04440 & -0.01845 & 572 & 272 & 0.47091 \\
 498 & -18 & 1 & -0.2245 & -0.09259 & 498 & 244 & 0.485205 & 573 & -3 & 1 & -0.03325 & -0.01382 & 573 & 273 & 0.471816 \\
 499 & -19 & 1 & -0.2366 & -0.09758 & 499 & 245 & 0.486217 & 574 & -4 & 1 & -0.04427 & -0.01840 & 574 & 274 & 0.472719 \\
 500 & -20 & 1 & -0.2486 & -0.1026 & 500 & 244 & 0.483264 & 575 & -5 & 1 & -0.05526 & -0.02297 & 575 & 273 & 0.470175 \\
 501 & -19 & 1 & -0.2358 & -0.09727 & 501 & 245 & 0.484276 & 576 & -4 & 1 & -0.04414 & -0.01835 & 576 & 274 & 0.471078 \\
 502 & -18 & 1 & -0.2230 & -0.09201 & 502 & 246 & 0.485284 & 577 & -5 & 1 & -0.05509 & -0.02291 & 577 & 275 & 0.471978 \\
 503 & -19 & 1 & -0.2350 & -0.09697 & 503 & 247 & 0.486288 & 578 & -6 & 1 & -0.06602 & -0.02745 & 578 & 274 & 0.469448 \\
 504 & -18 & 1 & -0.2222 & -0.09172 & 504 & 246 & 0.483358 & 579 & -5 & 1 & -0.05493 & -0.02285 & 579 & 275 & 0.470347 \\
 505 & -17 & 1 & -0.2095 & -0.08649 & 505 & 247 & 0.484362 & 580 & -4 & 1 & -0.04388 & -0.01825 & 580 & 274 & 0.467829 \\
 506 & -18 & 1 & -0.2215 & -0.09144 & 506 & 248 & 0.485362 & 581 & -3 & 1 & -0.03286 & -0.01367 & 581 & 275 & 0.468728 \\
 507 & -19 & 1 & -0.2334 & -0.09637 & 507 & 247 & 0.482451 & 582 & -4 & 1 & -0.04376 & -0.01820 & 582 & 276 & 0.469624 \\
 508 & -20 & 1 & -0.2453 & -0.1013 & 508 & 246 & 0.479552 & 583 & -3 & 1 & -0.03277 & -0.01363 & 583 & 277 & 0.470518 \\
 509 & -21 & 1 & -0.2571 & -0.1062 & 509 & 247 & 0.480556 & 584 & -2 & 1 & -0.02181 & -0.009077 & 584 & 278 & 0.471408 \\
 510 & -20 & 1 & -0.2445 & -0.1010 & 510 & 248 & 0.481555 & 585 & -1 & 1 & -0.01089 & -0.004532 & 585 & 277 & 0.468909 \\
 511 & -19 & 1 & -0.2319 & -0.09577 & 511 & 249 & 0.482551 & 586 & 0 & 0 & 0 & 0 & 586 & 278 & 0.469799 \\
 512 & -20 & 1 & -0.2437 & -0.1007 & 512 & 250 & 0.483543 & 587 & -1 & 1 & -0.01086 & -0.004520 & 587 & 279 & 0.470685 \\
 513 & -19 & 1 & -0.2311 & -0.09548 & 513 & 251 & 0.48453 & 588 & -2 & 1 & -0.02169 & -0.009028 & 588 & 280 & 0.471569 \\
 514 & -18 & 1 & -0.2186 & -0.09032 & 514 & 252 & 0.485514 & 589 & -1 & 1 & -0.01083 & -0.004508 & 589 & 281 & 0.47245 \\
 515 & -17 & 1 & -0.2061 & -0.08517 & 515 & 253 & 0.486494 & 590 & -2 & 1 & -0.02163 & -0.009004 & 590 & 282 & 0.473327 \\
 516 & -16 & 1 & -0.1937 & -0.08004 & 516 & 252 & 0.483632 & 591 & -1 & 1 & -0.01080 & -0.004496 & 591 & 283 & 0.474202 \\
 517 & -15 & 1 & -0.1813 & -0.07492 & 517 & 253 & 0.484612 & 592 & -2 & 1 & -0.02157 & -0.008980 & 592 & 282 & 0.471728 \\
 518 & -16 & 1 & -0.1930 & -0.07979 & 518 & 254 & 0.485589 & 593 & -3 & 1 & -0.03230 & -0.01345 & 593 & 283 & 0.472603 \\
 519 & -15 & 1 & -0.1807 & -0.07469 & 519 & 255 & 0.486561 & 594 & -4 & 1 & -0.04301 & -0.01791 & 594 & 284 & 0.473474 \\
 520 & -16 & 1 & -0.1924 & -0.07955 & 520 & 256 & 0.48753 & 595 & -5 & 1 & -0.05369 & -0.02236 & 595 & 285 & 0.474343 \\
 521 & -17 & 1 & -0.2041 & -0.08440 & 521 & 257 & 0.488495 & 596 & -6 & 1 & -0.06433 & -0.02680 & 596 & 284 & 0.471886 \\
 522 & -16 & 1 & -0.1918 & -0.07931 & 522 & 256 & 0.485662 & 597 & -5 & 1 & -0.05353 & -0.02230 & 597 & 285 & 0.472754 \\
 523 & -17 & 1 & -0.2035 & -0.08414 & 523 & 257 & 0.486627 & 598 & -6 & 1 & -0.06415 & -0.02673 & 598 & 286 & 0.473619 \\
 524 & -18 & 1 & -0.2151 & -0.08896 & 524 & 256 & 0.483808 & 599 & -7 & 1 & -0.07474 & -0.03114 & 599 & 287 & 0.474482 \\
\end{array} 
}
\end{equation*} 
\clearpage 

\end{table} 

\clearpage 

\newpage 
\begin{table}[ht]

\centering
\tiny
\begin{equation*}
\boxed{
\begin{array}{ccccc|ccc|ccccc|ccc}
x & L(x) & \frac{\operatorname{sgn}(L(x))}{(-1)^{\floor{\log\log x}}} & 
    \frac{L(x)}{L_{\approx,1}(x)} & \frac{L(x)}{L_{\approx,2}(x)} & 
    x & L_{\ast}(x) & \frac{L(x)}{L_{\approx}^{\ast}(x)} & 
x & L(x) & \frac{\operatorname{sgn}(L(x))}{(-1)^{\floor{\log\log x}}} & 
    \frac{L(x)}{L_{\approx,1}(x)} & \frac{L(x)}{L_{\approx,2}(x)} & 
    x & L_{\ast}(x) & \frac{L(x)}{L_{\approx}^{\ast}(x)} \\ \hline 
    600 & -6 & 1 & -0.06397 & -0.02666 & 600 & 286 & 0.472041 & 675 & -25 & 1 & -0.2413 & -0.1013 & 675 & 319 & 0.468006 \\
 601 & -7 & 1 & -0.07453 & -0.03106 & 601 & 287 & 0.472903 & 676 & -24 & 1 & -0.2313 & -0.09709 & 676 & 320 & 0.468779 \\
 602 & -8 & 1 & -0.08505 & -0.03545 & 602 & 288 & 0.473762 & 677 & -25 & 1 & -0.2407 & -0.1010 & 677 & 321 & 0.469549 \\
 603 & -9 & 1 & -0.09555 & -0.03983 & 603 & 287 & 0.471334 & 678 & -26 & 1 & -0.2500 & -0.1049 & 678 & 322 & 0.470317 \\
 604 & -10 & 1 & -0.1060 & -0.04420 & 604 & 286 & 0.468915 & 679 & -25 & 1 & -0.2401 & -0.1008 & 679 & 323 & 0.471083 \\
 605 & -11 & 1 & -0.1165 & -0.04855 & 605 & 285 & 0.466503 & 680 & -26 & 1 & -0.2494 & -0.1047 & 680 & 324 & 0.471846 \\
 606 & -12 & 1 & -0.1269 & -0.05290 & 606 & 286 & 0.467367 & 681 & -25 & 1 & -0.2395 & -0.1006 & 681 & 325 & 0.472608 \\
 607 & -13 & 1 & -0.1373 & -0.05723 & 607 & 287 & 0.468228 & 682 & -26 & 1 & -0.2488 & -0.1045 & 682 & 326 & 0.473367 \\
 608 & -12 & 1 & -0.1265 & -0.05276 & 608 & 288 & 0.469087 & 683 & -27 & 1 & -0.2580 & -0.1083 & 683 & 327 & 0.474124 \\
 609 & -13 & 1 & -0.1369 & -0.05709 & 609 & 289 & 0.469943 & 684 & -28 & 1 & -0.2672 & -0.1122 & 684 & 328 & 0.474878 \\
 610 & -14 & 1 & -0.1472 & -0.06140 & 610 & 290 & 0.470796 & 685 & -27 & 1 & -0.2574 & -0.1081 & 685 & 329 & 0.475631 \\
 611 & -13 & 1 & -0.1365 & -0.05694 & 611 & 291 & 0.471646 & 686 & -26 & 1 & -0.2475 & -0.1040 & 686 & 330 & 0.476381 \\
 612 & -14 & 1 & -0.1468 & -0.06124 & 612 & 292 & 0.472494 & 687 & -25 & 1 & -0.2377 & -0.09986 & 687 & 331 & 0.477129 \\
 613 & -15 & 1 & -0.1571 & -0.06553 & 613 & 293 & 0.473338 & 688 & -26 & 1 & -0.2469 & -0.1037 & 688 & 330 & 0.474996 \\
 614 & -14 & 1 & -0.1464 & -0.06108 & 614 & 294 & 0.47418 & 689 & -25 & 1 & -0.2371 & -0.09963 & 689 & 331 & 0.475744 \\
 615 & -15 & 1 & -0.1566 & -0.06536 & 615 & 295 & 0.47502 & 690 & -24 & 1 & -0.2274 & -0.09554 & 690 & 332 & 0.47649 \\
 616 & -16 & 1 & -0.1668 & -0.06963 & 616 & 296 & 0.475856 & 691 & -25 & 1 & -0.2365 & -0.09941 & 691 & 333 & 0.477233 \\
 617 & -17 & 1 & -0.1770 & -0.07389 & 617 & 297 & 0.47669 & 692 & -26 & 1 & -0.2457 & -0.1033 & 692 & 332 & 0.475113 \\
 618 & -18 & 1 & -0.1872 & -0.07814 & 618 & 298 & 0.477521 & 693 & -25 & 1 & -0.2360 & -0.09918 & 693 & 331 & 0.472998 \\
 619 & -19 & 1 & -0.1973 & -0.08237 & 619 & 299 & 0.478349 & 694 & -24 & 1 & -0.2263 & -0.09511 & 694 & 332 & 0.473743 \\
 620 & -18 & 1 & -0.1867 & -0.07794 & 620 & 298 & 0.475981 & 695 & -23 & 1 & -0.2166 & -0.09104 & 695 & 333 & 0.474487 \\
 621 & -17 & 1 & -0.1761 & -0.07351 & 621 & 299 & 0.476809 & 696 & -24 & 1 & -0.2257 & -0.09489 & 696 & 334 & 0.475228 \\
 622 & -16 & 1 & -0.1655 & -0.06910 & 622 & 300 & 0.477634 & 697 & -23 & 1 & -0.2160 & -0.09083 & 697 & 335 & 0.475967 \\
 623 & -15 & 1 & -0.1549 & -0.06470 & 623 & 301 & 0.478457 & 698 & -22 & 1 & -0.2064 & -0.08679 & 698 & 336 & 0.476704 \\
 624 & -14 & 1 & -0.1444 & -0.06031 & 624 & 300 & 0.476103 & 699 & -21 & 1 & -0.1968 & -0.08275 & 699 & 337 & 0.477438 \\
 625 & -13 & 1 & -0.1339 & -0.05593 & 625 & 299 & 0.473757 & 700 & -22 & 1 & -0.2059 & -0.08659 & 700 & 338 & 0.478171 \\
 626 & -12 & 1 & -0.1234 & -0.05157 & 626 & 300 & 0.474582 & 701 & -23 & 1 & -0.2150 & -0.09043 & 701 & 339 & 0.478902 \\
 627 & -13 & 1 & -0.1335 & -0.05579 & 627 & 301 & 0.475405 & 702 & -24 & 1 & -0.2241 & -0.09425 & 702 & 340 & 0.47963 \\
 628 & -14 & 1 & -0.1436 & -0.06001 & 628 & 300 & 0.473071 & 703 & -23 & 1 & -0.2145 & -0.09022 & 703 & 341 & 0.480357 \\
 629 & -13 & 1 & -0.1332 & -0.05565 & 629 & 301 & 0.473893 & 704 & -24 & 1 & -0.2235 & -0.09404 & 704 & 340 & 0.478268 \\
 630 & -14 & 1 & -0.1432 & -0.05986 & 630 & 300 & 0.471569 & 705 & -25 & 1 & -0.2326 & -0.09785 & 705 & 341 & 0.478994 \\
 631 & -15 & 1 & -0.1533 & -0.06406 & 631 & 301 & 0.472391 & 706 & -24 & 1 & -0.2230 & -0.09383 & 706 & 342 & 0.479718 \\
 632 & -14 & 1 & -0.1429 & -0.05971 & 632 & 302 & 0.473211 & 707 & -23 & 1 & -0.2134 & -0.08982 & 707 & 343 & 0.48044 \\
 633 & -13 & 1 & -0.1325 & -0.05538 & 633 & 303 & 0.474028 & 708 & -22 & 1 & -0.2039 & -0.08582 & 708 & 342 & 0.478363 \\
 634 & -12 & 1 & -0.1221 & -0.05105 & 634 & 304 & 0.474842 & 709 & -23 & 1 & -0.2129 & -0.08962 & 709 & 343 & 0.479085 \\
 635 & -11 & 1 & -0.1118 & -0.04674 & 635 & 305 & 0.475654 & 710 & -24 & 1 & -0.2219 & -0.09342 & 710 & 344 & 0.479805 \\
 636 & -10 & 1 & -0.1015 & -0.04244 & 636 & 304 & 0.473349 & 711 & -25 & 1 & -0.2309 & -0.09720 & 711 & 343 & 0.477737 \\
 637 & -11 & 1 & -0.1115 & -0.04663 & 637 & 303 & 0.471051 & 712 & -24 & 1 & -0.2214 & -0.09321 & 712 & 344 & 0.478457 \\
 638 & -12 & 1 & -0.1215 & -0.05080 & 638 & 304 & 0.471865 & 713 & -23 & 1 & -0.2119 & -0.08923 & 713 & 345 & 0.479175 \\
 639 & -13 & 1 & -0.1314 & -0.05497 & 639 & 303 & 0.469577 & 714 & -22 & 1 & -0.2025 & -0.08526 & 714 & 346 & 0.479891 \\
 640 & -12 & 1 & -0.1212 & -0.05068 & 640 & 304 & 0.47039 & 715 & -23 & 1 & -0.2114 & -0.08903 & 715 & 347 & 0.480605 \\
 641 & -13 & 1 & -0.1311 & -0.05483 & 641 & 305 & 0.471201 & 716 & -24 & 1 & -0.2203 & -0.09280 & 716 & 346 & 0.47855 \\
 642 & -14 & 1 & -0.1410 & -0.05898 & 642 & 306 & 0.47201 & 717 & -23 & 1 & -0.2109 & -0.08884 & 717 & 347 & 0.479264 \\
 643 & -15 & 1 & -0.1508 & -0.06312 & 643 & 307 & 0.472816 & 718 & -22 & 1 & -0.2015 & -0.08488 & 718 & 348 & 0.479976 \\
 644 & -14 & 1 & -0.1406 & -0.05884 & 644 & 306 & 0.470544 & 719 & -23 & 1 & -0.2104 & -0.08864 & 719 & 349 & 0.480686 \\
 645 & -15 & 1 & -0.1504 & -0.06296 & 645 & 307 & 0.47135 & 720 & -24 & 1 & -0.2193 & -0.09240 & 720 & 350 & 0.481393 \\
 646 & -16 & 1 & -0.1603 & -0.06708 & 646 & 308 & 0.472153 & 721 & -23 & 1 & -0.2099 & -0.08845 & 721 & 351 & 0.482099 \\
 647 & -17 & 1 & -0.1701 & -0.07118 & 647 & 309 & 0.472954 & 722 & -24 & 1 & -0.2188 & -0.09220 & 722 & 350 & 0.48006 \\
 648 & -18 & 1 & -0.1798 & -0.07528 & 648 & 308 & 0.470696 & 723 & -23 & 1 & -0.2094 & -0.08826 & 723 & 351 & 0.480766 \\
 649 & -17 & 1 & -0.1696 & -0.07101 & 649 & 309 & 0.471496 & 724 & -24 & 1 & -0.2183 & -0.09200 & 724 & 350 & 0.478734 \\
 650 & -16 & 1 & -0.1594 & -0.06675 & 650 & 308 & 0.469248 & 725 & -25 & 1 & -0.2271 & -0.09572 & 725 & 349 & 0.476708 \\
 651 & -17 & 1 & -0.1692 & -0.07084 & 651 & 309 & 0.470048 & 726 & -24 & 1 & -0.2178 & -0.09180 & 726 & 348 & 0.474687 \\
 652 & -18 & 1 & -0.1789 & -0.07492 & 652 & 308 & 0.467808 & 727 & -25 & 1 & -0.2266 & -0.09552 & 727 & 349 & 0.475396 \\
 653 & -19 & 1 & -0.1886 & -0.07898 & 653 & 309 & 0.468608 & 728 & -26 & 1 & -0.2354 & -0.09923 & 728 & 350 & 0.476103 \\
 654 & -20 & 1 & -0.1983 & -0.08304 & 654 & 310 & 0.469406 & 729 & -25 & 1 & -0.2261 & -0.09531 & 729 & 349 & 0.474092 \\
 655 & -19 & 1 & -0.1881 & -0.07879 & 655 & 311 & 0.470201 & 730 & -26 & 1 & -0.2348 & -0.09902 & 730 & 350 & 0.474799 \\
 656 & -20 & 1 & -0.1977 & -0.08284 & 656 & 310 & 0.467975 & 731 & -25 & 1 & -0.2255 & -0.09511 & 731 & 351 & 0.475504 \\
 657 & -21 & 1 & -0.2074 & -0.08688 & 657 & 309 & 0.465755 & 732 & -24 & 1 & -0.2163 & -0.09120 & 732 & 350 & 0.473502 \\
 658 & -22 & 1 & -0.2170 & -0.09091 & 658 & 310 & 0.466552 & 733 & -25 & 1 & -0.2250 & -0.09490 & 733 & 351 & 0.474207 \\
 659 & -23 & 1 & -0.2265 & -0.09493 & 659 & 311 & 0.467347 & 734 & -24 & 1 & -0.2158 & -0.09101 & 734 & 352 & 0.47491 \\
 660 & -24 & 1 & -0.2361 & -0.09893 & 660 & 310 & 0.465139 & 735 & -23 & 1 & -0.2065 & -0.08712 & 735 & 351 & 0.472916 \\
 661 & -25 & 1 & -0.2456 & -0.1029 & 661 & 311 & 0.465933 & 736 & -22 & 1 & -0.1973 & -0.08325 & 736 & 352 & 0.473619 \\
 662 & -24 & 1 & -0.2355 & -0.09870 & 662 & 312 & 0.466725 & 737 & -21 & 1 & -0.1881 & -0.07938 & 737 & 353 & 0.47432 \\
 663 & -25 & 1 & -0.2450 & -0.1027 & 663 & 313 & 0.467515 & 738 & -20 & 1 & -0.1790 & -0.07552 & 738 & 352 & 0.472336 \\
 664 & -24 & 1 & -0.2349 & -0.09847 & 664 & 314 & 0.468302 & 739 & -21 & 1 & -0.1877 & -0.07921 & 739 & 353 & 0.473037 \\
 665 & -25 & 1 & -0.2444 & -0.1024 & 665 & 315 & 0.469087 & 740 & -20 & 1 & -0.1786 & -0.07536 & 740 & 352 & 0.471059 \\
 666 & -24 & 1 & -0.2343 & -0.09823 & 666 & 314 & 0.466896 & 741 & -21 & 1 & -0.1873 & -0.07904 & 741 & 353 & 0.47176 \\
 667 & -23 & 1 & -0.2242 & -0.09403 & 667 & 315 & 0.467681 & 742 & -22 & 1 & -0.1960 & -0.08272 & 742 & 354 & 0.472459 \\
 668 & -24 & 1 & -0.2337 & -0.09800 & 668 & 314 & 0.465498 & 743 & -23 & 1 & -0.2046 & -0.08639 & 743 & 355 & 0.473156 \\
 669 & -23 & 1 & -0.2237 & -0.09381 & 669 & 315 & 0.466282 & 744 & -24 & 1 & -0.2133 & -0.09005 & 744 & 356 & 0.473851 \\
 670 & -24 & 1 & -0.2331 & -0.09777 & 670 & 316 & 0.467065 & 745 & -23 & 1 & -0.2042 & -0.08620 & 745 & 357 & 0.474544 \\
 671 & -23 & 1 & -0.2231 & -0.09359 & 671 & 317 & 0.467844 & 746 & -22 & 1 & -0.1951 & -0.08237 & 746 & 358 & 0.475235 \\
 672 & -24 & 1 & -0.2325 & -0.09754 & 672 & 318 & 0.468622 & 747 & -23 & 1 & -0.2037 & -0.08602 & 747 & 357 & 0.473274 \\
 673 & -25 & 1 & -0.2419 & -0.1015 & 673 & 319 & 0.469397 & 748 & -22 & 1 & -0.1946 & -0.08220 & 748 & 356 & 0.471317 \\
 674 & -24 & 1 & -0.2319 & -0.09732 & 674 & 320 & 0.47017 & 749 & -21 & 1 & -0.1856 & -0.07838 & 749 & 357 & 0.47201 \\
\end{array} 
}
\end{equation*} 
\clearpage 

\end{table} 

\clearpage 


\newpage 
\begin{table}[ht]

\centering
\tiny
\begin{equation*}
\boxed{
\begin{array}{ccccc|ccc|ccccc|ccc}
x & L(x) & \frac{\operatorname{sgn}(L(x))}{(-1)^{\floor{\log\log x}}} & 
    \frac{L(x)}{L_{\approx,1}(x)} & \frac{L(x)}{L_{\approx,2}(x)} & 
    x & L_{\ast}(x) & \frac{L(x)}{L_{\approx}^{\ast}(x)} & 
x & L(x) & \frac{\operatorname{sgn}(L(x))}{(-1)^{\floor{\log\log x}}} & 
    \frac{L(x)}{L_{\approx,1}(x)} & \frac{L(x)}{L_{\approx,2}(x)} & 
    x & L_{\ast}(x) & \frac{L(x)}{L_{\approx}^{\ast}(x)} \\ \hline 
     750 & -22 & 1 & -0.1942 & -0.08202 & 750 & 358 & 0.472701 & 825 & -15 & 1 & -0.1221 & -0.05189 & 825 & 391 & 0.46934 \\
 751 & -23 & 1 & -0.2028 & -0.08566 & 751 & 359 & 0.47339 & 826 & -16 & 1 & -0.1301 & -0.05530 & 826 & 392 & 0.469971 \\
 752 & -24 & 1 & -0.2114 & -0.08929 & 752 & 358 & 0.471444 & 827 & -17 & 1 & -0.1381 & -0.05870 & 827 & 393 & 0.4706 \\
 753 & -23 & 1 & -0.2023 & -0.08548 & 753 & 359 & 0.472133 & 828 & -18 & 1 & -0.1461 & -0.06209 & 828 & 394 & 0.471227 \\
 754 & -24 & 1 & -0.2109 & -0.08911 & 754 & 360 & 0.47282 & 829 & -19 & 1 & -0.1540 & -0.06548 & 829 & 395 & 0.471854 \\
 755 & -23 & 1 & -0.2019 & -0.08531 & 755 & 361 & 0.473505 & 830 & -20 & 1 & -0.1620 & -0.06886 & 830 & 396 & 0.472478 \\
 756 & -22 & 1 & -0.1929 & -0.08151 & 756 & 360 & 0.471569 & 831 & -19 & 1 & -0.1537 & -0.06536 & 831 & 397 & 0.473101 \\
 757 & -23 & 1 & -0.2014 & -0.08513 & 757 & 361 & 0.472254 & 832 & -20 & 1 & -0.1616 & -0.06873 & 832 & 396 & 0.471342 \\
 758 & -22 & 1 & -0.1924 & -0.08134 & 758 & 362 & 0.472938 & 833 & -21 & 1 & -0.1695 & -0.07210 & 833 & 395 & 0.469588 \\
 759 & -23 & 1 & -0.2010 & -0.08495 & 759 & 363 & 0.473619 & 834 & -22 & 1 & -0.1774 & -0.07546 & 834 & 396 & 0.470212 \\
 760 & -24 & 1 & -0.2095 & -0.08855 & 760 & 364 & 0.474299 & 835 & -21 & 1 & -0.1692 & -0.07196 & 835 & 397 & 0.470835 \\
 761 & -25 & 1 & -0.2180 & -0.09215 & 761 & 365 & 0.474977 & 836 & -20 & 1 & -0.1610 & -0.06847 & 836 & 396 & 0.469087 \\
 762 & -26 & 1 & -0.2264 & -0.09574 & 762 & 366 & 0.475654 & 837 & -19 & 1 & -0.1528 & -0.06499 & 837 & 397 & 0.46971 \\
 763 & -25 & 1 & -0.2175 & -0.09196 & 763 & 367 & 0.476328 & 838 & -18 & 1 & -0.1446 & -0.06151 & 838 & 398 & 0.470331 \\
 764 & -26 & 1 & -0.2259 & -0.09554 & 764 & 366 & 0.474408 & 839 & -19 & 1 & -0.1525 & -0.06487 & 839 & 399 & 0.470951 \\
 765 & -25 & 1 & -0.2170 & -0.09177 & 765 & 365 & 0.472494 & 840 & -18 & 1 & -0.1443 & -0.06139 & 840 & 400 & 0.471569 \\
 766 & -24 & 1 & -0.2081 & -0.08801 & 766 & 366 & 0.47317 & 841 & -17 & 1 & -0.1361 & -0.05793 & 841 & 399 & 0.469831 \\
 767 & -23 & 1 & -0.1992 & -0.08426 & 767 & 367 & 0.473844 & 842 & -16 & 1 & -0.1280 & -0.05447 & 842 & 400 & 0.470449 \\
 768 & -24 & 1 & -0.2076 & -0.08783 & 768 & 366 & 0.471938 & 843 & -15 & 1 & -0.1199 & -0.05102 & 843 & 401 & 0.471066 \\
 769 & -25 & 1 & -0.2160 & -0.09139 & 769 & 367 & 0.472612 & 844 & -16 & 1 & -0.1277 & -0.05437 & 844 & 400 & 0.469334 \\
 770 & -24 & 1 & -0.2072 & -0.08765 & 770 & 368 & 0.473284 & 845 & -17 & 1 & -0.1356 & -0.05771 & 845 & 399 & 0.467607 \\
 771 & -23 & 1 & -0.1983 & -0.08391 & 771 & 369 & 0.473954 & 846 & -16 & 1 & -0.1275 & -0.05427 & 846 & 398 & 0.465884 \\
 772 & -24 & 1 & -0.2067 & -0.08747 & 772 & 368 & 0.472058 & 847 & -17 & 1 & -0.1353 & -0.05761 & 847 & 397 & 0.464164 \\
 773 & -25 & 1 & -0.2151 & -0.09102 & 773 & 369 & 0.472728 & 848 & -18 & 1 & -0.1431 & -0.06094 & 848 & 396 & 0.462449 \\
 774 & -24 & 1 & -0.2063 & -0.08729 & 774 & 368 & 0.470838 & 849 & -17 & 1 & -0.1350 & -0.05750 & 849 & 397 & 0.463071 \\
 775 & -25 & 1 & -0.2146 & -0.09084 & 775 & 367 & 0.468953 & 850 & -16 & 1 & -0.1270 & -0.05407 & 850 & 396 & 0.461361 \\
 776 & -24 & 1 & -0.2058 & -0.08712 & 776 & 368 & 0.469624 & 851 & -15 & 1 & -0.1189 & -0.05064 & 851 & 397 & 0.461983 \\
 777 & -25 & 1 & -0.2141 & -0.09065 & 777 & 369 & 0.470295 & 852 & -14 & 1 & -0.1109 & -0.04722 & 852 & 396 & 0.460278 \\
 778 & -24 & 1 & -0.2053 & -0.08694 & 778 & 370 & 0.470963 & 853 & -15 & 1 & -0.1187 & -0.05055 & 853 & 397 & 0.460899 \\
 779 & -23 & 1 & -0.1966 & -0.08323 & 779 & 371 & 0.47163 & 854 & -16 & 1 & -0.1265 & -0.05387 & 854 & 398 & 0.461519 \\
 780 & -24 & 1 & -0.2049 & -0.08677 & 780 & 370 & 0.469755 & 855 & -15 & 1 & -0.1184 & -0.05046 & 855 & 397 & 0.459821 \\
 781 & -23 & 1 & -0.1962 & -0.08307 & 781 & 371 & 0.470422 & 856 & -14 & 1 & -0.1104 & -0.04705 & 856 & 398 & 0.460441 \\
 782 & -24 & 1 & -0.2045 & -0.08659 & 782 & 372 & 0.471087 & 857 & -15 & 1 & -0.1182 & -0.05036 & 857 & 399 & 0.461059 \\
 783 & -23 & 1 & -0.1957 & -0.08290 & 783 & 373 & 0.47175 & 858 & -14 & 1 & -0.1102 & -0.04696 & 858 & 400 & 0.461676 \\
 784 & -22 & 1 & -0.1870 & -0.07922 & 784 & 374 & 0.472411 & 859 & -15 & 1 & -0.1180 & -0.05027 & 859 & 401 & 0.462291 \\
 785 & -21 & 1 & -0.1783 & -0.07554 & 785 & 375 & 0.473071 & 860 & -14 & 1 & -0.1100 & -0.04688 & 860 & 400 & 0.460602 \\
 786 & -22 & 1 & -0.1866 & -0.07906 & 786 & 376 & 0.473729 & 861 & -15 & 1 & -0.1177 & -0.05018 & 861 & 401 & 0.461218 \\
 787 & -23 & 1 & -0.1949 & -0.08257 & 787 & 377 & 0.474385 & 862 & -14 & 1 & -0.1098 & -0.04679 & 862 & 402 & 0.461831 \\
 788 & -24 & 1 & -0.2031 & -0.08607 & 788 & 376 & 0.472527 & 863 & -15 & 1 & -0.1175 & -0.05009 & 863 & 403 & 0.462444 \\
 789 & -23 & 1 & -0.1945 & -0.08240 & 789 & 377 & 0.473183 & 864 & -14 & 1 & -0.1096 & -0.04671 & 864 & 404 & 0.463055 \\
 790 & -24 & 1 & -0.2027 & -0.08590 & 790 & 378 & 0.473837 & 865 & -13 & 1 & -0.1016 & -0.04333 & 865 & 405 & 0.463664 \\
 791 & -23 & 1 & -0.1940 & -0.08224 & 791 & 379 & 0.47449 & 866 & -12 & 1 & -0.09373 & -0.03996 & 866 & 406 & 0.464272 \\
 792 & -22 & 1 & -0.1854 & -0.07859 & 792 & 378 & 0.472641 & 867 & -13 & 1 & -0.1014 & -0.04325 & 867 & 405 & 0.462595 \\
 793 & -21 & 1 & -0.1768 & -0.07494 & 793 & 379 & 0.473294 & 868 & -12 & 1 & -0.09354 & -0.03989 & 868 & 404 & 0.460921 \\
 794 & -20 & 1 & -0.1682 & -0.07130 & 794 & 380 & 0.473945 & 869 & -11 & 1 & -0.08566 & -0.03653 & 869 & 405 & 0.46153 \\
 795 & -21 & 1 & -0.1764 & -0.07479 & 795 & 381 & 0.474594 & 870 & -10 & 1 & -0.07780 & -0.03318 & 870 & 406 & 0.462138 \\
 796 & -22 & 1 & -0.1846 & -0.07828 & 796 & 380 & 0.472754 & 871 & -9 & 1 & -0.06995 & -0.02984 & 871 & 407 & 0.462744 \\
 797 & -23 & 1 & -0.1928 & -0.08175 & 797 & 381 & 0.473403 & 872 & -8 & 1 & -0.06212 & -0.02650 & 872 & 408 & 0.463349 \\
 798 & -22 & 1 & -0.1842 & -0.07812 & 798 & 382 & 0.474051 & 873 & -9 & 1 & -0.06981 & -0.02978 & 873 & 407 & 0.461684 \\
 799 & -21 & 1 & -0.1757 & -0.07450 & 799 & 383 & 0.474697 & 874 & -10 & 1 & -0.07750 & -0.03306 & 874 & 408 & 0.462289 \\
 800 & -22 & 1 & -0.1838 & -0.07797 & 800 & 382 & 0.472866 & 875 & -9 & 1 & -0.06968 & -0.02973 & 875 & 409 & 0.462892 \\
 801 & -23 & 1 & -0.1920 & -0.08143 & 801 & 381 & 0.471039 & 876 & -8 & 1 & -0.06188 & -0.02640 & 876 & 408 & 0.461233 \\
 802 & -22 & 1 & -0.1834 & -0.07782 & 802 & 382 & 0.471687 & 877 & -9 & 1 & -0.06954 & -0.02968 & 877 & 409 & 0.461837 \\
 803 & -21 & 1 & -0.1749 & -0.07421 & 803 & 383 & 0.472333 & 878 & -8 & 1 & -0.06176 & -0.02635 & 878 & 410 & 0.462438 \\
 804 & -20 & 1 & -0.1664 & -0.07060 & 804 & 382 & 0.470513 & 879 & -7 & 1 & -0.05398 & -0.02304 & 879 & 411 & 0.463039 \\
 805 & -21 & 1 & -0.1745 & -0.07406 & 805 & 383 & 0.471159 & 880 & -6 & 1 & -0.04623 & -0.01973 & 880 & 410 & 0.461387 \\
 806 & -22 & 1 & -0.1827 & -0.07751 & 806 & 384 & 0.471803 & 881 & -7 & 1 & -0.05388 & -0.02300 & 881 & 411 & 0.461988 \\
 807 & -21 & 1 & -0.1742 & -0.07392 & 807 & 385 & 0.472446 & 882 & -8 & 1 & -0.06152 & -0.02626 & 882 & 412 & 0.462587 \\
 808 & -20 & 1 & -0.1657 & -0.07033 & 808 & 386 & 0.473087 & 883 & -9 & 1 & -0.06914 & -0.02952 & 883 & 413 & 0.463184 \\
 809 & -21 & 1 & -0.1738 & -0.07377 & 809 & 387 & 0.473726 & 884 & -8 & 1 & -0.06140 & -0.02621 & 884 & 412 & 0.46154 \\
 810 & -20 & 1 & -0.1654 & -0.07019 & 810 & 386 & 0.471918 & 885 & -9 & 1 & -0.06901 & -0.02946 & 885 & 413 & 0.462138 \\
 811 & -21 & 1 & -0.1734 & -0.07363 & 811 & 387 & 0.472558 & 886 & -8 & 1 & -0.06128 & -0.02617 & 886 & 414 & 0.462734 \\
 812 & -20 & 1 & -0.1650 & -0.07006 & 812 & 386 & 0.470756 & 887 & -9 & 1 & -0.06887 & -0.02941 & 887 & 415 & 0.463329 \\
 813 & -19 & 1 & -0.1566 & -0.06649 & 813 & 387 & 0.471395 & 888 & -10 & 1 & -0.07645 & -0.03265 & 888 & 416 & 0.463922 \\
 814 & -20 & 1 & -0.1647 & -0.06992 & 814 & 388 & 0.472033 & 889 & -9 & 1 & -0.06874 & -0.02936 & 889 & 417 & 0.464514 \\
 815 & -19 & 1 & -0.1563 & -0.06636 & 815 & 389 & 0.472668 & 890 & -10 & 1 & -0.07631 & -0.03259 & 890 & 418 & 0.465105 \\
 816 & -18 & 1 & -0.1479 & -0.06281 & 816 & 388 & 0.470876 & 891 & -11 & 1 & -0.08386 & -0.03582 & 891 & 417 & 0.463471 \\
 817 & -17 & 1 & -0.1395 & -0.05926 & 817 & 389 & 0.471511 & 892 & -12 & 1 & -0.09139 & -0.03904 & 892 & 416 & 0.461842 \\
 818 & -16 & 1 & -0.1312 & -0.05572 & 818 & 390 & 0.472146 & 893 & -11 & 1 & -0.08370 & -0.03576 & 893 & 417 & 0.462433 \\
 819 & -15 & 1 & -0.1229 & -0.05219 & 819 & 389 & 0.47036 & 894 & -12 & 1 & -0.09122 & -0.03898 & 894 & 418 & 0.463024 \\
 820 & -14 & 1 & -0.1145 & -0.04866 & 820 & 388 & 0.468579 & 895 & -11 & 1 & -0.08354 & -0.03570 & 895 & 419 & 0.463613 \\
 821 & -15 & 1 & -0.1226 & -0.05209 & 821 & 389 & 0.469214 & 896 & -10 & 1 & -0.07587 & -0.03242 & 896 & 420 & 0.464201 \\
 822 & -16 & 1 & -0.1306 & -0.05551 & 822 & 390 & 0.469848 & 897 & -11 & 1 & -0.08338 & -0.03563 & 897 & 421 & 0.464787 \\
 823 & -17 & 1 & -0.1387 & -0.05892 & 823 & 391 & 0.47048 & 898 & -10 & 1 & -0.07573 & -0.03237 & 898 & 422 & 0.465373 \\
 824 & -16 & 1 & -0.1304 & -0.05540 & 824 & 392 & 0.471111 & 899 & -9 & 1 & -0.06809 & -0.02910 & 899 & 423 & 0.465956 \\
\end{array} 
}
\end{equation*} 
\clearpage 

\end{table} 

\clearpage 


\newpage 
\begin{table}[ht]

\centering
\tiny
\begin{equation*}
\boxed{
\begin{array}{ccccc|ccc|ccccc|ccc}
x & L(x) & \frac{\operatorname{sgn}(L(x))}{(-1)^{\floor{\log\log x}}} & 
    \frac{L(x)}{L_{\approx,1}(x)} & \frac{L(x)}{L_{\approx,2}(x)} & 
    x & L_{\ast}(x) & \frac{L(x)}{L_{\approx}^{\ast}(x)} & 
x & L(x) & \frac{\operatorname{sgn}(L(x))}{(-1)^{\floor{\log\log x}}} & 
    \frac{L(x)}{L_{\approx,1}(x)} & \frac{L(x)}{L_{\approx,2}(x)} & 
    x & L_{\ast}(x) & \frac{L(x)}{L_{\approx}^{\ast}(x)} \\ \hline 
 900 & -8 & 1 & -0.06047 & -0.02585 & 900 & 422 & 0.464338 & 975 & -13 & 1 & -0.09177 & -0.03944 & 975 & 451 & 0.458075 \\
 901 & -7 & 1 & -0.05286 & -0.02260 & 901 & 423 & 0.464922 & 976 & -14 & 1 & -0.09874 & -0.04244 & 976 & 450 & 0.456591 \\
 902 & -8 & 1 & -0.06035 & -0.02580 & 902 & 424 & 0.465505 & 977 & -15 & 1 & -0.1057 & -0.04544 & 977 & 451 & 0.457137 \\
 903 & -9 & 1 & -0.06783 & -0.02900 & 903 & 425 & 0.466086 & 978 & -16 & 1 & -0.1126 & -0.04843 & 978 & 452 & 0.457682 \\
 904 & -8 & 1 & -0.06024 & -0.02576 & 904 & 426 & 0.466666 & 979 & -15 & 1 & -0.1055 & -0.04537 & 979 & 453 & 0.458226 \\
 905 & -7 & 1 & -0.05266 & -0.02252 & 905 & 427 & 0.467244 & 980 & -16 & 1 & -0.1124 & -0.04835 & 980 & 454 & 0.458769 \\
 906 & -8 & 1 & -0.06012 & -0.02571 & 906 & 428 & 0.467822 & 981 & -17 & 1 & -0.1194 & -0.05133 & 981 & 453 & 0.457292 \\
 907 & -9 & 1 & -0.06758 & -0.02890 & 907 & 429 & 0.468398 & 982 & -16 & 1 & -0.1123 & -0.04827 & 982 & 454 & 0.457835 \\
 908 & -10 & 1 & -0.07501 & -0.03209 & 908 & 428 & 0.466791 & 983 & -17 & 1 & -0.1192 & -0.05125 & 983 & 455 & 0.458377 \\
 909 & -11 & 1 & -0.08244 & -0.03526 & 909 & 427 & 0.465188 & 984 & -18 & 1 & -0.1261 & -0.05422 & 984 & 456 & 0.458917 \\
 910 & -10 & 1 & -0.07487 & -0.03203 & 910 & 428 & 0.465765 & 985 & -17 & 1 & -0.1190 & -0.05117 & 985 & 457 & 0.459457 \\
 911 & -11 & 1 & -0.08228 & -0.03520 & 911 & 429 & 0.466341 & 986 & -18 & 1 & -0.1258 & -0.05414 & 986 & 458 & 0.459995 \\
 912 & -10 & 1 & -0.07473 & -0.03198 & 912 & 428 & 0.464744 & 987 & -19 & 1 & -0.1327 & -0.05710 & 987 & 459 & 0.460532 \\
 913 & -9 & 1 & -0.06720 & -0.02875 & 913 & 429 & 0.465319 & 988 & -18 & 1 & -0.1256 & -0.05405 & 988 & 458 & 0.459064 \\
 914 & -8 & 1 & -0.05967 & -0.02554 & 914 & 430 & 0.465894 & 989 & -17 & 1 & -0.1185 & -0.05101 & 989 & 459 & 0.459601 \\
 915 & -9 & 1 & -0.06707 & -0.02870 & 915 & 431 & 0.466467 & 990 & -18 & 1 & -0.1254 & -0.05396 & 990 & 458 & 0.458137 \\
 916 & -10 & 1 & -0.07445 & -0.03187 & 916 & 430 & 0.464877 & 991 & -19 & 1 & -0.1323 & -0.05692 & 991 & 459 & 0.458674 \\
 917 & -9 & 1 & -0.06695 & -0.02865 & 917 & 431 & 0.46545 & 992 & -18 & 1 & -0.1252 & -0.05388 & 992 & 460 & 0.459209 \\
 918 & -10 & 1 & -0.07432 & -0.03181 & 918 & 432 & 0.466021 & 993 & -17 & 1 & -0.1181 & -0.05085 & 993 & 461 & 0.459744 \\
 919 & -11 & 1 & -0.08167 & -0.03496 & 919 & 433 & 0.466592 & 994 & -18 & 1 & -0.1250 & -0.05379 & 994 & 462 & 0.460278 \\
 920 & -12 & 1 & -0.08901 & -0.03811 & 920 & 434 & 0.467161 & 995 & -17 & 1 & -0.1179 & -0.05077 & 995 & 463 & 0.460811 \\
 921 & -11 & 1 & -0.08152 & -0.03490 & 921 & 435 & 0.467729 & 996 & -16 & 1 & -0.1109 & -0.04774 & 996 & 462 & 0.459354 \\
 922 & -10 & 1 & -0.07404 & -0.03170 & 922 & 436 & 0.468296 & 997 & -17 & 1 & -0.1177 & -0.05069 & 997 & 463 & 0.459886 \\
 923 & -9 & 1 & -0.06657 & -0.02851 & 923 & 437 & 0.468861 & 998 & -16 & 1 & -0.1107 & -0.04767 & 998 & 464 & 0.460418 \\
 924 & -10 & 1 & -0.07390 & -0.03165 & 924 & 436 & 0.467282 & 999 & -15 & 1 & -0.1037 & -0.04465 & 999 & 465 & 0.460948 \\
 925 & -11 & 1 & -0.08122 & -0.03478 & 925 & 435 & 0.465706 & 1000 & -14 & 1 & -0.09671 & -0.04164 & 1000 & 466 & 0.461478 \\
 926 & -10 & 1 & -0.07377 & -0.03160 & 926 & 436 & 0.466273 & 1001 & -15 & 1 & -0.1035 & -0.04458 & 1001 & 467 & 0.462006 \\
 927 & -11 & 1 & -0.08107 & -0.03473 & 927 & 435 & 0.464702 & 1002 & -16 & 1 & -0.1103 & -0.04752 & 1002 & 468 & 0.462533 \\
 928 & -10 & 1 & -0.07363 & -0.03154 & 928 & 436 & 0.465268 & 1003 & -15 & 1 & -0.1034 & -0.04451 & 1003 & 469 & 0.463059 \\
 929 & -11 & 1 & -0.08092 & -0.03467 & 929 & 437 & 0.465833 & 1004 & -16 & 1 & -0.1101 & -0.04744 & 1004 & 468 & 0.461612 \\
 930 & -10 & 1 & -0.07350 & -0.03149 & 930 & 438 & 0.466397 & 1005 & -17 & 1 & -0.1169 & -0.05037 & 1005 & 469 & 0.462138 \\
 931 & -11 & 1 & -0.08077 & -0.03461 & 931 & 437 & 0.464832 & 1006 & -16 & 1 & -0.1100 & -0.04737 & 1006 & 470 & 0.462663 \\
 932 & -12 & 1 & -0.08803 & -0.03772 & 932 & 436 & 0.463271 & 1007 & -15 & 1 & -0.1030 & -0.04437 & 1007 & 471 & 0.463187 \\
 933 & -11 & 1 & -0.08062 & -0.03455 & 933 & 437 & 0.463836 & 1008 & -16 & 1 & -0.1098 & -0.04729 & 1008 & 472 & 0.46371 \\
 934 & -10 & 1 & -0.07323 & -0.03138 & 934 & 438 & 0.4644 & 1009 & -17 & 1 & -0.1165 & -0.05021 & 1009 & 473 & 0.464232 \\
 935 & -11 & 1 & -0.08048 & -0.03449 & 935 & 439 & 0.464962 & 1010 & -18 & 1 & -0.1233 & -0.05312 & 1010 & 474 & 0.464752 \\
 936 & -10 & 1 & -0.07309 & -0.03133 & 936 & 438 & 0.463407 & 1011 & -17 & 1 & -0.1163 & -0.05013 & 1011 & 475 & 0.465272 \\
 937 & -11 & 1 & -0.08033 & -0.03443 & 937 & 439 & 0.46397 & 1012 & -16 & 1 & -0.1094 & -0.04715 & 1012 & 474 & 0.463834 \\
 938 & -12 & 1 & -0.08755 & -0.03753 & 938 & 440 & 0.464531 & 1013 & -17 & 1 & -0.1161 & -0.05006 & 1013 & 475 & 0.464354 \\
 939 & -11 & 1 & -0.08018 & -0.03438 & 939 & 441 & 0.465091 & 1014 & -16 & 1 & -0.1092 & -0.04707 & 1014 & 474 & 0.462919 \\
 940 & -10 & 1 & -0.07283 & -0.03122 & 940 & 440 & 0.463542 & 1015 & -17 & 1 & -0.1159 & -0.04998 & 1015 & 475 & 0.463439 \\
 941 & -11 & 1 & -0.08004 & -0.03432 & 941 & 441 & 0.464102 & 1016 & -16 & 1 & -0.1090 & -0.04700 & 1016 & 476 & 0.463957 \\
 942 & -12 & 1 & -0.08724 & -0.03741 & 942 & 442 & 0.464661 & 1017 & -17 & 1 & -0.1158 & -0.04990 & 1017 & 475 & 0.462527 \\
 943 & -11 & 1 & -0.07989 & -0.03426 & 943 & 443 & 0.465218 & 1018 & -16 & 1 & -0.1089 & -0.04693 & 1018 & 476 & 0.463046 \\
 944 & -12 & 1 & -0.08708 & -0.03735 & 944 & 442 & 0.463676 & 1019 & -17 & 1 & -0.1156 & -0.04982 & 1019 & 477 & 0.463563 \\
 945 & -13 & 1 & -0.09425 & -0.04042 & 945 & 443 & 0.464234 & 1020 & -18 & 1 & -0.1223 & -0.05271 & 1020 & 476 & 0.462138 \\
 946 & -14 & 1 & -0.1014 & -0.04350 & 946 & 444 & 0.46479 & 1021 & -19 & 1 & -0.1289 & -0.05560 & 1021 & 477 & 0.462655 \\
 947 & -15 & 1 & -0.1086 & -0.04657 & 947 & 445 & 0.465345 & 1022 & -20 & 1 & -0.1356 & -0.05848 & 1022 & 478 & 0.463171 \\
 948 & -14 & 1 & -0.1012 & -0.04343 & 948 & 444 & 0.463809 & 1023 & -21 & 1 & -0.1423 & -0.06136 & 1023 & 479 & 0.463687 \\
 949 & -13 & 1 & -0.09391 & -0.04029 & 949 & 445 & 0.464364 & 1024 & -20 & 1 & -0.1354 & -0.05839 & 1024 & 478 & 0.462267 \\
 950 & -12 & 1 & -0.08661 & -0.03716 & 950 & 444 & 0.462833 & 1025 & -21 & 1 & -0.1420 & -0.06126 & 1025 & 477 & 0.46085 \\
 951 & -11 & 1 & -0.07932 & -0.03404 & 951 & 445 & 0.463387 & 1026 & -22 & 1 & -0.1487 & -0.06413 & 1026 & 478 & 0.461366 \\
 952 & -12 & 1 & -0.08645 & -0.03710 & 952 & 446 & 0.463941 & 1027 & -21 & 1 & -0.1418 & -0.06117 & 1027 & 479 & 0.461881 \\
 953 & -13 & 1 & -0.09357 & -0.04016 & 953 & 447 & 0.464493 & 1028 & -22 & 1 & -0.1484 & -0.06403 & 1028 & 478 & 0.460468 \\
 954 & -12 & 1 & -0.08630 & -0.03704 & 954 & 446 & 0.462968 & 1029 & -21 & 1 & -0.1416 & -0.06108 & 1029 & 479 & 0.460983 \\
 955 & -11 & 1 & -0.07904 & -0.03392 & 955 & 447 & 0.46352 & 1030 & -22 & 1 & -0.1482 & -0.06394 & 1030 & 480 & 0.461497 \\
 956 & -12 & 1 & -0.08614 & -0.03698 & 956 & 446 & 0.462 & 1031 & -23 & 1 & -0.1548 & -0.06679 & 1031 & 481 & 0.46201 \\
 957 & -13 & 1 & -0.09324 & -0.04003 & 957 & 447 & 0.462552 & 1032 & -24 & 1 & -0.1614 & -0.06964 & 1032 & 482 & 0.462522 \\
 958 & -12 & 1 & -0.08599 & -0.03692 & 958 & 448 & 0.463103 & 1033 & -25 & 1 & -0.1680 & -0.07249 & 1033 & 483 & 0.463032 \\
 959 & -11 & 1 & -0.07875 & -0.03381 & 959 & 449 & 0.463652 & 1034 & -26 & 1 & -0.1745 & -0.07533 & 1034 & 484 & 0.463542 \\
 960 & -10 & 1 & -0.07153 & -0.03071 & 960 & 448 & 0.462138 & 1035 & -25 & 1 & -0.1677 & -0.07238 & 1035 & 483 & 0.462138 \\
 961 & -9 & 1 & -0.06432 & -0.02762 & 961 & 447 & 0.460626 & 1036 & -24 & 1 & -0.1608 & -0.06943 & 1036 & 482 & 0.460736 \\
 962 & -10 & 1 & -0.07140 & -0.03066 & 962 & 448 & 0.461177 & 1037 & -23 & 1 & -0.1540 & -0.06649 & 1037 & 483 & 0.461246 \\
 963 & -11 & 1 & -0.07847 & -0.03370 & 963 & 447 & 0.45967 & 1038 & -24 & 1 & -0.1606 & -0.06933 & 1038 & 484 & 0.461756 \\
 964 & -12 & 1 & -0.08553 & -0.03674 & 964 & 446 & 0.458166 & 1039 & -25 & 1 & -0.1671 & -0.07216 & 1039 & 485 & 0.462265 \\
 965 & -11 & 1 & -0.07834 & -0.03365 & 965 & 447 & 0.458717 & 1040 & -24 & 1 & -0.1603 & -0.06922 & 1040 & 484 & 0.460868 \\
 966 & -10 & 1 & -0.07115 & -0.03056 & 966 & 448 & 0.459267 & 1041 & -23 & 1 & -0.1535 & -0.06629 & 1041 & 485 & 0.461377 \\
 967 & -11 & 1 & -0.07820 & -0.03359 & 967 & 449 & 0.459816 & 1042 & -22 & 1 & -0.1467 & -0.06336 & 1042 & 486 & 0.461884 \\
 968 & -12 & 1 & -0.08523 & -0.03662 & 968 & 448 & 0.458318 & 1043 & -21 & 1 & -0.1399 & -0.06043 & 1043 & 487 & 0.462391 \\
 969 & -13 & 1 & -0.09225 & -0.03964 & 969 & 449 & 0.458867 & 1044 & -22 & 1 & -0.1465 & -0.06326 & 1044 & 488 & 0.462897 \\
 970 & -14 & 1 & -0.09926 & -0.04265 & 970 & 450 & 0.459415 & 1045 & -23 & 1 & -0.1530 & -0.06609 & 1045 & 489 & 0.463401 \\
 971 & -15 & 1 & -0.1063 & -0.04566 & 971 & 451 & 0.459962 & 1046 & -22 & 1 & -0.1462 & -0.06317 & 1046 & 490 & 0.463905 \\
 972 & -16 & 1 & -0.1132 & -0.04866 & 972 & 450 & 0.45847 & 1047 & -21 & 1 & -0.1395 & -0.06025 & 1047 & 491 & 0.464408 \\
 973 & -15 & 1 & -0.1061 & -0.04559 & 973 & 451 & 0.459017 & 1048 & -20 & 1 & -0.1327 & -0.05734 & 1048 & 492 & 0.46491 \\
 974 & -14 & 1 & -0.09891 & -0.04251 & 974 & 452 & 0.459562 & 1049 & -21 & 1 & -0.1392 & -0.06016 & 1049 & 493 & 0.46541 \\
\end{array} 
}
\end{equation*} 
\clearpage 

\end{table} 

\clearpage 

\newpage 
\begin{table}[ht]

\centering
\tiny
\begin{equation*}
\boxed{
\begin{array}{ccccc|ccc|ccccc|ccc}
x & L(x) & \frac{\operatorname{sgn}(L(x))}{(-1)^{\floor{\log\log x}}} & 
    \frac{L(x)}{L_{\approx,1}(x)} & \frac{L(x)}{L_{\approx,2}(x)} & 
    x & L_{\ast}(x) & \frac{L(x)}{L_{\approx}^{\ast}(x)} & 
x & L(x) & \frac{\operatorname{sgn}(L(x))}{(-1)^{\floor{\log\log x}}} & 
    \frac{L(x)}{L_{\approx,1}(x)} & \frac{L(x)}{L_{\approx,2}(x)} & 
    x & L_{\ast}(x) & \frac{L(x)}{L_{\approx}^{\ast}(x)} \\ \hline 
 1050 & -22 & 1 & -0.1458 & -0.06298 & 1050 & 492 & 0.464024 & 1125 & -37 & 1 & -0.2311 & -0.1003 & 1125 & 527 & 0.463898 \\
 1051 & -23 & 1 & -0.1523 & -0.06579 & 1051 & 493 & 0.464525 & 1126 & -36 & 1 & -0.2246 & -0.09756 & 1126 & 528 & 0.464366 \\
 1052 & -24 & 1 & -0.1587 & -0.06860 & 1052 & 492 & 0.463142 & 1127 & -37 & 1 & -0.2307 & -0.1002 & 1127 & 527 & 0.463075 \\
 1053 & -25 & 1 & -0.1652 & -0.07141 & 1053 & 491 & 0.461762 & 1128 & -38 & 1 & -0.2368 & -0.1028 & 1128 & 528 & 0.463542 \\
 1054 & -26 & 1 & -0.1717 & -0.07421 & 1054 & 492 & 0.462263 & 1129 & -39 & 1 & -0.2428 & -0.1055 & 1129 & 529 & 0.464009 \\
 1055 & -25 & 1 & -0.1650 & -0.07130 & 1055 & 493 & 0.462763 & 1130 & -40 & 1 & -0.2488 & -0.1081 & 1130 & 530 & 0.464475 \\
 1056 & -26 & 1 & -0.1714 & -0.07410 & 1056 & 494 & 0.463263 & 1131 & -41 & 1 & -0.2549 & -0.1107 & 1131 & 531 & 0.46494 \\
 1057 & -25 & 1 & -0.1647 & -0.07120 & 1057 & 495 & 0.463762 & 1132 & -42 & 1 & -0.2609 & -0.1133 & 1132 & 530 & 0.463654 \\
 1058 & -26 & 1 & -0.1711 & -0.07399 & 1058 & 494 & 0.462387 & 1133 & -41 & 1 & -0.2545 & -0.1106 & 1133 & 531 & 0.464119 \\
 1059 & -25 & 1 & -0.1644 & -0.07109 & 1059 & 495 & 0.462886 & 1134 & -40 & 1 & -0.2481 & -0.1078 & 1134 & 530 & 0.462836 \\
 1060 & -24 & 1 & -0.1577 & -0.06820 & 1060 & 494 & 0.461515 & 1135 & -39 & 1 & -0.2417 & -0.1050 & 1135 & 531 & 0.463301 \\
 1061 & -25 & 1 & -0.1642 & -0.07098 & 1061 & 495 & 0.462013 & 1136 & -40 & 1 & -0.2477 & -0.1076 & 1136 & 530 & 0.462021 \\
 1062 & -24 & 1 & -0.1575 & -0.06809 & 1062 & 494 & 0.460646 & 1137 & -39 & 1 & -0.2413 & -0.1049 & 1137 & 531 & 0.462486 \\
 1063 & -25 & 1 & -0.1639 & -0.07088 & 1063 & 495 & 0.461144 & 1138 & -38 & 1 & -0.2350 & -0.1021 & 1138 & 532 & 0.46295 \\
 1064 & -26 & 1 & -0.1703 & -0.07366 & 1064 & 496 & 0.461641 & 1139 & -37 & 1 & -0.2286 & -0.09937 & 1139 & 533 & 0.463413 \\
 1065 & -27 & 1 & -0.1767 & -0.07644 & 1065 & 497 & 0.462138 & 1140 & -38 & 1 & -0.2346 & -0.1020 & 1140 & 532 & 0.462138 \\
 1066 & -28 & 1 & -0.1831 & -0.07921 & 1066 & 498 & 0.462633 & 1141 & -37 & 1 & -0.2283 & -0.09923 & 1141 & 533 & 0.462601 \\
 1067 & -27 & 1 & -0.1764 & -0.07632 & 1067 & 499 & 0.463128 & 1142 & -36 & 1 & -0.2219 & -0.09648 & 1142 & 534 & 0.463063 \\
 1068 & -26 & 1 & -0.1698 & -0.07344 & 1068 & 498 & 0.461767 & 1143 & -37 & 1 & -0.2279 & -0.09910 & 1143 & 533 & 0.461791 \\
 1069 & -27 & 1 & -0.1762 & -0.07621 & 1069 & 499 & 0.462261 & 1144 & -38 & 1 & -0.2339 & -0.1017 & 1144 & 534 & 0.462253 \\
 1070 & -28 & 1 & -0.1825 & -0.07898 & 1070 & 500 & 0.462755 & 1145 & -37 & 1 & -0.2276 & -0.09896 & 1145 & 535 & 0.462714 \\
 1071 & -27 & 1 & -0.1759 & -0.07610 & 1071 & 499 & 0.461398 & 1146 & -38 & 1 & -0.2336 & -0.1016 & 1146 & 536 & 0.463175 \\
 1072 & -28 & 1 & -0.1822 & -0.07886 & 1072 & 498 & 0.460044 & 1147 & -37 & 1 & -0.2273 & -0.09882 & 1147 & 537 & 0.463634 \\
 1073 & -27 & 1 & -0.1756 & -0.07599 & 1073 & 499 & 0.460538 & 1148 & -36 & 1 & -0.2209 & -0.09609 & 1148 & 536 & 0.462368 \\
 1074 & -28 & 1 & -0.1820 & -0.07875 & 1074 & 500 & 0.461031 & 1149 & -35 & 1 & -0.2146 & -0.09336 & 1149 & 537 & 0.462827 \\
 1075 & -29 & 1 & -0.1883 & -0.08150 & 1075 & 499 & 0.459681 & 1150 & -34 & 1 & -0.2084 & -0.09063 & 1150 & 536 & 0.461564 \\
 1076 & -30 & 1 & -0.1946 & -0.08425 & 1076 & 498 & 0.458334 & 1151 & -35 & 1 & -0.2143 & -0.09323 & 1151 & 537 & 0.462023 \\
 1077 & -29 & 1 & -0.1880 & -0.08138 & 1077 & 499 & 0.458828 & 1152 & -36 & 1 & -0.2203 & -0.09583 & 1152 & 536 & 0.460762 \\
 1078 & -28 & 1 & -0.1814 & -0.07852 & 1078 & 498 & 0.457483 & 1153 & -37 & 1 & -0.2262 & -0.09842 & 1153 & 537 & 0.461222 \\
 1079 & -27 & 1 & -0.1748 & -0.07566 & 1079 & 499 & 0.457977 & 1154 & -36 & 1 & -0.2200 & -0.09570 & 1154 & 538 & 0.46168 \\
 1080 & -28 & 1 & -0.1811 & -0.07840 & 1080 & 500 & 0.45847 & 1155 & -35 & 1 & -0.2137 & -0.09297 & 1155 & 539 & 0.462138 \\
 1081 & -27 & 1 & -0.1745 & -0.07555 & 1081 & 501 & 0.458962 & 1156 & -34 & 1 & -0.2074 & -0.09026 & 1156 & 540 & 0.462595 \\
 1082 & -26 & 1 & -0.1679 & -0.07270 & 1082 & 502 & 0.459453 & 1157 & -33 & 1 & -0.2012 & -0.08754 & 1157 & 541 & 0.463051 \\
 1083 & -27 & 1 & -0.1742 & -0.07544 & 1083 & 501 & 0.458114 & 1158 & -34 & 1 & -0.2071 & -0.09013 & 1158 & 542 & 0.463506 \\
 1084 & -28 & 1 & -0.1805 & -0.07818 & 1084 & 500 & 0.456778 & 1159 & -33 & 1 & -0.2009 & -0.08742 & 1159 & 543 & 0.463961 \\
 1085 & -29 & 1 & -0.1868 & -0.08091 & 1085 & 501 & 0.45727 & 1160 & -34 & 1 & -0.2068 & -0.09001 & 1160 & 544 & 0.464414 \\
 1086 & -30 & 1 & -0.1931 & -0.08364 & 1086 & 502 & 0.457761 & 1161 & -33 & 1 & -0.2006 & -0.08731 & 1161 & 545 & 0.464867 \\
 1087 & -31 & 1 & -0.1994 & -0.08636 & 1087 & 503 & 0.458251 & 1162 & -34 & 1 & -0.2065 & -0.08989 & 1162 & 546 & 0.465319 \\
 1088 & -32 & 1 & -0.2056 & -0.08909 & 1088 & 502 & 0.456919 & 1163 & -35 & 1 & -0.2124 & -0.09247 & 1163 & 547 & 0.465771 \\
 1089 & -31 & 1 & -0.1991 & -0.08624 & 1089 & 503 & 0.457409 & 1164 & -34 & 1 & -0.2062 & -0.08977 & 1164 & 546 & 0.46452 \\
 1090 & -32 & 1 & -0.2053 & -0.08896 & 1090 & 504 & 0.457898 & 1165 & -33 & 1 & -0.2000 & -0.08707 & 1165 & 547 & 0.464971 \\
 1091 & -33 & 1 & -0.2116 & -0.09167 & 1091 & 505 & 0.458386 & 1166 & -34 & 1 & -0.2059 & -0.08965 & 1166 & 548 & 0.465422 \\
 1092 & -34 & 1 & -0.2178 & -0.09438 & 1092 & 504 & 0.457059 & 1167 & -33 & 1 & -0.1997 & -0.08695 & 1167 & 549 & 0.465871 \\
 1093 & -35 & 1 & -0.2240 & -0.09709 & 1093 & 505 & 0.457547 & 1168 & -34 & 1 & -0.2056 & -0.08953 & 1168 & 548 & 0.464625 \\
 1094 & -34 & 1 & -0.2175 & -0.09425 & 1094 & 506 & 0.458034 & 1169 & -33 & 1 & -0.1994 & -0.08684 & 1169 & 549 & 0.465074 \\
 1095 & -35 & 1 & -0.2237 & -0.09695 & 1095 & 507 & 0.45852 & 1170 & -34 & 1 & -0.2053 & -0.08941 & 1170 & 548 & 0.463831 \\
 1096 & -34 & 1 & -0.2171 & -0.09411 & 1096 & 508 & 0.459005 & 1171 & -35 & 1 & -0.2112 & -0.09198 & 1171 & 549 & 0.46428 \\
 1097 & -35 & 1 & -0.2233 & -0.09681 & 1097 & 509 & 0.45949 & 1172 & -36 & 1 & -0.2171 & -0.09454 & 1172 & 548 & 0.463039 \\
 1098 & -34 & 1 & -0.2168 & -0.09398 & 1098 & 508 & 0.458169 & 1173 & -37 & 1 & -0.2229 & -0.09710 & 1173 & 549 & 0.463489 \\
 1099 & -33 & 1 & -0.2103 & -0.09115 & 1099 & 509 & 0.458654 & 1174 & -36 & 1 & -0.2167 & -0.09441 & 1174 & 550 & 0.463937 \\
 1100 & -34 & 1 & -0.2165 & -0.09384 & 1100 & 510 & 0.459137 & 1175 & -37 & 1 & -0.2226 & -0.09697 & 1175 & 549 & 0.4627 \\
 1101 & -33 & 1 & -0.2099 & -0.09102 & 1101 & 511 & 0.459619 & 1176 & -36 & 1 & -0.2164 & -0.09429 & 1176 & 548 & 0.461464 \\
 1102 & -34 & 1 & -0.2161 & -0.09371 & 1102 & 512 & 0.460101 & 1177 & -35 & 1 & -0.2103 & -0.09161 & 1177 & 549 & 0.461913 \\
 1103 & -35 & 1 & -0.2223 & -0.09640 & 1103 & 513 & 0.460581 & 1178 & -36 & 1 & -0.2161 & -0.09416 & 1178 & 550 & 0.462362 \\
 1104 & -34 & 1 & -0.2158 & -0.09358 & 1104 & 512 & 0.459267 & 1179 & -37 & 1 & -0.2220 & -0.09671 & 1179 & 549 & 0.46113 \\
 1105 & -35 & 1 & -0.2220 & -0.09626 & 1105 & 513 & 0.459748 & 1180 & -36 & 1 & -0.2158 & -0.09404 & 1180 & 548 & 0.4599 \\
 1106 & -36 & 1 & -0.2281 & -0.09894 & 1106 & 514 & 0.460228 & 1181 & -37 & 1 & -0.2216 & -0.09659 & 1181 & 549 & 0.460349 \\
 1107 & -35 & 1 & -0.2216 & -0.09612 & 1107 & 515 & 0.460706 & 1182 & -38 & 1 & -0.2275 & -0.09913 & 1182 & 550 & 0.460797 \\
 1108 & -36 & 1 & -0.2278 & -0.09880 & 1108 & 514 & 0.459397 & 1183 & -39 & 1 & -0.2333 & -0.1017 & 1183 & 549 & 0.459571 \\
 1109 & -37 & 1 & -0.2339 & -0.1015 & 1109 & 515 & 0.459876 & 1184 & -38 & 1 & -0.2271 & -0.09900 & 1184 & 550 & 0.460019 \\
 1110 & -36 & 1 & -0.2274 & -0.09866 & 1110 & 516 & 0.460353 & 1185 & -39 & 1 & -0.2329 & -0.1015 & 1185 & 551 & 0.460466 \\
 1111 & -35 & 1 & -0.2209 & -0.09585 & 1111 & 517 & 0.46083 & 1186 & -38 & 1 & -0.2268 & -0.09887 & 1186 & 552 & 0.460913 \\
 1112 & -34 & 1 & -0.2145 & -0.09305 & 1112 & 518 & 0.461307 & 1187 & -39 & 1 & -0.2326 & -0.1014 & 1187 & 553 & 0.461359 \\
 1113 & -35 & 1 & -0.2206 & -0.09572 & 1113 & 519 & 0.461782 & 1188 & -38 & 1 & -0.2265 & -0.09874 & 1188 & 552 & 0.460137 \\
 1114 & -34 & 1 & -0.2141 & -0.09292 & 1114 & 520 & 0.462256 & 1189 & -37 & 1 & -0.2203 & -0.09608 & 1189 & 553 & 0.460583 \\
 1115 & -33 & 1 & -0.2077 & -0.09012 & 1115 & 521 & 0.46273 & 1190 & -36 & 1 & -0.2142 & -0.09342 & 1190 & 554 & 0.461028 \\
 1116 & -34 & 1 & -0.2138 & -0.09279 & 1116 & 522 & 0.463203 & 1191 & -35 & 1 & -0.2081 & -0.09076 & 1191 & 555 & 0.461473 \\
 1117 & -35 & 1 & -0.2199 & -0.09545 & 1117 & 523 & 0.463674 & 1192 & -34 & 1 & -0.2020 & -0.08811 & 1192 & 556 & 0.461916 \\
 1118 & -36 & 1 & -0.2260 & -0.09811 & 1118 & 524 & 0.464145 & 1193 & -35 & 1 & -0.2078 & -0.09064 & 1193 & 557 & 0.462359 \\
 1119 & -35 & 1 & -0.2196 & -0.09531 & 1119 & 525 & 0.464616 & 1194 & -36 & 1 & -0.2136 & -0.09317 & 1194 & 558 & 0.462801 \\
 1120 & -36 & 1 & -0.2257 & -0.09797 & 1120 & 526 & 0.465085 & 1195 & -35 & 1 & -0.2075 & -0.09052 & 1195 & 559 & 0.463243 \\
 1121 & -35 & 1 & -0.2192 & -0.09518 & 1121 & 527 & 0.465554 & 1196 & -34 & 1 & -0.2015 & -0.08788 & 1196 & 558 & 0.462027 \\
 1122 & -34 & 1 & -0.2128 & -0.09240 & 1122 & 528 & 0.466021 & 1197 & -33 & 1 & -0.1954 & -0.08524 & 1197 & 557 & 0.460814 \\
 1123 & -35 & 1 & -0.2189 & -0.09505 & 1123 & 529 & 0.466488 & 1198 & -32 & 1 & -0.1893 & -0.08260 & 1198 & 558 & 0.461256 \\
 1124 & -36 & 1 & -0.2250 & -0.09769 & 1124 & 528 & 0.465192 & 1199 & -31 & 1 & -0.1833 & -0.07997 & 1199 & 559 & 0.461697 \\
\end{array} 
}
\end{equation*} 
\clearpage 

\end{table} 

\clearpage 

%\NBRef{A03-2020-04026}
%\NBRef{A04-2020-04026}

\end{document}
